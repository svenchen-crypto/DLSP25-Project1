{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_name = \"deep-learning-spring-2025-project-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIugLjz-A2Qd"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from data_loader import get_cifar10_dataloaders, get_test_dataloader\n",
    "from trainer import train_model\n",
    "from model import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4z7iY1pkk2C"
   },
   "source": [
    "Configure the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e3wMn_41kd5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the total number of trainable parameters\n",
    "def num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4903242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 10, 50)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "    momentum = trial.suggest_uniform(\"momentum\", 0.5, 0.9) if optimizer_name == \"SGD\" else None\n",
    "\n",
    "    # Suggest data transformations\n",
    "    transform = transforms.Compose([\n",
    "        # add random crop and padding\n",
    "        transforms.RandomHorizontalFlip(trial.suggest_float(\"h_flip\", 0.0, 1.0)),\n",
    "        transforms.RandomRotation(trial.suggest_int(\"rotation\", 0, 30)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "    ])\n",
    "    \n",
    "    train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "        transform,\n",
    "        subset_percent=1.0, \n",
    "        valid_size=0.1,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Define model\n",
    "    model = ResNet18()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model_name = \"resnet\"\n",
    "\n",
    "    # Print the current hyperparameters, transformations, and model name\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Trial {trial.number}:\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Trainable Parameters: {num_params}\")\n",
    "    print(f\"Epochs: {num_epochs}\")\n",
    "    print(f\"Batch Size: {batch_size}\")\n",
    "    print(f\"Learning Rate: {learning_rate}\")\n",
    "    print(f\"Optimizer: {optimizer_name}\")\n",
    "    if optimizer_name == \"SGD\":\n",
    "        print(f\"Momentum: {momentum}\")\n",
    "    print(f\"Transformations: {transform}\")\n",
    "    print(\"- \" * 25)\n",
    "\n",
    "    # Define optimizer\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        trial, model, train_loader, criterion, optimizer, \n",
    "        valid_loader=valid_loader, num_epochs=num_epochs, device=device)\n",
    "    \n",
    "    # Checkpoint the model with the best validation accuracy\n",
    "    model_filename = f\"model_trial_{trial.number}_val_acc_{best_val_accuracy:.4f}.pth\"\n",
    "    study_name = trial.study.study_name\n",
    "    checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "    model_path = os.path.join(checkpoint_dir, model_filename)\n",
    "    \n",
    "    # Create a directory for checkpoints if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the model state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model checkpoint saved to {model_path}\")\n",
    "\n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-09 12:42:46,559] A new study created in memory with name: study_2025-03-09_12-42-46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Trial 0:\n",
      "Model: resnet\n",
      "Trainable Parameters: <function num_params at 0x14f0a0a4b940>\n",
      "Epochs: 46\n",
      "Batch Size: 256\n",
      "Learning Rate: 0.005965107711939086\n",
      "Optimizer: RMSprop\n",
      "Transformations: Compose(\n",
      "    RandomHorizontalFlip(p=0.06640679932192928)\n",
      "    RandomRotation(degrees=[-29.0, 29.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      ")\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/46], Batch [100/176], Loss: 1.7964\n",
      "  Validation Accuracy after Epoch 1: 0.3694\n",
      "  Epoch [2/46], Batch [100/176], Loss: 1.5153\n",
      "  Validation Accuracy after Epoch 2: 0.4332\n",
      "  Epoch [3/46], Batch [100/176], Loss: 1.2579\n",
      "  Validation Accuracy after Epoch 3: 0.5672\n",
      "  Epoch [4/46], Batch [100/176], Loss: 1.0908\n",
      "  Validation Accuracy after Epoch 4: 0.5522\n",
      "  Epoch [5/46], Batch [100/176], Loss: 1.0960\n",
      "  Validation Accuracy after Epoch 5: 0.5778\n",
      "  Epoch [6/46], Batch [100/176], Loss: 0.9112\n",
      "  Validation Accuracy after Epoch 6: 0.6556\n",
      "  Epoch [7/46], Batch [100/176], Loss: 0.8492\n",
      "  Validation Accuracy after Epoch 7: 0.6812\n",
      "  Epoch [8/46], Batch [100/176], Loss: 0.7236\n",
      "  Validation Accuracy after Epoch 8: 0.6970\n",
      "  Epoch [9/46], Batch [100/176], Loss: 0.7390\n",
      "  Validation Accuracy after Epoch 9: 0.6958\n",
      "  Epoch [10/46], Batch [100/176], Loss: 0.5167\n",
      "  Validation Accuracy after Epoch 10: 0.7362\n",
      "  Epoch [11/46], Batch [100/176], Loss: 0.4306\n",
      "  Validation Accuracy after Epoch 11: 0.7490\n",
      "  Epoch [12/46], Batch [100/176], Loss: 0.4811\n",
      "  Validation Accuracy after Epoch 12: 0.7624\n",
      "  Epoch [13/46], Batch [100/176], Loss: 0.3137\n",
      "  Validation Accuracy after Epoch 13: 0.7932\n",
      "  Epoch [14/46], Batch [100/176], Loss: 0.4512\n",
      "  Validation Accuracy after Epoch 14: 0.7814\n",
      "  Epoch [15/46], Batch [100/176], Loss: 0.2771\n",
      "  Validation Accuracy after Epoch 15: 0.7562\n",
      "  Epoch [16/46], Batch [100/176], Loss: 0.3245\n",
      "  Validation Accuracy after Epoch 16: 0.7984\n",
      "  Epoch [17/46], Batch [100/176], Loss: 0.2880\n",
      "  Validation Accuracy after Epoch 17: 0.8020\n",
      "  Epoch [18/46], Batch [100/176], Loss: 0.2269\n",
      "  Validation Accuracy after Epoch 18: 0.7810\n",
      "  Epoch [19/46], Batch [100/176], Loss: 0.2333\n",
      "  Validation Accuracy after Epoch 19: 0.7982\n",
      "  Epoch [20/46], Batch [100/176], Loss: 0.1798\n",
      "  Validation Accuracy after Epoch 20: 0.8108\n",
      "  Epoch [21/46], Batch [100/176], Loss: 0.1754\n",
      "  Validation Accuracy after Epoch 21: 0.8050\n",
      "  Epoch [22/46], Batch [100/176], Loss: 0.1796\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=study_name)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints_study_2025-03-09_12-31-02/model_trial_0_val_acc_0.0000.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the latest checkpoint\u001b[39;00m\n\u001b[1;32m      5\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/model_trial_0_val_acc_0.0000.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint)\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints_study_2025-03-09_12-31-02/model_trial_0_val_acc_0.0000.pth'"
     ]
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model.to(device)\n",
    "\n",
    "# Load the latest checkpoint\n",
    "checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "checkpoint = torch.load(f\"{checkpoint_dir}/model_trial_0_val_acc_0.0000.pth\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 32, 32])\n",
      "Label: 8\n",
      "Number of training data: 9\n",
      "Number of validation data: 1\n",
      "Acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "])\n",
    "\n",
    "from trainer import evaluate_model\n",
    "_, valid_loader = get_cifar10_dataloaders(\n",
    "    transform,\n",
    "    subset_percent=0.0002, \n",
    "    valid_size=0.1,\n",
    "    batch_size=128,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "acc = evaluate_model(model, valid_loader, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission file with test data\n",
    "test_loader = get_test_dataloader()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in test_loader:\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaggle\n",
    "# kaggle.api.competition_submit(\n",
    "#     file_name=\"submission.csv\",\n",
    "#     message=\"test\",\n",
    "#     competition=competition_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk8i7jiGjSg0feqDTW0l2u",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
