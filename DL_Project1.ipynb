{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_name = \"deep-learning-spring-2025-project-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIugLjz-A2Qd"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from data_loader import get_cifar10_dataloaders, get_test_dataloader\n",
    "from trainer import train_model\n",
    "# from model import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4z7iY1pkk2C"
   },
   "source": [
    "Configure the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e3wMn_41kd5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 10, 50)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "    momentum = trial.suggest_uniform(\"momentum\", 0.5, 0.9) if optimizer_name == \"SGD\" else None\n",
    "\n",
    "    # Suggest data transformations\n",
    "    transform = transforms.Compose([\n",
    "        # add random crop and padding\n",
    "        transforms.RandomHorizontalFlip(trial.suggest_float(\"h_flip\", 0.0, 1.0)),\n",
    "        transforms.RandomRotation(trial.suggest_int(\"rotation\", 0, 30)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "    ])\n",
    "    \n",
    "    train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "        transform,\n",
    "        subset_percent=1.0, \n",
    "        valid_size=0.1,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Define model\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    model_name = \"resnet18\"\n",
    "\n",
    "    # Print the current hyperparameters, transformations, and model name\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Trial {trial.number}:\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Epochs: {num_epochs}\")\n",
    "    print(f\"Batch Size: {batch_size}\")\n",
    "    print(f\"Learning Rate: {learning_rate}\")\n",
    "    print(f\"Optimizer: {optimizer_name}\")\n",
    "    if optimizer_name == \"SGD\":\n",
    "        print(f\"Momentum: {momentum}\")\n",
    "    print(f\"Transformations: {transform}\")\n",
    "    print(\"- \" * 25)\n",
    "\n",
    "    # Define optimizer\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        trial, model, train_loader, criterion, optimizer, \n",
    "        valid_loader=valid_loader, num_epochs=num_epochs, device=device)\n",
    "    \n",
    "    # Checkpoint the model with the best validation accuracy\n",
    "    model_filename = f\"model_trial_{trial.number}_val_acc_{best_val_accuracy:.4f}.pth\"\n",
    "    study_name = trial.study.study_name\n",
    "    checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "    model_path = os.path.join(checkpoint_dir, model_filename)\n",
    "    \n",
    "    # Create a directory for checkpoints if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the model state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model checkpoint saved to {model_path}\")\n",
    "\n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-09 12:31:02,851] A new study created in memory with name: study_2025-03-09_12-31-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 32, 32])\n",
      "Label: 1\n",
      "Number of training data: 45000\n",
      "Number of validation data: 5000\n",
      "--------------------------------------------------\n",
      "Trial 0:\n",
      "Model: resnet18\n",
      "Epochs: 24\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.001101960409207437\n",
      "Optimizer: Adam\n",
      "Transformations: Compose(\n",
      "    RandomHorizontalFlip(p=0.7723181767062807)\n",
      "    RandomRotation(degrees=[-23.0, 23.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      ")\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/24], Batch [100/704], Loss: 1.5933\n",
      "  Epoch [1/24], Batch [200/704], Loss: 1.5934\n",
      "  Epoch [1/24], Batch [300/704], Loss: 1.6876\n",
      "  Epoch [1/24], Batch [400/704], Loss: 1.2799\n",
      "  Epoch [1/24], Batch [500/704], Loss: 1.7427\n",
      "  Epoch [1/24], Batch [600/704], Loss: 1.3450\n",
      "  Epoch [1/24], Batch [700/704], Loss: 1.2652\n",
      "  Validation Accuracy after Epoch 1: 0.5380\n",
      "  Epoch [2/24], Batch [100/704], Loss: 1.1431\n",
      "  Epoch [2/24], Batch [200/704], Loss: 1.4307\n",
      "  Epoch [2/24], Batch [300/704], Loss: 1.2018\n",
      "  Epoch [2/24], Batch [400/704], Loss: 1.1710\n",
      "  Epoch [2/24], Batch [500/704], Loss: 1.3784\n",
      "  Epoch [2/24], Batch [600/704], Loss: 1.0109\n",
      "  Epoch [2/24], Batch [700/704], Loss: 1.1095\n",
      "  Validation Accuracy after Epoch 2: 0.6158\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=study_name)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the latest checkpoint\n",
    "checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "checkpoint = torch.load(f\"{checkpoint_dir}/model_trial_0_val_acc_0.0000.pth\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 32, 32])\n",
      "Label: 8\n",
      "Number of training data: 9\n",
      "Number of validation data: 1\n",
      "Acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "])\n",
    "\n",
    "from trainer import evaluate_model\n",
    "_, valid_loader = get_cifar10_dataloaders(\n",
    "    transform,\n",
    "    subset_percent=0.0002, \n",
    "    valid_size=0.1,\n",
    "    batch_size=128,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "acc = evaluate_model(model, valid_loader, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission file with test data\n",
    "test_loader = get_test_dataloader()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in test_loader:\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaggle\n",
    "# kaggle.api.competition_submit(\n",
    "#     file_name=\"submission.csv\",\n",
    "#     message=\"test\",\n",
    "#     competition=competition_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk8i7jiGjSg0feqDTW0l2u",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
