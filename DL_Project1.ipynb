{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIugLjz-A2Qd"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import optuna\n",
    "from torch.optim import lr_scheduler # StepLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "from data_loader import get_cifar10_dataloaders\n",
    "from trainer import train_model\n",
    "from model import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4z7iY1pkk2C"
   },
   "source": [
    "Configure the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e3wMn_41kd5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the total number of trainable parameters\n",
    "def num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4903242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_study_details(checkpoint_dir, trial_num, trial_details):\n",
    "    file_path = os.path.join(checkpoint_dir, \"study_details.json\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump({}, f, indent=4)\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        study_details = json.load(f)\n",
    "\n",
    "    study_details[str(trial_num)] = trial_details\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(study_details, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    study_name = trial.study.study_name\n",
    "    checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True) # Create a directory for checkpoints if it doesn't exist\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    num_epochs = 150 # trial.suggest_int(\"num_epochs\", 20, 35)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128]) # Rmed: 256\n",
    "    optimizer_type = trial.suggest_categorical(\"optimizer_type\", [\"Adam\", \"SGD\"]) # Rmed: RMSprop\n",
    "    scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"ReduceLROnPlateau\", \"OneCycleLR\"]) # Rmed: StepLR\n",
    "\n",
    "    optimizer_map = {\n",
    "        \"Adam\": optim.AdamW,\n",
    "        \"SGD\": optim.SGD,\n",
    "        \"RMSprop\": optim.RMSprop\n",
    "    }\n",
    "\n",
    "    scheduler_map = {\n",
    "        \"StepLR\": lr_scheduler.StepLR,\n",
    "        \"CosineAnnealingLR\": lr_scheduler.CosineAnnealingLR,\n",
    "        \"ReduceLROnPlateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "        \"OneCycleLR\": lr_scheduler.OneCycleLR\n",
    "    }\n",
    "    \n",
    "    optimizer_params = {\n",
    "        \"weight_decay\": trial.suggest_categorical(\"weight_decay\", [1e-4, 5e-4])\n",
    "    }\n",
    "    \n",
    "    if optimizer_type == \"SGD\":\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 0.01, 0.05, log=True)\n",
    "        optimizer_params[\"momentum\"] = 0.9 # trial.suggest_float(\"momentum\", 0.8, 0.9)\n",
    "        optimizer_params[\"nesterov\"] = True #bool(trial.suggest_categorical(\"nesterov\", [0, 1]))\n",
    "        optimizer_params[\"weight_decay\"] = 5e-4\n",
    "    else:\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 0.0001, 0.001, log=True)\n",
    "        optimizer_params[\"weight_decay\"] = 1e-4\n",
    "        \n",
    "    # Suggest data transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(trial.suggest_float(\"h_flip\", 0.0, 1.0)),\n",
    "        transforms.RandomRotation(trial.suggest_int(\"rotation\", 0, 30)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "    ])\n",
    "    \n",
    "    train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "        transform,\n",
    "        subset_percent=1, \n",
    "        valid_size=0.2,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    scheduler_params = {}\n",
    "    if scheduler_type == \"StepLR\":\n",
    "        scheduler_params[\"step_size\"] = trial.suggest_int(\"step_size\", 5, 20)\n",
    "        scheduler_params[\"gamma\"] = trial.suggest_float(\"gamma\", 0.1, 0.9)\n",
    "    elif scheduler_type == \"CosineAnnealingLR\":\n",
    "        scheduler_params[\"T_max\"] = 150 #trial.suggest_int(\"T_max\", 10, 50)\n",
    "        scheduler_params[\"eta_min\"] = trial.suggest_float(\"eta_min\", 0.0, 1e-6)\n",
    "    elif scheduler_type == \"ReduceLROnPlateau\":\n",
    "        scheduler_params[\"factor\"] = trial.suggest_float(\"factor\", 0.1, 0.9)\n",
    "        scheduler_params[\"patience\"] = trial.suggest_int(\"patience\", 2, 10)\n",
    "        scheduler_params[\"mode\"] = \"min\"\n",
    "    elif scheduler_type == \"OneCycleLR\":\n",
    "        scheduler_params[\"max_lr\"] = 0.1\n",
    "        scheduler_params[\"steps_per_epoch\"] = len(train_loader)\n",
    "        scheduler_params[\"epochs\"] = num_epochs\n",
    "\n",
    "    # Define model\n",
    "    model = ResNet18()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    trial_details = trial.params.copy()\n",
    "    trial_details[\"model_name\"] =  \"resnet18\"\n",
    "    trial_details[\"trainable_parameters\"] = num_params(model)\n",
    "    \n",
    "    # Print trial details\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{trial.number=}\")\n",
    "    for param, val in trial_details.items():\n",
    "        print(f\"{param}: {val}\")\n",
    "    print(\"- \" * 25)\n",
    "    update_study_details(checkpoint_dir, trial.number, trial_details)\n",
    "\n",
    "    optimizer = optimizer_map[optimizer_type](model.parameters(), **optimizer_params)\n",
    "    scheduler = scheduler_map[scheduler_type](optimizer, **scheduler_params)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        trial, model, train_loader, criterion, optimizer, \n",
    "        valid_loader=valid_loader, num_epochs=num_epochs, device=device,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    \n",
    "    # Checkpoint the model with the best validation accuracy\n",
    "    model_filename = f\"model_trial_{trial.number}_val_acc_{best_val_accuracy:.4f}.pth\"\n",
    "    model_path = os.path.join(checkpoint_dir, model_filename)\n",
    "    \n",
    "    # Save the model state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model checkpoint saved to {model_path}\")\n",
    "    trial_details[\"best_val_accuracy\"] = best_val_accuracy\n",
    "    trial_details[\"checkpoint_path\"] = model_path\n",
    "    update_study_details(checkpoint_dir, trial.number, trial_details)\n",
    "    \n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-09 23:00:10,784] A new study created in memory with name: study_2025-03-09_23-00-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=0\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: CosineAnnealingLR\n",
      "weight_decay: 0.0005\n",
      "learning_rate: 0.0009039934625206852\n",
      "h_flip: 0.6900074185944934\n",
      "rotation: 0\n",
      "eta_min: 2.8794734992728567e-07\n",
      "model_name: resnet18\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/150], Batch [310/313], Loss: 1.4270\n",
      "  Validation Accuracy after Epoch 1: 0.4845\n",
      "  Epoch [2/150], Batch [310/313], Loss: 1.0383\n",
      "  Validation Accuracy after Epoch 2: 0.6007\n",
      "  Epoch [3/150], Batch [310/313], Loss: 1.0462\n",
      "  Validation Accuracy after Epoch 3: 0.6402\n",
      "  Epoch [4/150], Batch [310/313], Loss: 0.8243\n",
      "  Validation Accuracy after Epoch 4: 0.7030\n",
      "  Epoch [5/150], Batch [310/313], Loss: 0.6541\n",
      "  Validation Accuracy after Epoch 5: 0.7429\n",
      "  Epoch [6/150], Batch [310/313], Loss: 0.6962\n",
      "  Validation Accuracy after Epoch 6: 0.7603\n",
      "  Epoch [7/150], Batch [310/313], Loss: 0.5589\n",
      "  Validation Accuracy after Epoch 7: 0.7944\n",
      "  Epoch [8/150], Batch [310/313], Loss: 0.7183\n",
      "  Validation Accuracy after Epoch 8: 0.8125\n",
      "  Epoch [9/150], Batch [310/313], Loss: 0.4005\n",
      "  Validation Accuracy after Epoch 9: 0.8271\n",
      "  Epoch [10/150], Batch [310/313], Loss: 0.4959\n",
      "  Validation Accuracy after Epoch 10: 0.8344\n",
      "  Epoch [11/150], Batch [310/313], Loss: 0.2847\n",
      "  Validation Accuracy after Epoch 11: 0.8425\n",
      "  Epoch [12/150], Batch [310/313], Loss: 0.3424\n",
      "  Validation Accuracy after Epoch 12: 0.8473\n",
      "  Epoch [13/150], Batch [310/313], Loss: 0.3549\n",
      "  Validation Accuracy after Epoch 13: 0.8526\n",
      "  Epoch [14/150], Batch [310/313], Loss: 0.3559\n",
      "  Validation Accuracy after Epoch 14: 0.8629\n",
      "  Epoch [15/150], Batch [310/313], Loss: 0.4004\n",
      "  Validation Accuracy after Epoch 15: 0.8682\n",
      "  Epoch [16/150], Batch [310/313], Loss: 0.3030\n",
      "  Validation Accuracy after Epoch 16: 0.8693\n",
      "  Epoch [17/150], Batch [310/313], Loss: 0.3392\n",
      "  Validation Accuracy after Epoch 17: 0.8664\n",
      "  Epoch [18/150], Batch [310/313], Loss: 0.2710\n",
      "  Validation Accuracy after Epoch 18: 0.8616\n",
      "  Epoch [19/150], Batch [310/313], Loss: 0.2452\n",
      "  Validation Accuracy after Epoch 19: 0.8474\n",
      "  Epoch [20/150], Batch [310/313], Loss: 0.2892\n",
      "  Validation Accuracy after Epoch 20: 0.8644\n",
      "  Epoch [21/150], Batch [310/313], Loss: 0.3868\n",
      "  Validation Accuracy after Epoch 21: 0.8342\n",
      "  Epoch [22/150], Batch [310/313], Loss: 0.2760\n",
      "  Validation Accuracy after Epoch 22: 0.8401\n",
      "  Epoch [23/150], Batch [310/313], Loss: 0.2467\n",
      "  Validation Accuracy after Epoch 23: 0.8388\n",
      "  Epoch [24/150], Batch [310/313], Loss: 0.4185\n",
      "  Validation Accuracy after Epoch 24: 0.8393\n",
      "  Epoch [25/150], Batch [310/313], Loss: 0.2515\n",
      "  Validation Accuracy after Epoch 25: 0.8466\n",
      "  Epoch [26/150], Batch [310/313], Loss: 0.1969\n",
      "  Validation Accuracy after Epoch 26: 0.8431\n",
      "  Epoch [27/150], Batch [310/313], Loss: 0.2390\n",
      "  Validation Accuracy after Epoch 27: 0.8486\n",
      "  Epoch [28/150], Batch [310/313], Loss: 0.3034\n",
      "  Validation Accuracy after Epoch 28: 0.8679\n",
      "  Epoch [29/150], Batch [310/313], Loss: 0.2417\n",
      "  Validation Accuracy after Epoch 29: 0.8682\n",
      "  Epoch [30/150], Batch [310/313], Loss: 0.1539\n",
      "  Validation Accuracy after Epoch 30: 0.8717\n",
      "  Epoch [31/150], Batch [310/313], Loss: 0.2503\n",
      "  Validation Accuracy after Epoch 31: 0.8751\n",
      "  Epoch [32/150], Batch [310/313], Loss: 0.1573\n",
      "  Validation Accuracy after Epoch 32: 0.8887\n",
      "  Epoch [33/150], Batch [310/313], Loss: 0.1198\n",
      "  Validation Accuracy after Epoch 33: 0.8889\n",
      "  Epoch [34/150], Batch [310/313], Loss: 0.1602\n",
      "  Validation Accuracy after Epoch 34: 0.8926\n",
      "  Epoch [35/150], Batch [310/313], Loss: 0.2751\n",
      "  Validation Accuracy after Epoch 35: 0.8910\n",
      "  Epoch [36/150], Batch [310/313], Loss: 0.1323\n",
      "  Validation Accuracy after Epoch 36: 0.8924\n",
      "  Epoch [37/150], Batch [310/313], Loss: 0.1965\n",
      "  Validation Accuracy after Epoch 37: 0.8937\n",
      "  Epoch [38/150], Batch [310/313], Loss: 0.1219\n",
      "  Validation Accuracy after Epoch 38: 0.8963\n",
      "  Epoch [39/150], Batch [310/313], Loss: 0.0824\n",
      "  Validation Accuracy after Epoch 39: 0.8924\n",
      "  Epoch [40/150], Batch [310/313], Loss: 0.0770\n",
      "  Validation Accuracy after Epoch 40: 0.8995\n",
      "  Epoch [41/150], Batch [310/313], Loss: 0.1338\n",
      "  Validation Accuracy after Epoch 41: 0.8969\n",
      "  Epoch [42/150], Batch [310/313], Loss: 0.1088\n",
      "  Validation Accuracy after Epoch 42: 0.8919\n",
      "  Epoch [43/150], Batch [310/313], Loss: 0.0981\n",
      "  Validation Accuracy after Epoch 43: 0.8901\n",
      "  Epoch [44/150], Batch [310/313], Loss: 0.0736\n",
      "  Validation Accuracy after Epoch 44: 0.8844\n",
      "  Epoch [45/150], Batch [310/313], Loss: 0.0864\n",
      "  Validation Accuracy after Epoch 45: 0.8724\n",
      "  Epoch [46/150], Batch [310/313], Loss: 0.2152\n",
      "  Validation Accuracy after Epoch 46: 0.8629\n",
      "  Epoch [47/150], Batch [310/313], Loss: 0.1253\n",
      "  Validation Accuracy after Epoch 47: 0.8760\n",
      "  Epoch [48/150], Batch [310/313], Loss: 0.1773\n",
      "  Validation Accuracy after Epoch 48: 0.8648\n",
      "  Epoch [49/150], Batch [310/313], Loss: 0.2048\n",
      "  Validation Accuracy after Epoch 49: 0.8810\n",
      "  Epoch [50/150], Batch [310/313], Loss: 0.1522\n",
      "  Validation Accuracy after Epoch 50: 0.8658\n",
      "  Epoch [51/150], Batch [310/313], Loss: 0.1029\n",
      "  Validation Accuracy after Epoch 51: 0.8890\n",
      "  Epoch [52/150], Batch [310/313], Loss: 0.0675\n",
      "  Validation Accuracy after Epoch 52: 0.8799\n",
      "  Epoch [53/150], Batch [310/313], Loss: 0.1072\n",
      "  Validation Accuracy after Epoch 53: 0.8993\n",
      "  Epoch [54/150], Batch [310/313], Loss: 0.0958\n",
      "  Validation Accuracy after Epoch 54: 0.8979\n",
      "  Epoch [55/150], Batch [310/313], Loss: 0.1499\n",
      "  Validation Accuracy after Epoch 55: 0.8956\n",
      "  Epoch [56/150], Batch [310/313], Loss: 0.0586\n",
      "  Validation Accuracy after Epoch 56: 0.9032\n",
      "  Epoch [57/150], Batch [310/313], Loss: 0.1065\n",
      "  Validation Accuracy after Epoch 57: 0.9020\n",
      "  Epoch [58/150], Batch [310/313], Loss: 0.1081\n",
      "  Validation Accuracy after Epoch 58: 0.9026\n",
      "  Epoch [59/150], Batch [310/313], Loss: 0.0509\n",
      "  Validation Accuracy after Epoch 59: 0.9020\n",
      "  Epoch [60/150], Batch [310/313], Loss: 0.0475\n",
      "  Validation Accuracy after Epoch 60: 0.9043\n",
      "  Epoch [61/150], Batch [310/313], Loss: 0.0668\n",
      "  Validation Accuracy after Epoch 61: 0.9078\n",
      "  Epoch [62/150], Batch [310/313], Loss: 0.0226\n",
      "  Validation Accuracy after Epoch 62: 0.9072\n",
      "  Epoch [63/150], Batch [310/313], Loss: 0.0269\n",
      "  Validation Accuracy after Epoch 63: 0.9035\n",
      "  Epoch [64/150], Batch [310/313], Loss: 0.0891\n",
      "  Validation Accuracy after Epoch 64: 0.9011\n",
      "  Epoch [65/150], Batch [310/313], Loss: 0.0157\n",
      "  Validation Accuracy after Epoch 65: 0.9005\n",
      "  Epoch [66/150], Batch [310/313], Loss: 0.0727\n",
      "  Validation Accuracy after Epoch 66: 0.8951\n",
      "  Epoch [67/150], Batch [310/313], Loss: 0.0389\n",
      "  Validation Accuracy after Epoch 67: 0.8922\n",
      "  Epoch [68/150], Batch [310/313], Loss: 0.1062\n",
      "  Validation Accuracy after Epoch 68: 0.8922\n",
      "  Epoch [69/150], Batch [310/313], Loss: 0.0569\n",
      "  Validation Accuracy after Epoch 69: 0.8862\n",
      "  Epoch [70/150], Batch [310/313], Loss: 0.1345\n",
      "  Validation Accuracy after Epoch 70: 0.8891\n",
      "  Epoch [71/150], Batch [310/313], Loss: 0.0912\n",
      "  Validation Accuracy after Epoch 71: 0.8918\n",
      "  Epoch [72/150], Batch [310/313], Loss: 0.1009\n",
      "  Validation Accuracy after Epoch 72: 0.8793\n",
      "  Epoch [73/150], Batch [310/313], Loss: 0.0900\n",
      "  Validation Accuracy after Epoch 73: 0.8703\n",
      "  Epoch [74/150], Batch [310/313], Loss: 0.1329\n",
      "  Validation Accuracy after Epoch 74: 0.8833\n",
      "  Epoch [75/150], Batch [310/313], Loss: 0.0843\n",
      "  Validation Accuracy after Epoch 75: 0.8915\n",
      "  Epoch [76/150], Batch [310/313], Loss: 0.0491\n",
      "  Validation Accuracy after Epoch 76: 0.8971\n",
      "  Epoch [77/150], Batch [310/313], Loss: 0.0374\n",
      "  Validation Accuracy after Epoch 77: 0.9085\n",
      "  Epoch [78/150], Batch [310/313], Loss: 0.0400\n",
      "  Validation Accuracy after Epoch 78: 0.9055\n",
      "  Epoch [79/150], Batch [310/313], Loss: 0.0294\n",
      "  Validation Accuracy after Epoch 79: 0.9050\n",
      "  Epoch [80/150], Batch [310/313], Loss: 0.0626\n",
      "  Validation Accuracy after Epoch 80: 0.9025\n",
      "  Epoch [81/150], Batch [310/313], Loss: 0.0583\n",
      "  Validation Accuracy after Epoch 81: 0.9015\n",
      "  Epoch [82/150], Batch [310/313], Loss: 0.0496\n",
      "  Validation Accuracy after Epoch 82: 0.9036\n",
      "  Epoch [83/150], Batch [310/313], Loss: 0.0265\n",
      "  Validation Accuracy after Epoch 83: 0.9096\n",
      "  Epoch [84/150], Batch [310/313], Loss: 0.0205\n",
      "  Validation Accuracy after Epoch 84: 0.9080\n",
      "  Epoch [85/150], Batch [310/313], Loss: 0.0193\n",
      "  Validation Accuracy after Epoch 85: 0.9079\n",
      "  Epoch [86/150], Batch [310/313], Loss: 0.0305\n",
      "  Validation Accuracy after Epoch 86: 0.9082\n",
      "  Epoch [87/150], Batch [310/313], Loss: 0.0202\n",
      "  Validation Accuracy after Epoch 87: 0.9064\n",
      "  Epoch [88/150], Batch [310/313], Loss: 0.0027\n",
      "  Validation Accuracy after Epoch 88: 0.9058\n",
      "  Epoch [89/150], Batch [310/313], Loss: 0.0165\n",
      "  Validation Accuracy after Epoch 89: 0.8991\n",
      "  Epoch [90/150], Batch [310/313], Loss: 0.0281\n",
      "  Validation Accuracy after Epoch 90: 0.8998\n",
      "  Epoch [91/150], Batch [310/313], Loss: 0.0206\n",
      "  Validation Accuracy after Epoch 91: 0.8933\n",
      "  Epoch [92/150], Batch [310/313], Loss: 0.1479\n",
      "  Validation Accuracy after Epoch 92: 0.8822\n",
      "  Epoch [93/150], Batch [310/313], Loss: 0.0238\n",
      "  Validation Accuracy after Epoch 93: 0.8904\n",
      "  Epoch [94/150], Batch [310/313], Loss: 0.0572\n",
      "  Validation Accuracy after Epoch 94: 0.8916\n",
      "  Epoch [95/150], Batch [310/313], Loss: 0.0622\n",
      "  Validation Accuracy after Epoch 95: 0.8971\n",
      "  Epoch [96/150], Batch [310/313], Loss: 0.1688\n",
      "  Validation Accuracy after Epoch 96: 0.8961\n",
      "  Epoch [97/150], Batch [310/313], Loss: 0.0260\n",
      "  Validation Accuracy after Epoch 97: 0.8980\n",
      "  Epoch [98/150], Batch [310/313], Loss: 0.0599\n",
      "  Validation Accuracy after Epoch 98: 0.8985\n",
      "  Epoch [99/150], Batch [310/313], Loss: 0.0496\n",
      "  Validation Accuracy after Epoch 99: 0.8951\n",
      "  Epoch [100/150], Batch [310/313], Loss: 0.0227\n",
      "  Validation Accuracy after Epoch 100: 0.9071\n",
      "  Epoch [101/150], Batch [310/313], Loss: 0.0188\n",
      "  Validation Accuracy after Epoch 101: 0.9021\n",
      "  Epoch [102/150], Batch [310/313], Loss: 0.0742\n",
      "  Validation Accuracy after Epoch 102: 0.9063\n",
      "  Epoch [103/150], Batch [310/313], Loss: 0.0670\n",
      "  Validation Accuracy after Epoch 103: 0.9058\n",
      "  Epoch [104/150], Batch [310/313], Loss: 0.0193\n",
      "  Validation Accuracy after Epoch 104: 0.9100\n",
      "  Epoch [105/150], Batch [310/313], Loss: 0.0124\n",
      "  Validation Accuracy after Epoch 105: 0.9059\n",
      "  Epoch [106/150], Batch [310/313], Loss: 0.0087\n",
      "  Validation Accuracy after Epoch 106: 0.9091\n",
      "  Epoch [107/150], Batch [310/313], Loss: 0.0115\n",
      "  Validation Accuracy after Epoch 107: 0.9068\n",
      "  Epoch [108/150], Batch [310/313], Loss: 0.0026\n",
      "  Validation Accuracy after Epoch 108: 0.9051\n",
      "  Epoch [109/150], Batch [310/313], Loss: 0.0153\n",
      "  Validation Accuracy after Epoch 109: 0.9068\n",
      "  Epoch [110/150], Batch [310/313], Loss: 0.0022\n",
      "  Validation Accuracy after Epoch 110: 0.9036\n",
      "  Epoch [111/150], Batch [310/313], Loss: 0.0164\n",
      "  Validation Accuracy after Epoch 111: 0.9058\n",
      "  Epoch [112/150], Batch [310/313], Loss: 0.0322\n",
      "  Validation Accuracy after Epoch 112: 0.9059\n",
      "  Epoch [113/150], Batch [310/313], Loss: 0.0218\n",
      "  Validation Accuracy after Epoch 113: 0.9030\n",
      "  Epoch [114/150], Batch [310/313], Loss: 0.0317\n",
      "  Validation Accuracy after Epoch 114: 0.8980\n",
      "  Epoch [115/150], Batch [310/313], Loss: 0.0179\n",
      "  Validation Accuracy after Epoch 115: 0.8961\n",
      "  Epoch [116/150], Batch [310/313], Loss: 0.0400\n",
      "  Validation Accuracy after Epoch 116: 0.8957\n",
      "  Epoch [117/150], Batch [310/313], Loss: 0.0516\n",
      "  Validation Accuracy after Epoch 117: 0.8871\n",
      "  Epoch [118/150], Batch [310/313], Loss: 0.0203\n",
      "  Validation Accuracy after Epoch 118: 0.8952\n",
      "  Epoch [119/150], Batch [310/313], Loss: 0.0479\n",
      "  Validation Accuracy after Epoch 119: 0.8949\n",
      "  Epoch [120/150], Batch [310/313], Loss: 0.0091\n",
      "  Validation Accuracy after Epoch 120: 0.8954\n",
      "  Epoch [121/150], Batch [310/313], Loss: 0.0286\n",
      "  Validation Accuracy after Epoch 121: 0.8963\n",
      "  Epoch [122/150], Batch [310/313], Loss: 0.0691\n",
      "  Validation Accuracy after Epoch 122: 0.9010\n",
      "  Epoch [123/150], Batch [310/313], Loss: 0.0050\n",
      "  Validation Accuracy after Epoch 123: 0.9049\n",
      "  Epoch [124/150], Batch [310/313], Loss: 0.0142\n",
      "  Validation Accuracy after Epoch 124: 0.9081\n",
      "  Epoch [125/150], Batch [310/313], Loss: 0.0164\n",
      "  Validation Accuracy after Epoch 125: 0.9068\n",
      "  Epoch [126/150], Batch [310/313], Loss: 0.0245\n",
      "  Validation Accuracy after Epoch 126: 0.9032\n",
      "  Epoch [127/150], Batch [310/313], Loss: 0.0076\n",
      "  Validation Accuracy after Epoch 127: 0.9082\n",
      "  Epoch [128/150], Batch [310/313], Loss: 0.0203\n",
      "  Validation Accuracy after Epoch 128: 0.9097\n",
      "  Epoch [129/150], Batch [310/313], Loss: 0.0523\n",
      "  Validation Accuracy after Epoch 129: 0.9100\n",
      "  Epoch [130/150], Batch [310/313], Loss: 0.0097\n",
      "  Validation Accuracy after Epoch 130: 0.9052\n",
      "  Epoch [131/150], Batch [310/313], Loss: 0.0045\n",
      "  Validation Accuracy after Epoch 131: 0.9089\n",
      "  Epoch [132/150], Batch [310/313], Loss: 0.0290\n",
      "  Validation Accuracy after Epoch 132: 0.9058\n",
      "  Epoch [133/150], Batch [310/313], Loss: 0.0096\n",
      "  Validation Accuracy after Epoch 133: 0.9122\n",
      "  Epoch [134/150], Batch [310/313], Loss: 0.0163\n",
      "  Validation Accuracy after Epoch 134: 0.9104\n",
      "  Epoch [135/150], Batch [310/313], Loss: 0.0199\n",
      "  Validation Accuracy after Epoch 135: 0.9103\n",
      "  Epoch [136/150], Batch [310/313], Loss: 0.0317\n",
      "  Validation Accuracy after Epoch 136: 0.9043\n",
      "  Epoch [137/150], Batch [310/313], Loss: 0.0203\n",
      "  Validation Accuracy after Epoch 137: 0.9053\n",
      "  Epoch [138/150], Batch [310/313], Loss: 0.0097\n",
      "  Validation Accuracy after Epoch 138: 0.9010\n",
      "  Epoch [139/150], Batch [310/313], Loss: 0.1269\n",
      "  Validation Accuracy after Epoch 139: 0.9015\n",
      "  Epoch [140/150], Batch [310/313], Loss: 0.0146\n",
      "  Validation Accuracy after Epoch 140: 0.8993\n",
      "  Epoch [141/150], Batch [310/313], Loss: 0.0349\n",
      "  Validation Accuracy after Epoch 141: 0.8993\n",
      "  Epoch [142/150], Batch [310/313], Loss: 0.0027\n",
      "  Validation Accuracy after Epoch 142: 0.8971\n",
      "  Epoch [143/150], Batch [310/313], Loss: 0.0340\n",
      "  Validation Accuracy after Epoch 143: 0.9017\n",
      "  Epoch [144/150], Batch [310/313], Loss: 0.1049\n",
      "  Validation Accuracy after Epoch 144: 0.9016\n",
      "  Epoch [145/150], Batch [310/313], Loss: 0.0074\n",
      "  Validation Accuracy after Epoch 145: 0.9063\n",
      "  Epoch [146/150], Batch [310/313], Loss: 0.0114\n",
      "  Validation Accuracy after Epoch 146: 0.9078\n",
      "  Epoch [147/150], Batch [310/313], Loss: 0.0160\n",
      "  Validation Accuracy after Epoch 147: 0.9051\n",
      "  Epoch [148/150], Batch [310/313], Loss: 0.0140\n",
      "  Validation Accuracy after Epoch 148: 0.9072\n",
      "  Epoch [149/150], Batch [310/313], Loss: 0.0176\n",
      "  Validation Accuracy after Epoch 149: 0.9102\n",
      "  Epoch [150/150], Batch [310/313], Loss: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-09 23:16:20,008] Trial 0 finished with value: 0.9122 and parameters: {'batch_size': 128, 'optimizer_type': 'Adam', 'scheduler_type': 'CosineAnnealingLR', 'weight_decay': 0.0005, 'learning_rate': 0.0009039934625206852, 'h_flip': 0.6900074185944934, 'rotation': 0, 'eta_min': 2.8794734992728567e-07}. Best is trial 0 with value: 0.9122.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy after Epoch 150: 0.9098\n",
      "Trial 0 complete. Best Validation Accuracy: 0.9122\n",
      "\n",
      "Model checkpoint saved to checkpoints_study_2025-03-09_23-00-10/model_trial_0_val_acc_0.9122.pth\n",
      "--------------------------------------------------\n",
      "trial.number=1\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: OneCycleLR\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.0002633296693669444\n",
      "h_flip: 0.4549003559902508\n",
      "rotation: 17\n",
      "model_name: resnet18\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/150], Batch [310/313], Loss: 1.6078\n",
      "  Validation Accuracy after Epoch 1: 0.4221\n",
      "  Epoch [2/150], Batch [310/313], Loss: 1.2467\n",
      "  Validation Accuracy after Epoch 2: 0.5307\n",
      "  Epoch [3/150], Batch [310/313], Loss: 1.2627\n",
      "  Validation Accuracy after Epoch 3: 0.5555\n",
      "  Epoch [4/150], Batch [310/313], Loss: 0.9073\n",
      "  Validation Accuracy after Epoch 4: 0.6265\n",
      "  Epoch [5/150], Batch [310/313], Loss: 0.8654\n",
      "  Validation Accuracy after Epoch 5: 0.6455\n",
      "  Epoch [6/150], Batch [310/313], Loss: 0.8786\n",
      "  Validation Accuracy after Epoch 6: 0.6718\n",
      "  Epoch [7/150], Batch [310/313], Loss: 0.6814\n",
      "  Validation Accuracy after Epoch 7: 0.7092\n",
      "  Epoch [8/150], Batch [310/313], Loss: 0.8406\n",
      "  Validation Accuracy after Epoch 8: 0.7191\n",
      "  Epoch [9/150], Batch [310/313], Loss: 0.5766\n",
      "  Validation Accuracy after Epoch 9: 0.7417\n",
      "  Epoch [10/150], Batch [310/313], Loss: 0.6845\n",
      "  Validation Accuracy after Epoch 10: 0.7746\n",
      "  Epoch [11/150], Batch [310/313], Loss: 0.4376\n",
      "  Validation Accuracy after Epoch 11: 0.7622\n",
      "  Epoch [12/150], Batch [310/313], Loss: 0.5643\n",
      "  Validation Accuracy after Epoch 12: 0.7663\n",
      "  Epoch [13/150], Batch [310/313], Loss: 0.5861\n",
      "  Validation Accuracy after Epoch 13: 0.7734\n",
      "  Epoch [14/150], Batch [310/313], Loss: 0.6275\n",
      "  Validation Accuracy after Epoch 14: 0.7731\n",
      "  Epoch [15/150], Batch [310/313], Loss: 0.7174\n",
      "  Validation Accuracy after Epoch 15: 0.8003\n",
      "  Epoch [16/150], Batch [310/313], Loss: 0.6099\n",
      "  Validation Accuracy after Epoch 16: 0.7665\n",
      "  Epoch [17/150], Batch [310/313], Loss: 0.5207\n",
      "  Validation Accuracy after Epoch 17: 0.7345\n",
      "  Epoch [18/150], Batch [310/313], Loss: 0.4327\n",
      "  Validation Accuracy after Epoch 18: 0.7910\n",
      "  Epoch [19/150], Batch [310/313], Loss: 0.5911\n",
      "  Validation Accuracy after Epoch 19: 0.7626\n",
      "  Epoch [20/150], Batch [310/313], Loss: 0.4903\n",
      "  Validation Accuracy after Epoch 20: 0.7779\n",
      "  Epoch [21/150], Batch [310/313], Loss: 0.6820\n",
      "  Validation Accuracy after Epoch 21: 0.7816\n",
      "  Epoch [22/150], Batch [310/313], Loss: 0.6109\n",
      "  Validation Accuracy after Epoch 22: 0.7907\n",
      "  Epoch [23/150], Batch [310/313], Loss: 0.5215\n",
      "  Validation Accuracy after Epoch 23: 0.8088\n",
      "  Epoch [24/150], Batch [310/313], Loss: 0.5691\n",
      "  Validation Accuracy after Epoch 24: 0.7752\n",
      "  Epoch [25/150], Batch [310/313], Loss: 0.5108\n",
      "  Validation Accuracy after Epoch 25: 0.7923\n",
      "  Epoch [26/150], Batch [310/313], Loss: 0.4742\n",
      "  Validation Accuracy after Epoch 26: 0.7629\n",
      "  Epoch [27/150], Batch [310/313], Loss: 0.2779\n",
      "  Validation Accuracy after Epoch 27: 0.8003\n",
      "  Epoch [28/150], Batch [310/313], Loss: 0.4955\n",
      "  Validation Accuracy after Epoch 28: 0.7889\n",
      "  Epoch [29/150], Batch [310/313], Loss: 0.4746\n",
      "  Validation Accuracy after Epoch 29: 0.7848\n",
      "  Epoch [30/150], Batch [310/313], Loss: 0.5015\n",
      "  Validation Accuracy after Epoch 30: 0.8071\n",
      "  Epoch [31/150], Batch [310/313], Loss: 0.5311\n",
      "  Validation Accuracy after Epoch 31: 0.7922\n",
      "  Epoch [32/150], Batch [310/313], Loss: 0.3481\n",
      "  Validation Accuracy after Epoch 32: 0.8035\n",
      "  Epoch [33/150], Batch [310/313], Loss: 0.3897\n",
      "  Validation Accuracy after Epoch 33: 0.7807\n",
      "  Epoch [34/150], Batch [310/313], Loss: 0.4654\n",
      "  Validation Accuracy after Epoch 34: 0.7789\n",
      "  Epoch [35/150], Batch [310/313], Loss: 0.4402\n",
      "  Validation Accuracy after Epoch 35: 0.8128\n",
      "  Epoch [36/150], Batch [310/313], Loss: 0.5186\n",
      "  Validation Accuracy after Epoch 36: 0.8341\n",
      "  Epoch [37/150], Batch [310/313], Loss: 0.4250\n",
      "  Validation Accuracy after Epoch 37: 0.7935\n",
      "  Epoch [38/150], Batch [310/313], Loss: 0.4087\n",
      "  Validation Accuracy after Epoch 38: 0.8272\n",
      "  Epoch [39/150], Batch [310/313], Loss: 0.3245\n",
      "  Validation Accuracy after Epoch 39: 0.8363\n",
      "  Epoch [40/150], Batch [310/313], Loss: 0.4135\n",
      "  Validation Accuracy after Epoch 40: 0.8143\n",
      "  Epoch [41/150], Batch [310/313], Loss: 0.3992\n",
      "  Validation Accuracy after Epoch 41: 0.8134\n",
      "  Epoch [42/150], Batch [310/313], Loss: 0.3419\n",
      "  Validation Accuracy after Epoch 42: 0.8262\n",
      "  Epoch [43/150], Batch [310/313], Loss: 0.5594\n",
      "  Validation Accuracy after Epoch 43: 0.8238\n",
      "  Epoch [44/150], Batch [310/313], Loss: 0.2950\n",
      "  Validation Accuracy after Epoch 44: 0.8438\n",
      "  Epoch [45/150], Batch [310/313], Loss: 0.3867\n",
      "  Validation Accuracy after Epoch 45: 0.8359\n",
      "  Epoch [46/150], Batch [310/313], Loss: 0.3106\n",
      "  Validation Accuracy after Epoch 46: 0.8171\n",
      "  Epoch [47/150], Batch [310/313], Loss: 0.3727\n",
      "  Validation Accuracy after Epoch 47: 0.8392\n",
      "  Epoch [48/150], Batch [310/313], Loss: 0.3000\n",
      "  Validation Accuracy after Epoch 48: 0.8387\n",
      "  Epoch [49/150], Batch [310/313], Loss: 0.3648\n",
      "  Validation Accuracy after Epoch 49: 0.8419\n",
      "  Epoch [50/150], Batch [310/313], Loss: 0.4632\n",
      "  Validation Accuracy after Epoch 50: 0.8434\n",
      "  Epoch [51/150], Batch [310/313], Loss: 0.3936\n",
      "  Validation Accuracy after Epoch 51: 0.8426\n",
      "  Epoch [52/150], Batch [310/313], Loss: 0.3976\n",
      "  Validation Accuracy after Epoch 52: 0.8539\n",
      "  Epoch [53/150], Batch [310/313], Loss: 0.2764\n",
      "  Validation Accuracy after Epoch 53: 0.8562\n",
      "  Epoch [54/150], Batch [310/313], Loss: 0.4416\n",
      "  Validation Accuracy after Epoch 54: 0.8521\n",
      "  Epoch [55/150], Batch [310/313], Loss: 0.4372\n",
      "  Validation Accuracy after Epoch 55: 0.8484\n",
      "  Epoch [56/150], Batch [310/313], Loss: 0.3259\n",
      "  Validation Accuracy after Epoch 56: 0.8444\n",
      "  Epoch [57/150], Batch [310/313], Loss: 0.4832\n",
      "  Validation Accuracy after Epoch 57: 0.8592\n",
      "  Epoch [58/150], Batch [310/313], Loss: 0.2586\n",
      "  Validation Accuracy after Epoch 58: 0.8540\n",
      "  Epoch [59/150], Batch [310/313], Loss: 0.1737\n",
      "  Validation Accuracy after Epoch 59: 0.8675\n",
      "  Epoch [60/150], Batch [310/313], Loss: 0.2675\n",
      "  Validation Accuracy after Epoch 60: 0.8522\n",
      "  Epoch [61/150], Batch [310/313], Loss: 0.1916\n",
      "  Validation Accuracy after Epoch 61: 0.8540\n",
      "  Epoch [62/150], Batch [310/313], Loss: 0.1856\n",
      "  Validation Accuracy after Epoch 62: 0.8630\n",
      "  Epoch [63/150], Batch [310/313], Loss: 0.2118\n",
      "  Validation Accuracy after Epoch 63: 0.8578\n",
      "  Epoch [64/150], Batch [310/313], Loss: 0.3387\n",
      "  Validation Accuracy after Epoch 64: 0.8697\n",
      "  Epoch [65/150], Batch [310/313], Loss: 0.2626\n",
      "  Validation Accuracy after Epoch 65: 0.8597\n",
      "  Epoch [66/150], Batch [310/313], Loss: 0.3572\n",
      "  Validation Accuracy after Epoch 66: 0.8614\n",
      "  Epoch [67/150], Batch [310/313], Loss: 0.2426\n",
      "  Validation Accuracy after Epoch 67: 0.8696\n",
      "  Epoch [68/150], Batch [310/313], Loss: 0.2678\n",
      "  Validation Accuracy after Epoch 68: 0.8727\n",
      "  Epoch [69/150], Batch [310/313], Loss: 0.1594\n",
      "  Validation Accuracy after Epoch 69: 0.8682\n",
      "  Epoch [70/150], Batch [310/313], Loss: 0.2151\n",
      "  Validation Accuracy after Epoch 70: 0.8738\n",
      "  Epoch [71/150], Batch [310/313], Loss: 0.2319\n",
      "  Validation Accuracy after Epoch 71: 0.8667\n",
      "  Epoch [72/150], Batch [310/313], Loss: 0.1423\n",
      "  Validation Accuracy after Epoch 72: 0.8678\n",
      "  Epoch [73/150], Batch [310/313], Loss: 0.1916\n",
      "  Validation Accuracy after Epoch 73: 0.8671\n",
      "  Epoch [74/150], Batch [310/313], Loss: 0.2317\n",
      "  Validation Accuracy after Epoch 74: 0.8673\n",
      "  Epoch [75/150], Batch [310/313], Loss: 0.2624\n",
      "  Validation Accuracy after Epoch 75: 0.8743\n",
      "  Epoch [76/150], Batch [310/313], Loss: 0.2357\n",
      "  Validation Accuracy after Epoch 76: 0.8690\n",
      "  Epoch [77/150], Batch [310/313], Loss: 0.1122\n",
      "  Validation Accuracy after Epoch 77: 0.8799\n",
      "  Epoch [78/150], Batch [310/313], Loss: 0.1290\n",
      "  Validation Accuracy after Epoch 78: 0.8809\n",
      "  Epoch [79/150], Batch [310/313], Loss: 0.3952\n",
      "  Validation Accuracy after Epoch 79: 0.8806\n",
      "  Epoch [80/150], Batch [310/313], Loss: 0.1383\n",
      "  Validation Accuracy after Epoch 80: 0.8800\n",
      "  Epoch [81/150], Batch [310/313], Loss: 0.1006\n",
      "  Validation Accuracy after Epoch 81: 0.8787\n",
      "  Epoch [82/150], Batch [310/313], Loss: 0.1735\n",
      "  Validation Accuracy after Epoch 82: 0.8822\n",
      "  Epoch [83/150], Batch [310/313], Loss: 0.1788\n",
      "  Validation Accuracy after Epoch 83: 0.8846\n",
      "  Epoch [84/150], Batch [310/313], Loss: 0.1816\n",
      "  Validation Accuracy after Epoch 84: 0.8858\n",
      "  Epoch [85/150], Batch [310/313], Loss: 0.1435\n",
      "  Validation Accuracy after Epoch 85: 0.8883\n",
      "  Epoch [86/150], Batch [310/313], Loss: 0.0593\n",
      "  Validation Accuracy after Epoch 86: 0.8858\n",
      "  Epoch [87/150], Batch [310/313], Loss: 0.1914\n",
      "  Validation Accuracy after Epoch 87: 0.8796\n",
      "  Epoch [88/150], Batch [310/313], Loss: 0.0966\n",
      "  Validation Accuracy after Epoch 88: 0.8925\n",
      "  Epoch [89/150], Batch [310/313], Loss: 0.0761\n",
      "  Validation Accuracy after Epoch 89: 0.8806\n",
      "  Epoch [90/150], Batch [310/313], Loss: 0.0860\n",
      "  Validation Accuracy after Epoch 90: 0.8767\n",
      "  Epoch [91/150], Batch [310/313], Loss: 0.1177\n",
      "  Validation Accuracy after Epoch 91: 0.8891\n",
      "  Epoch [92/150], Batch [310/313], Loss: 0.1421\n",
      "  Validation Accuracy after Epoch 92: 0.8879\n",
      "  Epoch [93/150], Batch [310/313], Loss: 0.1206\n",
      "  Validation Accuracy after Epoch 93: 0.8887\n",
      "  Epoch [94/150], Batch [310/313], Loss: 0.1540\n",
      "  Validation Accuracy after Epoch 94: 0.8863\n",
      "  Epoch [95/150], Batch [310/313], Loss: 0.1076\n",
      "  Validation Accuracy after Epoch 95: 0.8917\n",
      "  Epoch [96/150], Batch [310/313], Loss: 0.0961\n",
      "  Validation Accuracy after Epoch 96: 0.8902\n",
      "  Epoch [97/150], Batch [310/313], Loss: 0.0980\n",
      "  Validation Accuracy after Epoch 97: 0.8868\n",
      "  Epoch [98/150], Batch [310/313], Loss: 0.0404\n",
      "  Validation Accuracy after Epoch 98: 0.8933\n",
      "  Epoch [99/150], Batch [310/313], Loss: 0.0840\n",
      "  Validation Accuracy after Epoch 99: 0.8892\n",
      "  Epoch [100/150], Batch [310/313], Loss: 0.0514\n",
      "  Validation Accuracy after Epoch 100: 0.8939\n",
      "  Epoch [101/150], Batch [310/313], Loss: 0.0826\n",
      "  Validation Accuracy after Epoch 101: 0.8980\n",
      "  Epoch [102/150], Batch [310/313], Loss: 0.0742\n",
      "  Validation Accuracy after Epoch 102: 0.8957\n",
      "  Epoch [103/150], Batch [310/313], Loss: 0.1321\n",
      "  Validation Accuracy after Epoch 103: 0.8940\n",
      "  Epoch [104/150], Batch [310/313], Loss: 0.1054\n",
      "  Validation Accuracy after Epoch 104: 0.8988\n",
      "  Epoch [105/150], Batch [310/313], Loss: 0.0134\n",
      "  Validation Accuracy after Epoch 105: 0.8966\n",
      "  Epoch [106/150], Batch [310/313], Loss: 0.0959\n",
      "  Validation Accuracy after Epoch 106: 0.8949\n",
      "  Epoch [107/150], Batch [310/313], Loss: 0.0389\n",
      "  Validation Accuracy after Epoch 107: 0.8990\n",
      "  Epoch [108/150], Batch [310/313], Loss: 0.0593\n",
      "  Validation Accuracy after Epoch 108: 0.8998\n",
      "  Epoch [109/150], Batch [310/313], Loss: 0.0673\n",
      "  Validation Accuracy after Epoch 109: 0.8992\n",
      "  Epoch [110/150], Batch [310/313], Loss: 0.0215\n",
      "  Validation Accuracy after Epoch 110: 0.9013\n",
      "  Epoch [111/150], Batch [310/313], Loss: 0.0479\n",
      "  Validation Accuracy after Epoch 111: 0.9033\n",
      "  Epoch [112/150], Batch [310/313], Loss: 0.0261\n",
      "  Validation Accuracy after Epoch 112: 0.9047\n",
      "  Epoch [113/150], Batch [310/313], Loss: 0.0368\n",
      "  Validation Accuracy after Epoch 113: 0.9041\n",
      "  Epoch [114/150], Batch [310/313], Loss: 0.0418\n",
      "  Validation Accuracy after Epoch 114: 0.9005\n",
      "  Epoch [115/150], Batch [310/313], Loss: 0.1313\n",
      "  Validation Accuracy after Epoch 115: 0.8986\n",
      "  Epoch [116/150], Batch [310/313], Loss: 0.0502\n",
      "  Validation Accuracy after Epoch 116: 0.9027\n",
      "  Epoch [117/150], Batch [310/313], Loss: 0.0364\n",
      "  Validation Accuracy after Epoch 117: 0.9023\n",
      "  Epoch [118/150], Batch [310/313], Loss: 0.0072\n",
      "  Validation Accuracy after Epoch 118: 0.9005\n",
      "  Epoch [119/150], Batch [310/313], Loss: 0.0666\n",
      "  Validation Accuracy after Epoch 119: 0.9060\n",
      "  Epoch [120/150], Batch [310/313], Loss: 0.0297\n",
      "  Validation Accuracy after Epoch 120: 0.9043\n",
      "  Epoch [121/150], Batch [310/313], Loss: 0.0506\n",
      "  Validation Accuracy after Epoch 121: 0.9045\n",
      "  Epoch [122/150], Batch [310/313], Loss: 0.0749\n",
      "  Validation Accuracy after Epoch 122: 0.9016\n",
      "  Epoch [123/150], Batch [310/313], Loss: 0.0125\n",
      "  Validation Accuracy after Epoch 123: 0.9076\n",
      "  Epoch [124/150], Batch [310/313], Loss: 0.0369\n",
      "  Validation Accuracy after Epoch 124: 0.9015\n",
      "  Epoch [125/150], Batch [310/313], Loss: 0.0099\n",
      "  Validation Accuracy after Epoch 125: 0.9027\n",
      "  Epoch [126/150], Batch [310/313], Loss: 0.0301\n",
      "  Validation Accuracy after Epoch 126: 0.9090\n",
      "  Epoch [127/150], Batch [310/313], Loss: 0.0679\n",
      "  Validation Accuracy after Epoch 127: 0.9038\n",
      "  Epoch [128/150], Batch [310/313], Loss: 0.0290\n",
      "  Validation Accuracy after Epoch 128: 0.9067\n",
      "  Epoch [129/150], Batch [310/313], Loss: 0.0221\n",
      "  Validation Accuracy after Epoch 129: 0.9066\n",
      "  Epoch [130/150], Batch [310/313], Loss: 0.0120\n",
      "  Validation Accuracy after Epoch 130: 0.9095\n",
      "  Epoch [131/150], Batch [310/313], Loss: 0.0553\n",
      "  Validation Accuracy after Epoch 131: 0.9073\n",
      "  Epoch [132/150], Batch [310/313], Loss: 0.0371\n",
      "  Validation Accuracy after Epoch 132: 0.9064\n",
      "  Epoch [133/150], Batch [310/313], Loss: 0.0013\n",
      "  Validation Accuracy after Epoch 133: 0.9124\n",
      "  Epoch [134/150], Batch [310/313], Loss: 0.0189\n",
      "  Validation Accuracy after Epoch 134: 0.9083\n",
      "  Epoch [135/150], Batch [310/313], Loss: 0.0416\n",
      "  Validation Accuracy after Epoch 135: 0.9075\n",
      "  Epoch [136/150], Batch [310/313], Loss: 0.0319\n",
      "  Validation Accuracy after Epoch 136: 0.9079\n",
      "  Epoch [137/150], Batch [310/313], Loss: 0.0019\n",
      "  Validation Accuracy after Epoch 137: 0.9085\n",
      "  Epoch [138/150], Batch [310/313], Loss: 0.0030\n",
      "  Validation Accuracy after Epoch 138: 0.9103\n",
      "  Epoch [139/150], Batch [310/313], Loss: 0.0573\n",
      "  Validation Accuracy after Epoch 139: 0.9078\n",
      "  Epoch [140/150], Batch [310/313], Loss: 0.0108\n",
      "  Validation Accuracy after Epoch 140: 0.9121\n",
      "  Epoch [141/150], Batch [310/313], Loss: 0.0460\n",
      "  Validation Accuracy after Epoch 141: 0.9091\n",
      "  Epoch [142/150], Batch [310/313], Loss: 0.0015\n",
      "  Validation Accuracy after Epoch 142: 0.9071\n",
      "  Epoch [143/150], Batch [310/313], Loss: 0.0067\n",
      "  Validation Accuracy after Epoch 143: 0.9090\n",
      "  Epoch [144/150], Batch [310/313], Loss: 0.0188\n",
      "  Validation Accuracy after Epoch 144: 0.9056\n",
      "  Epoch [145/150], Batch [310/313], Loss: 0.0056\n",
      "  Validation Accuracy after Epoch 145: 0.9098\n",
      "  Epoch [146/150], Batch [310/313], Loss: 0.0213\n",
      "  Validation Accuracy after Epoch 146: 0.9128\n",
      "  Epoch [147/150], Batch [310/313], Loss: 0.0403\n",
      "  Validation Accuracy after Epoch 147: 0.9079\n",
      "  Epoch [148/150], Batch [310/313], Loss: 0.0017\n",
      "  Validation Accuracy after Epoch 148: 0.9098\n",
      "  Epoch [149/150], Batch [310/313], Loss: 0.0009\n",
      "  Validation Accuracy after Epoch 149: 0.9084\n",
      "  Epoch [150/150], Batch [310/313], Loss: 0.0020\n",
      "  Validation Accuracy after Epoch 150: 0.9096\n",
      "Trial 1 complete. Best Validation Accuracy: 0.9128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-09 23:33:41,183] Trial 1 finished with value: 0.9128 and parameters: {'batch_size': 128, 'optimizer_type': 'Adam', 'scheduler_type': 'OneCycleLR', 'weight_decay': 0.0001, 'learning_rate': 0.0002633296693669444, 'h_flip': 0.4549003559902508, 'rotation': 17}. Best is trial 1 with value: 0.9128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved to checkpoints_study_2025-03-09_23-00-10/model_trial_1_val_acc_0.9128.pth\n",
      "Best trial: 1\n",
      "Best hyperparameters: {'batch_size': 128, 'optimizer_type': 'Adam', 'scheduler_type': 'OneCycleLR', 'weight_decay': 0.0001, 'learning_rate': 0.0002633296693669444, 'h_flip': 0.4549003559902508, 'rotation': 17}\n",
      "Best validation accuracy: 0.9128\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "study_name = f\"study_{timestamp}\"    \n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=study_name)\n",
    "study.optimize(objective, n_trials=2)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model.to(device)\n",
    "\n",
    "# Load the latest checkpoint\n",
    "checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "# checkpoint_dir = \"checkpoints_study_2025-03-09_12-42-46\"\n",
    "checkpoint = torch.load(f\"{checkpoint_dir}/model_trial_1_val_acc_0.9128.pth\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9237\n"
     ]
    }
   ],
   "source": [
    "from trainer import evaluate_model\n",
    "from data_loader import get_test_dataloader\n",
    "\n",
    "test_loader = get_test_dataloader()\n",
    "acc = evaluate_model(model, test_loader, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_kaggle_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission file saved.\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file with test data\n",
    "kaggle_test_loader = get_kaggle_test_dataloader()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in kaggle_test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67.3k/67.3k [00:00<00:00, 259kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Deep Learning Spring 2025: CIFAR 10 classification"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import kaggle\n",
    "# kaggle.api.competition_submit(\n",
    "#     file_name=\"submission.csv\",\n",
    "#     message=\"0.9237\",\n",
    "#     competition=competition_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk8i7jiGjSg0feqDTW0l2u",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
