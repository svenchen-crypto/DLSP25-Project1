{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIugLjz-A2Qd"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import optuna\n",
    "from torch.optim import lr_scheduler # StepLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "from data_loader import get_cifar10_dataloaders\n",
    "from trainer import train_model\n",
    "from model import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4z7iY1pkk2C"
   },
   "source": [
    "Configure the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e3wMn_41kd5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the total number of trainable parameters\n",
    "def num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4903242"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_study_details(checkpoint_dir, trial_num, trial_details):\n",
    "    file_path = os.path.join(checkpoint_dir, \"study_details.json\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump({}, f, indent=4)\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        study_details = json.load(f)\n",
    "\n",
    "    study_details[str(trial_num)] = trial_details\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(study_details, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    study_name = trial.study.study_name\n",
    "    checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True) # Create a directory for checkpoints if it doesn't exist\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    num_epochs = 150 # trial.suggest_int(\"num_epochs\", 20, 35)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128]) # Rmed: 256\n",
    "    optimizer_type = trial.suggest_categorical(\"optimizer_type\", [\"Adam\", \"SGD\"]) # Rmed: RMSprop\n",
    "    scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"ReduceLROnPlateau\", \"OneCycleLR\"]) # Rmed: StepLR\n",
    "\n",
    "    optimizer_map = {\n",
    "        \"Adam\": optim.AdamW,\n",
    "        \"SGD\": optim.SGD,\n",
    "        \"RMSprop\": optim.RMSprop\n",
    "    }\n",
    "\n",
    "    scheduler_map = {\n",
    "        \"StepLR\": lr_scheduler.StepLR,\n",
    "        \"CosineAnnealingLR\": lr_scheduler.CosineAnnealingLR,\n",
    "        \"ReduceLROnPlateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "        \"OneCycleLR\": lr_scheduler.OneCycleLR\n",
    "    }\n",
    "    \n",
    "    optimizer_params = {\n",
    "        \"weight_decay\": trial.suggest_categorical(\"weight_decay\", [1e-4, 5e-4])\n",
    "    }\n",
    "    \n",
    "    if optimizer_type == \"SGD\":\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 0.01, 0.05, log=True)\n",
    "        optimizer_params[\"momentum\"] = 0.9 # trial.suggest_float(\"momentum\", 0.8, 0.9)\n",
    "        optimizer_params[\"nesterov\"] = True #bool(trial.suggest_categorical(\"nesterov\", [0, 1]))\n",
    "        optimizer_params[\"weight_decay\"] = 5e-4\n",
    "    else:\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 0.0001, 0.001, log=True)\n",
    "        optimizer_params[\"weight_decay\"] = 1e-4\n",
    "        \n",
    "    # Suggest data transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(trial.suggest_float(\"h_flip\", 0.0, 1.0)),\n",
    "        transforms.RandomRotation(trial.suggest_int(\"rotation\", 0, 30)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "    ])\n",
    "    \n",
    "    train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "        transform,\n",
    "        subset_percent=1, \n",
    "        valid_size=0.1,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    scheduler_params = {}\n",
    "    if scheduler_type == \"StepLR\":\n",
    "        scheduler_params[\"step_size\"] = trial.suggest_int(\"step_size\", 5, 20)\n",
    "        scheduler_params[\"gamma\"] = trial.suggest_float(\"gamma\", 0.1, 0.9)\n",
    "    elif scheduler_type == \"CosineAnnealingLR\":\n",
    "        scheduler_params[\"T_max\"] = num_epochs #trial.suggest_int(\"T_max\", 10, 50)\n",
    "        scheduler_params[\"eta_min\"] = trial.suggest_float(\"eta_min\", 0.0, 1e-6)\n",
    "    elif scheduler_type == \"ReduceLROnPlateau\":\n",
    "        scheduler_params[\"factor\"] = trial.suggest_float(\"factor\", 0.1, 0.9)\n",
    "        scheduler_params[\"patience\"] = trial.suggest_int(\"patience\", 2, 10)\n",
    "        scheduler_params[\"mode\"] = \"min\"\n",
    "    elif scheduler_type == \"OneCycleLR\":\n",
    "        scheduler_params[\"max_lr\"] = 0.1\n",
    "        scheduler_params[\"steps_per_epoch\"] = len(train_loader)\n",
    "        scheduler_params[\"epochs\"] = num_epochs\n",
    "\n",
    "    # Define model\n",
    "    model = ResNet18()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    trial_details = trial.params.copy()\n",
    "    trial_details[\"model_name\"] =  \"resnet18\"\n",
    "    trial_details[\"trainable_parameters\"] = num_params(model)\n",
    "    \n",
    "    # Print trial details\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{trial.number=}\")\n",
    "    for param, val in trial_details.items():\n",
    "        print(f\"{param}: {val}\")\n",
    "    print(\"- \" * 25)\n",
    "    update_study_details(checkpoint_dir, trial.number, trial_details)\n",
    "\n",
    "    optimizer = optimizer_map[optimizer_type](model.parameters(), **optimizer_params)\n",
    "    scheduler = scheduler_map[scheduler_type](optimizer, **scheduler_params)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        trial, model, train_loader, criterion, optimizer, \n",
    "        valid_loader=valid_loader, num_epochs=num_epochs, device=device,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    # Checkpoint the model with the best validation accuracy\n",
    "    model_filename = f\"model_trial_{trial.number}_val_acc_{best_val_accuracy:.4f}.pth\"\n",
    "    model_path = os.path.join(checkpoint_dir, model_filename)\n",
    "    \n",
    "    # Save the model state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model checkpoint saved to {model_path}\")\n",
    "    trial_details[\"best_val_accuracy\"] = best_val_accuracy\n",
    "    trial_details[\"checkpoint_path\"] = model_path\n",
    "    update_study_details(checkpoint_dir, trial.number, trial_details)\n",
    "    \n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 02:34:32,794] A new study created in memory with name: study_2025-03-10_02-34-32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=0\n",
      "batch_size: 128\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.023700108124443908\n",
      "h_flip: 0.12736253958494903\n",
      "rotation: 5\n",
      "model_name: resnet18\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/150], Batch [350/352], Train Acc: 0.3631 Loss: 1.5053\n",
      "  Validation Accuracy after Epoch 1: 0.4744\n",
      "  Epoch [2/150], Batch [350/352], Train Acc: 0.5320 Loss: 1.2707\n",
      "  Validation Accuracy after Epoch 2: 0.5728\n",
      "  Epoch [3/150], Batch [350/352], Train Acc: 0.6074 Loss: 1.1254\n",
      "  Validation Accuracy after Epoch 3: 0.6068\n",
      "  Epoch [4/150], Batch [350/352], Train Acc: 0.6490 Loss: 0.8709\n",
      "  Validation Accuracy after Epoch 4: 0.6664\n",
      "  Epoch [5/150], Batch [350/352], Train Acc: 0.6802 Loss: 0.7314\n",
      "  Validation Accuracy after Epoch 5: 0.6908\n",
      "  Epoch [6/150], Batch [350/352], Train Acc: 0.7068 Loss: 0.7927\n",
      "  Validation Accuracy after Epoch 6: 0.7030\n",
      "  Epoch [7/150], Batch [350/352], Train Acc: 0.7297 Loss: 0.6819\n",
      "  Validation Accuracy after Epoch 7: 0.7090\n",
      "  Epoch [8/150], Batch [350/352], Train Acc: 0.7441 Loss: 0.6547\n",
      "  Validation Accuracy after Epoch 8: 0.7428\n",
      "  Epoch [9/150], Batch [350/352], Train Acc: 0.7591 Loss: 0.7012\n",
      "  Validation Accuracy after Epoch 9: 0.7480\n",
      "  Epoch [10/150], Batch [350/352], Train Acc: 0.7681 Loss: 0.6796\n",
      "  Validation Accuracy after Epoch 10: 0.7134\n",
      "  Epoch [11/150], Batch [350/352], Train Acc: 0.7824 Loss: 0.5020\n",
      "  Validation Accuracy after Epoch 11: 0.7392\n",
      "  Epoch [12/150], Batch [350/352], Train Acc: 0.7911 Loss: 0.6882\n",
      "  Validation Accuracy after Epoch 12: 0.7730\n",
      "  Epoch [13/150], Batch [350/352], Train Acc: 0.7976 Loss: 0.6655\n",
      "  Validation Accuracy after Epoch 13: 0.7758\n",
      "  Epoch [14/150], Batch [350/352], Train Acc: 0.8039 Loss: 0.5291\n",
      "  Validation Accuracy after Epoch 14: 0.7744\n",
      "  Epoch [15/150], Batch [350/352], Train Acc: 0.8126 Loss: 0.6184\n",
      "  Validation Accuracy after Epoch 15: 0.7950\n",
      "  Epoch [16/150], Batch [350/352], Train Acc: 0.8172 Loss: 0.5526\n",
      "  Validation Accuracy after Epoch 16: 0.7988\n",
      "  Epoch [17/150], Batch [350/352], Train Acc: 0.8202 Loss: 0.5600\n",
      "  Validation Accuracy after Epoch 17: 0.7778\n",
      "  Epoch [18/150], Batch [350/352], Train Acc: 0.8290 Loss: 0.4753\n",
      "  Validation Accuracy after Epoch 18: 0.8230\n",
      "  Epoch [19/150], Batch [350/352], Train Acc: 0.8330 Loss: 0.5662\n",
      "  Validation Accuracy after Epoch 19: 0.8048\n",
      "  Epoch [20/150], Batch [350/352], Train Acc: 0.8340 Loss: 0.2998\n",
      "  Validation Accuracy after Epoch 20: 0.8154\n",
      "  Epoch [21/150], Batch [350/352], Train Acc: 0.8373 Loss: 0.5786\n",
      "  Validation Accuracy after Epoch 21: 0.8268\n",
      "  Epoch [22/150], Batch [350/352], Train Acc: 0.8412 Loss: 0.5602\n",
      "  Validation Accuracy after Epoch 22: 0.8096\n",
      "  Epoch [23/150], Batch [350/352], Train Acc: 0.8414 Loss: 0.4113\n",
      "  Validation Accuracy after Epoch 23: 0.8208\n",
      "  Epoch [24/150], Batch [350/352], Train Acc: 0.8426 Loss: 0.5148\n",
      "  Validation Accuracy after Epoch 24: 0.8268\n",
      "  Epoch [25/150], Batch [350/352], Train Acc: 0.8446 Loss: 0.5148\n",
      "  Validation Accuracy after Epoch 25: 0.7888\n",
      "  Epoch [26/150], Batch [350/352], Train Acc: 0.8440 Loss: 0.4012\n",
      "  Validation Accuracy after Epoch 26: 0.7862\n",
      "  Epoch [27/150], Batch [350/352], Train Acc: 0.8456 Loss: 0.5653\n",
      "  Validation Accuracy after Epoch 27: 0.8156\n",
      "  Epoch [28/150], Batch [350/352], Train Acc: 0.8469 Loss: 0.4405\n",
      "  Validation Accuracy after Epoch 28: 0.7942\n",
      "  Epoch [29/150], Batch [350/352], Train Acc: 0.8456 Loss: 0.5513\n",
      "  Validation Accuracy after Epoch 29: 0.8014\n",
      "  Epoch [30/150], Batch [350/352], Train Acc: 0.8466 Loss: 0.4715\n",
      "  Validation Accuracy after Epoch 30: 0.7716\n",
      "  Epoch [31/150], Batch [350/352], Train Acc: 0.8481 Loss: 0.3710\n",
      "  Validation Accuracy after Epoch 31: 0.8206\n",
      "  Epoch [32/150], Batch [350/352], Train Acc: 0.8502 Loss: 0.5067\n",
      "  Validation Accuracy after Epoch 32: 0.8186\n",
      "  Epoch [33/150], Batch [350/352], Train Acc: 0.8475 Loss: 0.3995\n",
      "  Validation Accuracy after Epoch 33: 0.8102\n",
      "  Epoch [34/150], Batch [350/352], Train Acc: 0.8491 Loss: 0.3027\n",
      "  Validation Accuracy after Epoch 34: 0.7650\n",
      "  Epoch [35/150], Batch [350/352], Train Acc: 0.8469 Loss: 0.5005\n",
      "  Validation Accuracy after Epoch 35: 0.8146\n",
      "  Epoch [36/150], Batch [350/352], Train Acc: 0.8503 Loss: 0.4021\n",
      "  Validation Accuracy after Epoch 36: 0.8078\n",
      "  Epoch [37/150], Batch [350/352], Train Acc: 0.8510 Loss: 0.4972\n",
      "  Validation Accuracy after Epoch 37: 0.7676\n",
      "  Epoch [38/150], Batch [350/352], Train Acc: 0.8514 Loss: 0.4176\n",
      "  Validation Accuracy after Epoch 38: 0.8220\n",
      "  Epoch [39/150], Batch [350/352], Train Acc: 0.8495 Loss: 0.3255\n",
      "  Validation Accuracy after Epoch 39: 0.7854\n",
      "  Epoch [40/150], Batch [350/352], Train Acc: 0.8501 Loss: 0.6177\n",
      "  Validation Accuracy after Epoch 40: 0.7948\n",
      "  Epoch [41/150], Batch [350/352], Train Acc: 0.8546 Loss: 0.4208\n",
      "  Validation Accuracy after Epoch 41: 0.7930\n",
      "  Epoch [42/150], Batch [350/352], Train Acc: 0.8517 Loss: 0.4480\n",
      "  Validation Accuracy after Epoch 42: 0.8154\n",
      "  Epoch [43/150], Batch [350/352], Train Acc: 0.8531 Loss: 0.3672\n",
      "  Validation Accuracy after Epoch 43: 0.7978\n",
      "  Epoch [44/150], Batch [350/352], Train Acc: 0.8548 Loss: 0.4117\n",
      "  Validation Accuracy after Epoch 44: 0.8080\n",
      "  Epoch [45/150], Batch [350/352], Train Acc: 0.8555 Loss: 0.3081\n",
      "  Validation Accuracy after Epoch 45: 0.7864\n",
      "  Epoch [46/150], Batch [350/352], Train Acc: 0.8571 Loss: 0.3886\n",
      "  Validation Accuracy after Epoch 46: 0.7924\n",
      "  Epoch [47/150], Batch [350/352], Train Acc: 0.8566 Loss: 0.4402\n",
      "  Validation Accuracy after Epoch 47: 0.8056\n",
      "  Epoch [48/150], Batch [350/352], Train Acc: 0.8555 Loss: 0.4508\n",
      "  Validation Accuracy after Epoch 48: 0.8174\n",
      "  Epoch [49/150], Batch [350/352], Train Acc: 0.8559 Loss: 0.4437\n",
      "  Validation Accuracy after Epoch 49: 0.7552\n",
      "  Epoch [50/150], Batch [350/352], Train Acc: 0.8572 Loss: 0.4073\n",
      "  Validation Accuracy after Epoch 50: 0.8258\n",
      "  Epoch [51/150], Batch [350/352], Train Acc: 0.8565 Loss: 0.4384\n",
      "  Validation Accuracy after Epoch 51: 0.8214\n",
      "  Epoch [52/150], Batch [350/352], Train Acc: 0.8582 Loss: 0.2976\n",
      "  Validation Accuracy after Epoch 52: 0.8306\n",
      "  Epoch [53/150], Batch [350/352], Train Acc: 0.8584 Loss: 0.4407\n",
      "  Validation Accuracy after Epoch 53: 0.8188\n",
      "  Epoch [54/150], Batch [350/352], Train Acc: 0.8585 Loss: 0.2969\n",
      "  Validation Accuracy after Epoch 54: 0.7632\n",
      "  Epoch [55/150], Batch [350/352], Train Acc: 0.8565 Loss: 0.4192\n",
      "  Validation Accuracy after Epoch 55: 0.7612\n",
      "  Epoch [56/150], Batch [350/352], Train Acc: 0.8611 Loss: 0.3816\n",
      "  Validation Accuracy after Epoch 56: 0.8210\n",
      "  Epoch [57/150], Batch [350/352], Train Acc: 0.8608 Loss: 0.3390\n",
      "  Validation Accuracy after Epoch 57: 0.8126\n",
      "  Epoch [58/150], Batch [350/352], Train Acc: 0.8603 Loss: 0.3609\n",
      "  Validation Accuracy after Epoch 58: 0.8038\n",
      "  Epoch [59/150], Batch [350/352], Train Acc: 0.8590 Loss: 0.3120\n",
      "  Validation Accuracy after Epoch 59: 0.8158\n",
      "  Epoch [60/150], Batch [350/352], Train Acc: 0.8604 Loss: 0.4181\n",
      "  Validation Accuracy after Epoch 60: 0.8404\n",
      "  Epoch [61/150], Batch [350/352], Train Acc: 0.8614 Loss: 0.4051\n",
      "  Validation Accuracy after Epoch 61: 0.8302\n",
      "  Epoch [62/150], Batch [350/352], Train Acc: 0.8604 Loss: 0.3938\n",
      "  Validation Accuracy after Epoch 62: 0.8420\n",
      "  Epoch [63/150], Batch [350/352], Train Acc: 0.8644 Loss: 0.4566\n",
      "  Validation Accuracy after Epoch 63: 0.8072\n",
      "  Epoch [64/150], Batch [350/352], Train Acc: 0.8603 Loss: 0.4490\n",
      "  Validation Accuracy after Epoch 64: 0.7884\n",
      "  Epoch [65/150], Batch [350/352], Train Acc: 0.8628 Loss: 0.4252\n",
      "  Validation Accuracy after Epoch 65: 0.8088\n",
      "  Epoch [66/150], Batch [350/352], Train Acc: 0.8631 Loss: 0.4020\n",
      "  Validation Accuracy after Epoch 66: 0.8312\n",
      "  Epoch [67/150], Batch [350/352], Train Acc: 0.8656 Loss: 0.4746\n",
      "  Validation Accuracy after Epoch 67: 0.8196\n",
      "  Epoch [68/150], Batch [350/352], Train Acc: 0.8649 Loss: 0.4136\n",
      "  Validation Accuracy after Epoch 68: 0.8114\n",
      "  Epoch [69/150], Batch [350/352], Train Acc: 0.8631 Loss: 0.5059\n",
      "  Validation Accuracy after Epoch 69: 0.7782\n",
      "  Epoch [70/150], Batch [350/352], Train Acc: 0.8661 Loss: 0.4492\n",
      "  Validation Accuracy after Epoch 70: 0.7676\n",
      "  Epoch [71/150], Batch [350/352], Train Acc: 0.8668 Loss: 0.3799\n",
      "  Validation Accuracy after Epoch 71: 0.8348\n",
      "  Epoch [72/150], Batch [350/352], Train Acc: 0.8651 Loss: 0.4939\n",
      "  Validation Accuracy after Epoch 72: 0.8268\n",
      "  Epoch [73/150], Batch [350/352], Train Acc: 0.8703 Loss: 0.4103\n",
      "  Validation Accuracy after Epoch 73: 0.8408\n",
      "  Epoch [74/150], Batch [350/352], Train Acc: 0.8676 Loss: 0.4013\n",
      "  Validation Accuracy after Epoch 74: 0.8292\n",
      "  Epoch [75/150], Batch [350/352], Train Acc: 0.8690 Loss: 0.4423\n",
      "  Validation Accuracy after Epoch 75: 0.8192\n",
      "  Epoch [76/150], Batch [350/352], Train Acc: 0.8685 Loss: 0.5310\n",
      "  Validation Accuracy after Epoch 76: 0.8126\n",
      "  Epoch [77/150], Batch [350/352], Train Acc: 0.8697 Loss: 0.3965\n",
      "  Validation Accuracy after Epoch 77: 0.8380\n",
      "  Epoch [78/150], Batch [350/352], Train Acc: 0.8724 Loss: 0.5047\n",
      "  Validation Accuracy after Epoch 78: 0.8302\n",
      "  Epoch [79/150], Batch [350/352], Train Acc: 0.8692 Loss: 0.3054\n",
      "  Validation Accuracy after Epoch 79: 0.8314\n",
      "  Epoch [80/150], Batch [350/352], Train Acc: 0.8711 Loss: 0.3910\n",
      "  Validation Accuracy after Epoch 80: 0.8186\n",
      "  Epoch [81/150], Batch [350/352], Train Acc: 0.8696 Loss: 0.2943\n",
      "  Validation Accuracy after Epoch 81: 0.7890\n",
      "  Epoch [82/150], Batch [350/352], Train Acc: 0.8715 Loss: 0.4993\n",
      "  Validation Accuracy after Epoch 82: 0.7768\n",
      "  Epoch [83/150], Batch [350/352], Train Acc: 0.8750 Loss: 0.3508\n",
      "  Validation Accuracy after Epoch 83: 0.8160\n",
      "  Epoch [84/150], Batch [350/352], Train Acc: 0.8727 Loss: 0.4194\n",
      "  Validation Accuracy after Epoch 84: 0.8312\n",
      "  Epoch [85/150], Batch [350/352], Train Acc: 0.8752 Loss: 0.3436\n",
      "  Validation Accuracy after Epoch 85: 0.8474\n",
      "  Epoch [86/150], Batch [350/352], Train Acc: 0.8750 Loss: 0.3273\n",
      "  Validation Accuracy after Epoch 86: 0.8306\n",
      "  Epoch [87/150], Batch [350/352], Train Acc: 0.8756 Loss: 0.4264\n",
      "  Validation Accuracy after Epoch 87: 0.8174\n",
      "  Epoch [88/150], Batch [350/352], Train Acc: 0.8775 Loss: 0.4263\n",
      "  Validation Accuracy after Epoch 88: 0.7996\n",
      "  Epoch [89/150], Batch [350/352], Train Acc: 0.8782 Loss: 0.2662\n",
      "  Validation Accuracy after Epoch 89: 0.8274\n",
      "  Epoch [90/150], Batch [350/352], Train Acc: 0.8784 Loss: 0.3349\n",
      "  Validation Accuracy after Epoch 90: 0.8518\n",
      "  Epoch [91/150], Batch [350/352], Train Acc: 0.8790 Loss: 0.3592\n",
      "  Validation Accuracy after Epoch 91: 0.8400\n",
      "  Epoch [92/150], Batch [350/352], Train Acc: 0.8801 Loss: 0.4155\n",
      "  Validation Accuracy after Epoch 92: 0.8404\n",
      "  Epoch [93/150], Batch [350/352], Train Acc: 0.8812 Loss: 0.3868\n",
      "  Validation Accuracy after Epoch 93: 0.8166\n",
      "  Epoch [94/150], Batch [350/352], Train Acc: 0.8792 Loss: 0.2932\n",
      "  Validation Accuracy after Epoch 94: 0.8090\n",
      "  Epoch [95/150], Batch [350/352], Train Acc: 0.8798 Loss: 0.3412\n",
      "  Validation Accuracy after Epoch 95: 0.8550\n",
      "  Epoch [96/150], Batch [350/352], Train Acc: 0.8820 Loss: 0.4574\n",
      "  Validation Accuracy after Epoch 96: 0.8108\n",
      "  Epoch [97/150], Batch [350/352], Train Acc: 0.8842 Loss: 0.4299\n",
      "  Validation Accuracy after Epoch 97: 0.8448\n",
      "  Epoch [98/150], Batch [350/352], Train Acc: 0.8858 Loss: 0.4040\n",
      "  Validation Accuracy after Epoch 98: 0.8350\n",
      "  Epoch [99/150], Batch [350/352], Train Acc: 0.8867 Loss: 0.3067\n",
      "  Validation Accuracy after Epoch 99: 0.8552\n",
      "  Epoch [100/150], Batch [350/352], Train Acc: 0.8887 Loss: 0.2183\n",
      "  Validation Accuracy after Epoch 100: 0.8560\n",
      "  Epoch [101/150], Batch [350/352], Train Acc: 0.8890 Loss: 0.3465\n",
      "  Validation Accuracy after Epoch 101: 0.8520\n",
      "  Epoch [102/150], Batch [350/352], Train Acc: 0.8921 Loss: 0.3938\n",
      "  Validation Accuracy after Epoch 102: 0.8408\n",
      "  Epoch [103/150], Batch [350/352], Train Acc: 0.8893 Loss: 0.2819\n",
      "  Validation Accuracy after Epoch 103: 0.8458\n",
      "  Epoch [104/150], Batch [350/352], Train Acc: 0.8922 Loss: 0.2665\n",
      "  Validation Accuracy after Epoch 104: 0.8488\n",
      "  Epoch [105/150], Batch [350/352], Train Acc: 0.8922 Loss: 0.2839\n",
      "  Validation Accuracy after Epoch 105: 0.8550\n",
      "  Epoch [106/150], Batch [350/352], Train Acc: 0.8956 Loss: 0.3368\n",
      "  Validation Accuracy after Epoch 106: 0.8370\n",
      "  Epoch [107/150], Batch [350/352], Train Acc: 0.8968 Loss: 0.3516\n",
      "  Validation Accuracy after Epoch 107: 0.8500\n",
      "  Epoch [108/150], Batch [350/352], Train Acc: 0.8976 Loss: 0.2230\n",
      "  Validation Accuracy after Epoch 108: 0.8210\n",
      "  Epoch [109/150], Batch [350/352], Train Acc: 0.8972 Loss: 0.2361\n",
      "  Validation Accuracy after Epoch 109: 0.8450\n",
      "  Epoch [110/150], Batch [350/352], Train Acc: 0.9017 Loss: 0.3665\n",
      "  Validation Accuracy after Epoch 110: 0.8678\n",
      "  Epoch [111/150], Batch [350/352], Train Acc: 0.9012 Loss: 0.2075\n",
      "  Validation Accuracy after Epoch 111: 0.8634\n",
      "  Epoch [112/150], Batch [350/352], Train Acc: 0.9019 Loss: 0.3540\n",
      "  Validation Accuracy after Epoch 112: 0.8680\n",
      "  Epoch [113/150], Batch [350/352], Train Acc: 0.9044 Loss: 0.2036\n",
      "  Validation Accuracy after Epoch 113: 0.8700\n",
      "  Epoch [114/150], Batch [350/352], Train Acc: 0.9049 Loss: 0.2199\n",
      "  Validation Accuracy after Epoch 114: 0.8746\n",
      "  Epoch [115/150], Batch [350/352], Train Acc: 0.9085 Loss: 0.3482\n",
      "  Validation Accuracy after Epoch 115: 0.8652\n",
      "  Epoch [116/150], Batch [350/352], Train Acc: 0.9106 Loss: 0.1837\n",
      "  Validation Accuracy after Epoch 116: 0.8720\n",
      "  Epoch [117/150], Batch [350/352], Train Acc: 0.9117 Loss: 0.2210\n",
      "  Validation Accuracy after Epoch 117: 0.8758\n",
      "  Epoch [118/150], Batch [350/352], Train Acc: 0.9161 Loss: 0.2188\n",
      "  Validation Accuracy after Epoch 118: 0.8824\n",
      "  Epoch [119/150], Batch [350/352], Train Acc: 0.9187 Loss: 0.2112\n",
      "  Validation Accuracy after Epoch 119: 0.8644\n",
      "  Epoch [120/150], Batch [350/352], Train Acc: 0.9161 Loss: 0.2093\n",
      "  Validation Accuracy after Epoch 120: 0.8858\n",
      "  Epoch [121/150], Batch [350/352], Train Acc: 0.9211 Loss: 0.2721\n",
      "  Validation Accuracy after Epoch 121: 0.8764\n",
      "  Epoch [122/150], Batch [350/352], Train Acc: 0.9218 Loss: 0.1726\n",
      "  Validation Accuracy after Epoch 122: 0.8846\n",
      "  Epoch [123/150], Batch [350/352], Train Acc: 0.9275 Loss: 0.1666\n",
      "  Validation Accuracy after Epoch 123: 0.8824\n",
      "  Epoch [124/150], Batch [350/352], Train Acc: 0.9260 Loss: 0.1806\n",
      "  Validation Accuracy after Epoch 124: 0.8848\n",
      "  Epoch [125/150], Batch [350/352], Train Acc: 0.9306 Loss: 0.2079\n",
      "  Validation Accuracy after Epoch 125: 0.8824\n",
      "  Epoch [126/150], Batch [350/352], Train Acc: 0.9321 Loss: 0.2023\n",
      "  Validation Accuracy after Epoch 126: 0.8988\n",
      "  Epoch [127/150], Batch [350/352], Train Acc: 0.9384 Loss: 0.1378\n",
      "  Validation Accuracy after Epoch 127: 0.8968\n",
      "  Epoch [128/150], Batch [350/352], Train Acc: 0.9424 Loss: 0.1397\n",
      "  Validation Accuracy after Epoch 128: 0.8972\n",
      "  Epoch [129/150], Batch [350/352], Train Acc: 0.9429 Loss: 0.1964\n",
      "  Validation Accuracy after Epoch 129: 0.8970\n",
      "  Epoch [130/150], Batch [350/352], Train Acc: 0.9474 Loss: 0.1309\n",
      "  Validation Accuracy after Epoch 130: 0.9010\n",
      "  Epoch [131/150], Batch [350/352], Train Acc: 0.9471 Loss: 0.2048\n",
      "  Validation Accuracy after Epoch 131: 0.9014\n",
      "  Epoch [132/150], Batch [350/352], Train Acc: 0.9544 Loss: 0.1557\n",
      "  Validation Accuracy after Epoch 132: 0.9032\n",
      "  Epoch [133/150], Batch [350/352], Train Acc: 0.9561 Loss: 0.1536\n",
      "  Validation Accuracy after Epoch 133: 0.9058\n",
      "  Epoch [134/150], Batch [350/352], Train Acc: 0.9591 Loss: 0.1316\n",
      "  Validation Accuracy after Epoch 134: 0.9082\n",
      "  Epoch [135/150], Batch [350/352], Train Acc: 0.9632 Loss: 0.1099\n",
      "  Validation Accuracy after Epoch 135: 0.9190\n",
      "  Epoch [136/150], Batch [350/352], Train Acc: 0.9655 Loss: 0.1035\n",
      "  Validation Accuracy after Epoch 136: 0.9160\n",
      "  Epoch [137/150], Batch [350/352], Train Acc: 0.9682 Loss: 0.0672\n",
      "  Validation Accuracy after Epoch 137: 0.9128\n",
      "  Epoch [138/150], Batch [350/352], Train Acc: 0.9729 Loss: 0.0308\n",
      "  Validation Accuracy after Epoch 138: 0.9216\n",
      "  Epoch [139/150], Batch [350/352], Train Acc: 0.9733 Loss: 0.1511\n",
      "  Validation Accuracy after Epoch 139: 0.9200\n",
      "  Epoch [140/150], Batch [350/352], Train Acc: 0.9766 Loss: 0.0857\n",
      "  Validation Accuracy after Epoch 140: 0.9182\n",
      "  Epoch [141/150], Batch [350/352], Train Acc: 0.9783 Loss: 0.0884\n",
      "  Validation Accuracy after Epoch 141: 0.9212\n",
      "  Epoch [142/150], Batch [350/352], Train Acc: 0.9792 Loss: 0.0657\n",
      "  Validation Accuracy after Epoch 142: 0.9232\n",
      "  Epoch [143/150], Batch [350/352], Train Acc: 0.9819 Loss: 0.0282\n",
      "  Validation Accuracy after Epoch 143: 0.9192\n",
      "  Epoch [144/150], Batch [350/352], Train Acc: 0.9829 Loss: 0.0562\n",
      "  Validation Accuracy after Epoch 144: 0.9250\n",
      "  Epoch [145/150], Batch [350/352], Train Acc: 0.9826 Loss: 0.0521\n",
      "  Validation Accuracy after Epoch 145: 0.9196\n",
      "  Epoch [146/150], Batch [350/352], Train Acc: 0.9846 Loss: 0.0392\n",
      "  Validation Accuracy after Epoch 146: 0.9230\n",
      "  Epoch [147/150], Batch [350/352], Train Acc: 0.9837 Loss: 0.0546\n",
      "  Validation Accuracy after Epoch 147: 0.9258\n",
      "  Epoch [148/150], Batch [350/352], Train Acc: 0.9858 Loss: 0.0745\n",
      "  Validation Accuracy after Epoch 148: 0.9246\n",
      "  Epoch [149/150], Batch [350/352], Train Acc: 0.9848 Loss: 0.0285\n",
      "  Validation Accuracy after Epoch 149: 0.9262\n",
      "  Epoch [150/150], Batch [350/352], Train Acc: 0.9843 Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 03:10:59,140] Trial 0 finished with value: 0.9262 and parameters: {'batch_size': 128, 'optimizer_type': 'SGD', 'scheduler_type': 'OneCycleLR', 'weight_decay': 0.0001, 'learning_rate': 0.023700108124443908, 'h_flip': 0.12736253958494903, 'rotation': 5}. Best is trial 0 with value: 0.9262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy after Epoch 150: 0.9218\n",
      "Trial 0 complete. Best Validation Accuracy: 0.9262\n",
      "\n",
      "Model checkpoint saved to checkpoints_study_2025-03-10_02-34-32/model_trial_0_val_acc_0.9262.pth\n",
      "--------------------------------------------------\n",
      "trial.number=1\n",
      "batch_size: 128\n",
      "optimizer_type: SGD\n",
      "scheduler_type: CosineAnnealingLR\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.014053665707054585\n",
      "h_flip: 0.9940407167574773\n",
      "rotation: 0\n",
      "eta_min: 4.5147344423316726e-07\n",
      "model_name: resnet18\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/150], Batch [350/352], Train Acc: 0.3592 Loss: 1.6222\n",
      "  Validation Accuracy after Epoch 1: 0.4566\n",
      "  Epoch [2/150], Batch [350/352], Train Acc: 0.5127 Loss: 1.2483\n",
      "  Validation Accuracy after Epoch 2: 0.6004\n",
      "  Epoch [3/150], Batch [350/352], Train Acc: 0.5979 Loss: 1.1686\n",
      "  Validation Accuracy after Epoch 3: 0.6640\n",
      "  Epoch [4/150], Batch [350/352], Train Acc: 0.6383 Loss: 0.9289\n",
      "  Validation Accuracy after Epoch 4: 0.6682\n",
      "  Epoch [5/150], Batch [350/352], Train Acc: 0.6681 Loss: 0.8296\n",
      "  Validation Accuracy after Epoch 5: 0.6432\n",
      "  Epoch [6/150], Batch [350/352], Train Acc: 0.6945 Loss: 0.9647\n",
      "  Validation Accuracy after Epoch 6: 0.6724\n",
      "  Epoch [7/150], Batch [350/352], Train Acc: 0.7210 Loss: 0.7128\n",
      "  Validation Accuracy after Epoch 7: 0.6974\n",
      "  Epoch [8/150], Batch [350/352], Train Acc: 0.7442 Loss: 0.6055\n",
      "  Validation Accuracy after Epoch 8: 0.7770\n",
      "  Epoch [9/150], Batch [350/352], Train Acc: 0.7615 Loss: 0.6574\n",
      "  Validation Accuracy after Epoch 9: 0.7888\n",
      "  Epoch [10/150], Batch [350/352], Train Acc: 0.7742 Loss: 0.5448\n",
      "  Validation Accuracy after Epoch 10: 0.7900\n",
      "  Epoch [11/150], Batch [350/352], Train Acc: 0.7795 Loss: 0.5447\n",
      "  Validation Accuracy after Epoch 11: 0.7382\n",
      "  Epoch [12/150], Batch [350/352], Train Acc: 0.7891 Loss: 0.7214\n",
      "  Validation Accuracy after Epoch 12: 0.7348\n",
      "  Epoch [13/150], Batch [350/352], Train Acc: 0.8006 Loss: 0.6615\n",
      "  Validation Accuracy after Epoch 13: 0.7788\n",
      "  Epoch [14/150], Batch [350/352], Train Acc: 0.8094 Loss: 0.5550\n",
      "  Validation Accuracy after Epoch 14: 0.8248\n",
      "  Epoch [15/150], Batch [350/352], Train Acc: 0.8183 Loss: 0.5784\n",
      "  Validation Accuracy after Epoch 15: 0.8364\n",
      "  Epoch [16/150], Batch [350/352], Train Acc: 0.8250 Loss: 0.3743\n",
      "  Validation Accuracy after Epoch 16: 0.8202\n",
      "  Epoch [17/150], Batch [350/352], Train Acc: 0.8255 Loss: 0.6576\n",
      "  Validation Accuracy after Epoch 17: 0.7620\n",
      "  Epoch [18/150], Batch [350/352], Train Acc: 0.8339 Loss: 0.4411\n",
      "  Validation Accuracy after Epoch 18: 0.7888\n",
      "  Epoch [19/150], Batch [350/352], Train Acc: 0.8409 Loss: 0.4142\n",
      "  Validation Accuracy after Epoch 19: 0.8402\n",
      "  Epoch [20/150], Batch [350/352], Train Acc: 0.8489 Loss: 0.2262\n",
      "  Validation Accuracy after Epoch 20: 0.8446\n",
      "  Epoch [21/150], Batch [350/352], Train Acc: 0.8510 Loss: 0.4683\n",
      "  Validation Accuracy after Epoch 21: 0.8536\n",
      "  Epoch [22/150], Batch [350/352], Train Acc: 0.8573 Loss: 0.5322\n",
      "  Validation Accuracy after Epoch 22: 0.8166\n",
      "  Epoch [23/150], Batch [350/352], Train Acc: 0.8578 Loss: 0.4404\n",
      "  Validation Accuracy after Epoch 23: 0.8134\n",
      "  Epoch [24/150], Batch [350/352], Train Acc: 0.8613 Loss: 0.4549\n",
      "  Validation Accuracy after Epoch 24: 0.8358\n",
      "  Epoch [25/150], Batch [350/352], Train Acc: 0.8673 Loss: 0.4489\n",
      "  Validation Accuracy after Epoch 25: 0.8402\n",
      "  Epoch [26/150], Batch [350/352], Train Acc: 0.8755 Loss: 0.2652\n",
      "  Validation Accuracy after Epoch 26: 0.8616\n",
      "  Epoch [27/150], Batch [350/352], Train Acc: 0.8766 Loss: 0.3983\n",
      "  Validation Accuracy after Epoch 27: 0.8680\n",
      "  Epoch [28/150], Batch [350/352], Train Acc: 0.8763 Loss: 0.4128\n",
      "  Validation Accuracy after Epoch 28: 0.8186\n",
      "  Epoch [29/150], Batch [350/352], Train Acc: 0.8767 Loss: 0.4609\n",
      "  Validation Accuracy after Epoch 29: 0.8174\n",
      "  Epoch [30/150], Batch [350/352], Train Acc: 0.8811 Loss: 0.4716\n",
      "  Validation Accuracy after Epoch 30: 0.8396\n",
      "  Epoch [31/150], Batch [350/352], Train Acc: 0.8857 Loss: 0.2687\n",
      "  Validation Accuracy after Epoch 31: 0.8592\n",
      "  Epoch [32/150], Batch [350/352], Train Acc: 0.8902 Loss: 0.2977\n",
      "  Validation Accuracy after Epoch 32: 0.8694\n",
      "  Epoch [33/150], Batch [350/352], Train Acc: 0.8928 Loss: 0.2947\n",
      "  Validation Accuracy after Epoch 33: 0.8698\n",
      "  Epoch [34/150], Batch [350/352], Train Acc: 0.8946 Loss: 0.2965\n",
      "  Validation Accuracy after Epoch 34: 0.8080\n",
      "  Epoch [35/150], Batch [350/352], Train Acc: 0.8919 Loss: 0.4322\n",
      "  Validation Accuracy after Epoch 35: 0.8270\n",
      "  Epoch [36/150], Batch [350/352], Train Acc: 0.8975 Loss: 0.3278\n",
      "  Validation Accuracy after Epoch 36: 0.8556\n",
      "  Epoch [37/150], Batch [350/352], Train Acc: 0.9022 Loss: 0.3365\n",
      "  Validation Accuracy after Epoch 37: 0.8714\n",
      "  Epoch [38/150], Batch [350/352], Train Acc: 0.9059 Loss: 0.2724\n",
      "  Validation Accuracy after Epoch 38: 0.8806\n",
      "  Epoch [39/150], Batch [350/352], Train Acc: 0.9078 Loss: 0.1326\n",
      "  Validation Accuracy after Epoch 39: 0.8734\n",
      "  Epoch [40/150], Batch [350/352], Train Acc: 0.9058 Loss: 0.3153\n",
      "  Validation Accuracy after Epoch 40: 0.8432\n",
      "  Epoch [41/150], Batch [350/352], Train Acc: 0.9076 Loss: 0.4265\n",
      "  Validation Accuracy after Epoch 41: 0.8432\n",
      "  Epoch [42/150], Batch [350/352], Train Acc: 0.9094 Loss: 0.2359\n",
      "  Validation Accuracy after Epoch 42: 0.8674\n",
      "  Epoch [43/150], Batch [350/352], Train Acc: 0.9162 Loss: 0.2149\n",
      "  Validation Accuracy after Epoch 43: 0.8830\n",
      "  Epoch [44/150], Batch [350/352], Train Acc: 0.9177 Loss: 0.2490\n",
      "  Validation Accuracy after Epoch 44: 0.8914\n",
      "  Epoch [45/150], Batch [350/352], Train Acc: 0.9187 Loss: 0.2054\n",
      "  Validation Accuracy after Epoch 45: 0.8732\n",
      "  Epoch [46/150], Batch [350/352], Train Acc: 0.9177 Loss: 0.2508\n",
      "  Validation Accuracy after Epoch 46: 0.8590\n",
      "  Epoch [47/150], Batch [350/352], Train Acc: 0.9202 Loss: 0.2885\n",
      "  Validation Accuracy after Epoch 47: 0.8450\n",
      "  Epoch [48/150], Batch [350/352], Train Acc: 0.9208 Loss: 0.2655\n",
      "  Validation Accuracy after Epoch 48: 0.8810\n",
      "  Epoch [49/150], Batch [350/352], Train Acc: 0.9270 Loss: 0.1941\n",
      "  Validation Accuracy after Epoch 49: 0.8810\n",
      "  Epoch [50/150], Batch [350/352], Train Acc: 0.9284 Loss: 0.1669\n",
      "  Validation Accuracy after Epoch 50: 0.8836\n",
      "  Epoch [51/150], Batch [350/352], Train Acc: 0.9272 Loss: 0.2335\n",
      "  Validation Accuracy after Epoch 51: 0.8708\n",
      "  Epoch [52/150], Batch [350/352], Train Acc: 0.9267 Loss: 0.1847\n",
      "  Validation Accuracy after Epoch 52: 0.8240\n",
      "  Epoch [53/150], Batch [350/352], Train Acc: 0.9279 Loss: 0.2143\n",
      "  Validation Accuracy after Epoch 53: 0.8580\n",
      "  Epoch [54/150], Batch [350/352], Train Acc: 0.9313 Loss: 0.1386\n",
      "  Validation Accuracy after Epoch 54: 0.8892\n",
      "  Epoch [55/150], Batch [350/352], Train Acc: 0.9350 Loss: 0.2189\n",
      "  Validation Accuracy after Epoch 55: 0.8906\n",
      "  Epoch [56/150], Batch [350/352], Train Acc: 0.9359 Loss: 0.2163\n",
      "  Validation Accuracy after Epoch 56: 0.8926\n",
      "  Epoch [57/150], Batch [350/352], Train Acc: 0.9344 Loss: 0.1505\n",
      "  Validation Accuracy after Epoch 57: 0.8610\n",
      "  Epoch [58/150], Batch [350/352], Train Acc: 0.9353 Loss: 0.1533\n",
      "  Validation Accuracy after Epoch 58: 0.8504\n",
      "  Epoch [59/150], Batch [350/352], Train Acc: 0.9337 Loss: 0.1899\n",
      "  Validation Accuracy after Epoch 59: 0.8744\n",
      "  Epoch [60/150], Batch [350/352], Train Acc: 0.9401 Loss: 0.2359\n",
      "  Validation Accuracy after Epoch 60: 0.8894\n",
      "  Epoch [61/150], Batch [350/352], Train Acc: 0.9428 Loss: 0.1535\n",
      "  Validation Accuracy after Epoch 61: 0.8886\n",
      "  Epoch [62/150], Batch [350/352], Train Acc: 0.9424 Loss: 0.1989\n",
      "  Validation Accuracy after Epoch 62: 0.8878\n",
      "  Epoch [63/150], Batch [350/352], Train Acc: 0.9413 Loss: 0.2392\n",
      "  Validation Accuracy after Epoch 63: 0.8698\n",
      "  Epoch [64/150], Batch [350/352], Train Acc: 0.9403 Loss: 0.2237\n",
      "  Validation Accuracy after Epoch 64: 0.8556\n",
      "  Epoch [65/150], Batch [350/352], Train Acc: 0.9425 Loss: 0.2061\n",
      "  Validation Accuracy after Epoch 65: 0.8770\n",
      "  Epoch [66/150], Batch [350/352], Train Acc: 0.9456 Loss: 0.1039\n",
      "  Validation Accuracy after Epoch 66: 0.8892\n",
      "  Epoch [67/150], Batch [350/352], Train Acc: 0.9492 Loss: 0.1190\n",
      "  Validation Accuracy after Epoch 67: 0.8942\n",
      "  Epoch [68/150], Batch [350/352], Train Acc: 0.9477 Loss: 0.1042\n",
      "  Validation Accuracy after Epoch 68: 0.8894\n",
      "  Epoch [69/150], Batch [350/352], Train Acc: 0.9486 Loss: 0.2755\n",
      "  Validation Accuracy after Epoch 69: 0.8718\n",
      "  Epoch [70/150], Batch [350/352], Train Acc: 0.9473 Loss: 0.2598\n",
      "  Validation Accuracy after Epoch 70: 0.8520\n",
      "  Epoch [71/150], Batch [350/352], Train Acc: 0.9480 Loss: 0.1068\n",
      "  Validation Accuracy after Epoch 71: 0.8810\n",
      "  Epoch [72/150], Batch [350/352], Train Acc: 0.9509 Loss: 0.2574\n",
      "  Validation Accuracy after Epoch 72: 0.8922\n",
      "  Epoch [73/150], Batch [350/352], Train Acc: 0.9521 Loss: 0.1702\n",
      "  Validation Accuracy after Epoch 73: 0.9008\n",
      "  Epoch [74/150], Batch [350/352], Train Acc: 0.9520 Loss: 0.1597\n",
      "  Validation Accuracy after Epoch 74: 0.8840\n",
      "  Epoch [75/150], Batch [350/352], Train Acc: 0.9509 Loss: 0.1593\n",
      "  Validation Accuracy after Epoch 75: 0.8658\n",
      "  Epoch [76/150], Batch [350/352], Train Acc: 0.9514 Loss: 0.1918\n",
      "  Validation Accuracy after Epoch 76: 0.8826\n",
      "  Epoch [77/150], Batch [350/352], Train Acc: 0.9520 Loss: 0.1492\n",
      "  Validation Accuracy after Epoch 77: 0.8906\n",
      "  Epoch [78/150], Batch [350/352], Train Acc: 0.9568 Loss: 0.1166\n",
      "  Validation Accuracy after Epoch 78: 0.8962\n",
      "  Epoch [79/150], Batch [350/352], Train Acc: 0.9544 Loss: 0.0619\n",
      "  Validation Accuracy after Epoch 79: 0.8942\n",
      "  Epoch [80/150], Batch [350/352], Train Acc: 0.9561 Loss: 0.0944\n",
      "  Validation Accuracy after Epoch 80: 0.8778\n",
      "  Epoch [81/150], Batch [350/352], Train Acc: 0.9524 Loss: 0.1500\n",
      "  Validation Accuracy after Epoch 81: 0.8642\n",
      "  Epoch [82/150], Batch [350/352], Train Acc: 0.9532 Loss: 0.2126\n",
      "  Validation Accuracy after Epoch 82: 0.8692\n",
      "  Epoch [83/150], Batch [350/352], Train Acc: 0.9556 Loss: 0.0718\n",
      "  Validation Accuracy after Epoch 83: 0.8914\n",
      "  Epoch [84/150], Batch [350/352], Train Acc: 0.9593 Loss: 0.1208\n",
      "  Validation Accuracy after Epoch 84: 0.8932\n",
      "  Epoch [85/150], Batch [350/352], Train Acc: 0.9575 Loss: 0.1285\n",
      "  Validation Accuracy after Epoch 85: 0.8958\n",
      "  Epoch [86/150], Batch [350/352], Train Acc: 0.9563 Loss: 0.1740\n",
      "  Validation Accuracy after Epoch 86: 0.8756\n",
      "  Epoch [87/150], Batch [350/352], Train Acc: 0.9558 Loss: 0.1910\n",
      "  Validation Accuracy after Epoch 87: 0.8512\n",
      "  Epoch [88/150], Batch [350/352], Train Acc: 0.9574 Loss: 0.1196\n",
      "  Validation Accuracy after Epoch 88: 0.8826\n",
      "  Epoch [89/150], Batch [350/352], Train Acc: 0.9601 Loss: 0.0782\n",
      "  Validation Accuracy after Epoch 89: 0.8928\n",
      "  Epoch [90/150], Batch [350/352], Train Acc: 0.9619 Loss: 0.1284\n",
      "  Validation Accuracy after Epoch 90: 0.8952\n",
      "  Epoch [91/150], Batch [350/352], Train Acc: 0.9603 Loss: 0.1328\n",
      "  Validation Accuracy after Epoch 91: 0.8896\n",
      "  Epoch [92/150], Batch [350/352], Train Acc: 0.9599 Loss: 0.1587\n",
      "  Validation Accuracy after Epoch 92: 0.8680\n",
      "  Epoch [93/150], Batch [350/352], Train Acc: 0.9587 Loss: 0.1516\n",
      "  Validation Accuracy after Epoch 93: 0.8708\n",
      "  Epoch [94/150], Batch [350/352], Train Acc: 0.9580 Loss: 0.1353\n",
      "  Validation Accuracy after Epoch 94: 0.8784\n",
      "  Epoch [95/150], Batch [350/352], Train Acc: 0.9620 Loss: 0.1257\n",
      "  Validation Accuracy after Epoch 95: 0.8960\n",
      "  Epoch [96/150], Batch [350/352], Train Acc: 0.9644 Loss: 0.1830\n",
      "  Validation Accuracy after Epoch 96: 0.8998\n",
      "  Epoch [97/150], Batch [350/352], Train Acc: 0.9596 Loss: 0.1446\n",
      "  Validation Accuracy after Epoch 97: 0.8894\n",
      "  Epoch [98/150], Batch [350/352], Train Acc: 0.9616 Loss: 0.1497\n",
      "  Validation Accuracy after Epoch 98: 0.8624\n",
      "  Epoch [99/150], Batch [350/352], Train Acc: 0.9603 Loss: 0.1743\n",
      "  Validation Accuracy after Epoch 99: 0.8640\n",
      "  Epoch [100/150], Batch [350/352], Train Acc: 0.9615 Loss: 0.0825\n",
      "  Validation Accuracy after Epoch 100: 0.8918\n",
      "  Epoch [101/150], Batch [350/352], Train Acc: 0.9649 Loss: 0.0774\n",
      "  Validation Accuracy after Epoch 101: 0.8958\n",
      "  Epoch [102/150], Batch [350/352], Train Acc: 0.9644 Loss: 0.1314\n",
      "  Validation Accuracy after Epoch 102: 0.8968\n",
      "  Epoch [103/150], Batch [350/352], Train Acc: 0.9625 Loss: 0.0643\n",
      "  Validation Accuracy after Epoch 103: 0.8800\n",
      "  Epoch [104/150], Batch [350/352], Train Acc: 0.9614 Loss: 0.1770\n",
      "  Validation Accuracy after Epoch 104: 0.8634\n",
      "  Epoch [105/150], Batch [350/352], Train Acc: 0.9597 Loss: 0.0804\n",
      "  Validation Accuracy after Epoch 105: 0.8762\n",
      "  Epoch [106/150], Batch [350/352], Train Acc: 0.9648 Loss: 0.1282\n",
      "  Validation Accuracy after Epoch 106: 0.8898\n",
      "  Epoch [107/150], Batch [350/352], Train Acc: 0.9645 Loss: 0.0762\n",
      "  Validation Accuracy after Epoch 107: 0.8978\n",
      "  Epoch [108/150], Batch [350/352], Train Acc: 0.9650 Loss: 0.0829\n",
      "  Validation Accuracy after Epoch 108: 0.8990\n",
      "  Epoch [109/150], Batch [350/352], Train Acc: 0.9655 Loss: 0.0727\n",
      "  Validation Accuracy after Epoch 109: 0.8712\n",
      "  Epoch [110/150], Batch [350/352], Train Acc: 0.9626 Loss: 0.2270\n",
      "  Validation Accuracy after Epoch 110: 0.8698\n",
      "  Epoch [111/150], Batch [350/352], Train Acc: 0.9626 Loss: 0.1164\n",
      "  Validation Accuracy after Epoch 111: 0.8806\n",
      "  Epoch [112/150], Batch [350/352], Train Acc: 0.9656 Loss: 0.0944\n",
      "  Validation Accuracy after Epoch 112: 0.8960\n",
      "  Epoch [113/150], Batch [350/352], Train Acc: 0.9669 Loss: 0.0860\n",
      "  Validation Accuracy after Epoch 113: 0.8964\n",
      "  Epoch [114/150], Batch [350/352], Train Acc: 0.9644 Loss: 0.0564\n",
      "  Validation Accuracy after Epoch 114: 0.8952\n",
      "  Epoch [115/150], Batch [350/352], Train Acc: 0.9660 Loss: 0.1048\n",
      "  Validation Accuracy after Epoch 115: 0.8736\n",
      "  Epoch [116/150], Batch [350/352], Train Acc: 0.9642 Loss: 0.2230\n",
      "  Validation Accuracy after Epoch 116: 0.8626\n",
      "  Epoch [117/150], Batch [350/352], Train Acc: 0.9649 Loss: 0.0761\n",
      "  Validation Accuracy after Epoch 117: 0.8856\n",
      "  Epoch [118/150], Batch [350/352], Train Acc: 0.9682 Loss: 0.0708\n",
      "  Validation Accuracy after Epoch 118: 0.8956\n",
      "  Epoch [119/150], Batch [350/352], Train Acc: 0.9665 Loss: 0.0632\n",
      "  Validation Accuracy after Epoch 119: 0.9032\n",
      "  Epoch [120/150], Batch [350/352], Train Acc: 0.9675 Loss: 0.0877\n",
      "  Validation Accuracy after Epoch 120: 0.8920\n",
      "  Epoch [121/150], Batch [350/352], Train Acc: 0.9657 Loss: 0.1713\n",
      "  Validation Accuracy after Epoch 121: 0.8598\n",
      "  Epoch [122/150], Batch [350/352], Train Acc: 0.9648 Loss: 0.1743\n",
      "  Validation Accuracy after Epoch 122: 0.8628\n",
      "  Epoch [123/150], Batch [350/352], Train Acc: 0.9649 Loss: 0.0994\n",
      "  Validation Accuracy after Epoch 123: 0.8890\n",
      "  Epoch [124/150], Batch [350/352], Train Acc: 0.9685 Loss: 0.0371\n",
      "  Validation Accuracy after Epoch 124: 0.8934\n",
      "  Epoch [125/150], Batch [350/352], Train Acc: 0.9663 Loss: 0.0893\n",
      "  Validation Accuracy after Epoch 125: 0.9022\n",
      "  Epoch [126/150], Batch [350/352], Train Acc: 0.9662 Loss: 0.0832\n",
      "  Validation Accuracy after Epoch 126: 0.8824\n",
      "  Epoch [127/150], Batch [350/352], Train Acc: 0.9658 Loss: 0.1951\n",
      "  Validation Accuracy after Epoch 127: 0.8694\n",
      "  Epoch [128/150], Batch [350/352], Train Acc: 0.9651 Loss: 0.0595\n",
      "  Validation Accuracy after Epoch 128: 0.8678\n",
      "  Epoch [129/150], Batch [350/352], Train Acc: 0.9651 Loss: 0.0620\n",
      "  Validation Accuracy after Epoch 129: 0.8920\n",
      "  Epoch [130/150], Batch [350/352], Train Acc: 0.9694 Loss: 0.0426\n",
      "  Validation Accuracy after Epoch 130: 0.9060\n",
      "  Epoch [131/150], Batch [350/352], Train Acc: 0.9675 Loss: 0.0645\n",
      "  Validation Accuracy after Epoch 131: 0.9004\n",
      "  Epoch [132/150], Batch [350/352], Train Acc: 0.9684 Loss: 0.0962\n",
      "  Validation Accuracy after Epoch 132: 0.8858\n",
      "  Epoch [133/150], Batch [350/352], Train Acc: 0.9651 Loss: 0.1813\n",
      "  Validation Accuracy after Epoch 133: 0.8616\n",
      "  Epoch [134/150], Batch [350/352], Train Acc: 0.9647 Loss: 0.0957\n",
      "  Validation Accuracy after Epoch 134: 0.8650\n",
      "  Epoch [135/150], Batch [350/352], Train Acc: 0.9685 Loss: 0.1396\n",
      "  Validation Accuracy after Epoch 135: 0.8994\n",
      "  Epoch [136/150], Batch [350/352], Train Acc: 0.9693 Loss: 0.0836\n",
      "  Validation Accuracy after Epoch 136: 0.9004\n",
      "  Epoch [137/150], Batch [350/352], Train Acc: 0.9714 Loss: 0.0646\n",
      "  Validation Accuracy after Epoch 137: 0.9002\n",
      "  Epoch [138/150], Batch [350/352], Train Acc: 0.9698 Loss: 0.0845\n",
      "  Validation Accuracy after Epoch 138: 0.8728\n",
      "  Epoch [139/150], Batch [350/352], Train Acc: 0.9645 Loss: 0.2639\n",
      "  Validation Accuracy after Epoch 139: 0.8354\n",
      "  Epoch [140/150], Batch [350/352], Train Acc: 0.9653 Loss: 0.1490\n",
      "  Validation Accuracy after Epoch 140: 0.8750\n",
      "  Epoch [141/150], Batch [350/352], Train Acc: 0.9693 Loss: 0.0233\n",
      "  Validation Accuracy after Epoch 141: 0.9000\n",
      "  Epoch [142/150], Batch [350/352], Train Acc: 0.9705 Loss: 0.1165\n",
      "  Validation Accuracy after Epoch 142: 0.9020\n",
      "  Epoch [143/150], Batch [350/352], Train Acc: 0.9689 Loss: 0.0385\n",
      "  Validation Accuracy after Epoch 143: 0.8870\n",
      "  Epoch [144/150], Batch [350/352], Train Acc: 0.9700 Loss: 0.1545\n",
      "  Validation Accuracy after Epoch 144: 0.8702\n",
      "  Epoch [145/150], Batch [350/352], Train Acc: 0.9652 Loss: 0.1885\n",
      "  Validation Accuracy after Epoch 145: 0.8766\n",
      "  Epoch [146/150], Batch [350/352], Train Acc: 0.9675 Loss: 0.0943\n",
      "  Validation Accuracy after Epoch 146: 0.8882\n",
      "  Epoch [147/150], Batch [350/352], Train Acc: 0.9709 Loss: 0.0632\n",
      "  Validation Accuracy after Epoch 147: 0.8978\n",
      "  Epoch [148/150], Batch [350/352], Train Acc: 0.9728 Loss: 0.1061\n",
      "  Validation Accuracy after Epoch 148: 0.8984\n",
      "  Epoch [149/150], Batch [350/352], Train Acc: 0.9713 Loss: 0.1191\n",
      "  Validation Accuracy after Epoch 149: 0.8946\n",
      "  Epoch [150/150], Batch [350/352], Train Acc: 0.9666 Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 03:46:33,862] Trial 1 finished with value: 0.906 and parameters: {'batch_size': 128, 'optimizer_type': 'SGD', 'scheduler_type': 'CosineAnnealingLR', 'weight_decay': 0.0001, 'learning_rate': 0.014053665707054585, 'h_flip': 0.9940407167574773, 'rotation': 0, 'eta_min': 4.5147344423316726e-07}. Best is trial 0 with value: 0.9262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy after Epoch 150: 0.8698\n",
      "Trial 1 complete. Best Validation Accuracy: 0.9060\n",
      "\n",
      "Model checkpoint saved to checkpoints_study_2025-03-10_02-34-32/model_trial_1_val_acc_0.9060.pth\n",
      "--------------------------------------------------\n",
      "trial.number=2\n",
      "batch_size: 128\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.038247681576415386\n",
      "h_flip: 0.6069439315107943\n",
      "rotation: 28\n",
      "model_name: resnet18\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/150], Batch [350/352], Train Acc: 0.3474 Loss: 1.5806\n",
      "  Validation Accuracy after Epoch 1: 0.4146\n",
      "  Epoch [2/150], Batch [350/352], Train Acc: 0.4901 Loss: 1.3508\n",
      "  Validation Accuracy after Epoch 2: 0.5274\n",
      "  Epoch [3/150], Batch [350/352], Train Acc: 0.5531 Loss: 1.3389\n",
      "  Validation Accuracy after Epoch 3: 0.5608\n",
      "  Epoch [4/150], Batch [350/352], Train Acc: 0.5914 Loss: 0.9938\n",
      "  Validation Accuracy after Epoch 4: 0.5758\n",
      "  Epoch [5/150], Batch [350/352], Train Acc: 0.6120 Loss: 0.9544\n",
      "  Validation Accuracy after Epoch 5: 0.6344\n",
      "  Epoch [6/150], Batch [350/352], Train Acc: 0.6320 Loss: 1.1015\n",
      "  Validation Accuracy after Epoch 6: 0.6166\n",
      "  Epoch [7/150], Batch [350/352], Train Acc: 0.6559 Loss: 0.8989\n",
      "  Validation Accuracy after Epoch 7: 0.6386\n",
      "  Epoch [8/150], Batch [350/352], Train Acc: 0.6679 Loss: 0.8605\n",
      "  Validation Accuracy after Epoch 8: 0.6722\n",
      "  Epoch [9/150], Batch [350/352], Train Acc: 0.6890 Loss: 0.9469\n",
      "  Validation Accuracy after Epoch 9: 0.6516\n",
      "  Epoch [10/150], Batch [350/352], Train Acc: 0.7001 Loss: 0.8411\n",
      "  Validation Accuracy after Epoch 10: 0.6944\n",
      "  Epoch [11/150], Batch [350/352], Train Acc: 0.7143 Loss: 0.6693\n",
      "  Validation Accuracy after Epoch 11: 0.7262\n",
      "  Epoch [12/150], Batch [350/352], Train Acc: 0.7200 Loss: 0.9562\n",
      "  Validation Accuracy after Epoch 12: 0.6450\n",
      "  Epoch [13/150], Batch [350/352], Train Acc: 0.7314 Loss: 0.7793\n",
      "  Validation Accuracy after Epoch 13: 0.7092\n",
      "  Epoch [14/150], Batch [350/352], Train Acc: 0.7394 Loss: 0.7211\n",
      "  Validation Accuracy after Epoch 14: 0.7078\n",
      "  Epoch [15/150], Batch [350/352], Train Acc: 0.7431 Loss: 0.8297\n",
      "  Validation Accuracy after Epoch 15: 0.7262\n",
      "  Epoch [16/150], Batch [350/352], Train Acc: 0.7514 Loss: 0.7176\n",
      "  Validation Accuracy after Epoch 16: 0.6910\n",
      "  Epoch [17/150], Batch [350/352], Train Acc: 0.7555 Loss: 0.7502\n",
      "  Validation Accuracy after Epoch 17: 0.7326\n",
      "  Epoch [18/150], Batch [350/352], Train Acc: 0.7630 Loss: 0.5925\n",
      "  Validation Accuracy after Epoch 18: 0.7388\n",
      "  Epoch [19/150], Batch [350/352], Train Acc: 0.7671 Loss: 0.7256\n",
      "  Validation Accuracy after Epoch 19: 0.7418\n",
      "  Epoch [20/150], Batch [350/352], Train Acc: 0.7720 Loss: 0.4983\n",
      "  Validation Accuracy after Epoch 20: 0.7328\n",
      "  Epoch [21/150], Batch [350/352], Train Acc: 0.7731 Loss: 0.6938\n",
      "  Validation Accuracy after Epoch 21: 0.7468\n",
      "  Epoch [22/150], Batch [350/352], Train Acc: 0.7777 Loss: 0.8057\n",
      "  Validation Accuracy after Epoch 22: 0.7796\n",
      "  Epoch [23/150], Batch [350/352], Train Acc: 0.7770 Loss: 0.6486\n",
      "  Validation Accuracy after Epoch 23: 0.7644\n",
      "  Epoch [24/150], Batch [350/352], Train Acc: 0.7795 Loss: 0.6863\n",
      "  Validation Accuracy after Epoch 24: 0.7582\n",
      "  Epoch [25/150], Batch [350/352], Train Acc: 0.7832 Loss: 0.7208\n",
      "  Validation Accuracy after Epoch 25: 0.7472\n",
      "  Epoch [26/150], Batch [350/352], Train Acc: 0.7833 Loss: 0.5793\n",
      "  Validation Accuracy after Epoch 26: 0.7514\n",
      "  Epoch [27/150], Batch [350/352], Train Acc: 0.7833 Loss: 0.6934\n",
      "  Validation Accuracy after Epoch 27: 0.7372\n",
      "  Epoch [28/150], Batch [350/352], Train Acc: 0.7854 Loss: 0.6325\n",
      "  Validation Accuracy after Epoch 28: 0.7342\n",
      "  Epoch [29/150], Batch [350/352], Train Acc: 0.7891 Loss: 0.6381\n",
      "  Validation Accuracy after Epoch 29: 0.7540\n",
      "  Epoch [30/150], Batch [350/352], Train Acc: 0.7877 Loss: 0.6121\n",
      "  Validation Accuracy after Epoch 30: 0.7554\n",
      "  Epoch [31/150], Batch [350/352], Train Acc: 0.7873 Loss: 0.5214\n",
      "  Validation Accuracy after Epoch 31: 0.7586\n",
      "  Epoch [32/150], Batch [350/352], Train Acc: 0.7904 Loss: 0.6637\n",
      "  Validation Accuracy after Epoch 32: 0.7340\n",
      "  Epoch [33/150], Batch [350/352], Train Acc: 0.7892 Loss: 0.6299\n",
      "  Validation Accuracy after Epoch 33: 0.7598\n",
      "  Epoch [34/150], Batch [350/352], Train Acc: 0.7890 Loss: 0.5659\n",
      "  Validation Accuracy after Epoch 34: 0.7532\n",
      "  Epoch [35/150], Batch [350/352], Train Acc: 0.7895 Loss: 0.5824\n",
      "  Validation Accuracy after Epoch 35: 0.7564\n",
      "  Epoch [36/150], Batch [350/352], Train Acc: 0.7905 Loss: 0.5729\n",
      "  Validation Accuracy after Epoch 36: 0.7402\n",
      "  Epoch [37/150], Batch [350/352], Train Acc: 0.7943 Loss: 0.6771\n",
      "  Validation Accuracy after Epoch 37: 0.7412\n",
      "  Epoch [38/150], Batch [350/352], Train Acc: 0.7944 Loss: 0.5808\n",
      "  Validation Accuracy after Epoch 38: 0.7808\n",
      "  Epoch [39/150], Batch [350/352], Train Acc: 0.7920 Loss: 0.4052\n",
      "  Validation Accuracy after Epoch 39: 0.7024\n",
      "  Epoch [40/150], Batch [350/352], Train Acc: 0.7948 Loss: 0.6853\n",
      "  Validation Accuracy after Epoch 40: 0.7368\n",
      "  Epoch [41/150], Batch [350/352], Train Acc: 0.7960 Loss: 0.5967\n",
      "  Validation Accuracy after Epoch 41: 0.7770\n",
      "  Epoch [42/150], Batch [350/352], Train Acc: 0.7951 Loss: 0.5122\n",
      "  Validation Accuracy after Epoch 42: 0.7690\n",
      "  Epoch [43/150], Batch [350/352], Train Acc: 0.7953 Loss: 0.5673\n",
      "  Validation Accuracy after Epoch 43: 0.7702\n",
      "  Epoch [44/150], Batch [350/352], Train Acc: 0.7954 Loss: 0.6104\n",
      "  Validation Accuracy after Epoch 44: 0.6816\n",
      "  Epoch [45/150], Batch [350/352], Train Acc: 0.7971 Loss: 0.4624\n",
      "  Validation Accuracy after Epoch 45: 0.7476\n",
      "  Epoch [46/150], Batch [350/352], Train Acc: 0.7990 Loss: 0.5716\n",
      "  Validation Accuracy after Epoch 46: 0.7868\n",
      "  Epoch [47/150], Batch [350/352], Train Acc: 0.7964 Loss: 0.5314\n",
      "  Validation Accuracy after Epoch 47: 0.7650\n",
      "  Epoch [48/150], Batch [350/352], Train Acc: 0.7992 Loss: 0.6657\n",
      "  Validation Accuracy after Epoch 48: 0.7692\n",
      "  Epoch [49/150], Batch [350/352], Train Acc: 0.7997 Loss: 0.6592\n",
      "  Validation Accuracy after Epoch 49: 0.7454\n",
      "  Epoch [50/150], Batch [350/352], Train Acc: 0.8030 Loss: 0.6689\n",
      "  Validation Accuracy after Epoch 50: 0.7560\n",
      "  Epoch [51/150], Batch [350/352], Train Acc: 0.8042 Loss: 0.4833\n",
      "  Validation Accuracy after Epoch 51: 0.7598\n",
      "  Epoch [52/150], Batch [350/352], Train Acc: 0.8007 Loss: 0.4471\n",
      "  Validation Accuracy after Epoch 52: 0.7794\n",
      "  Epoch [53/150], Batch [350/352], Train Acc: 0.8039 Loss: 0.6606\n",
      "  Validation Accuracy after Epoch 53: 0.7854\n",
      "  Epoch [54/150], Batch [350/352], Train Acc: 0.8040 Loss: 0.5604\n",
      "  Validation Accuracy after Epoch 54: 0.7626\n",
      "  Epoch [55/150], Batch [350/352], Train Acc: 0.8054 Loss: 0.5351\n",
      "  Validation Accuracy after Epoch 55: 0.7804\n",
      "  Epoch [56/150], Batch [350/352], Train Acc: 0.8033 Loss: 0.5198\n",
      "  Validation Accuracy after Epoch 56: 0.7864\n",
      "  Epoch [57/150], Batch [350/352], Train Acc: 0.8055 Loss: 0.5365\n",
      "  Validation Accuracy after Epoch 57: 0.7520\n",
      "  Epoch [58/150], Batch [350/352], Train Acc: 0.8029 Loss: 0.5719\n",
      "  Validation Accuracy after Epoch 58: 0.7690\n",
      "  Epoch [59/150], Batch [350/352], Train Acc: 0.8027 Loss: 0.4682\n",
      "  Validation Accuracy after Epoch 59: 0.7782\n",
      "  Epoch [60/150], Batch [350/352], Train Acc: 0.8079 Loss: 0.7520\n",
      "  Validation Accuracy after Epoch 60: 0.7788\n",
      "  Epoch [61/150], Batch [350/352], Train Acc: 0.8072 Loss: 0.5799\n",
      "  Validation Accuracy after Epoch 61: 0.7448\n",
      "  Epoch [62/150], Batch [350/352], Train Acc: 0.8080 Loss: 0.4428\n",
      "  Validation Accuracy after Epoch 62: 0.7874\n",
      "  Epoch [63/150], Batch [350/352], Train Acc: 0.8087 Loss: 0.6273\n",
      "  Validation Accuracy after Epoch 63: 0.7728\n",
      "  Epoch [64/150], Batch [350/352], Train Acc: 0.8092 Loss: 0.5422\n",
      "  Validation Accuracy after Epoch 64: 0.7784\n",
      "  Epoch [65/150], Batch [350/352], Train Acc: 0.8096 Loss: 0.5320\n",
      "  Validation Accuracy after Epoch 65: 0.7910\n",
      "  Epoch [66/150], Batch [350/352], Train Acc: 0.8076 Loss: 0.5822\n",
      "  Validation Accuracy after Epoch 66: 0.7710\n",
      "  Epoch [67/150], Batch [350/352], Train Acc: 0.8116 Loss: 0.5463\n",
      "  Validation Accuracy after Epoch 67: 0.7542\n",
      "  Epoch [68/150], Batch [350/352], Train Acc: 0.8092 Loss: 0.4034\n",
      "  Validation Accuracy after Epoch 68: 0.7674\n",
      "  Epoch [69/150], Batch [350/352], Train Acc: 0.8089 Loss: 0.6392\n",
      "  Validation Accuracy after Epoch 69: 0.7978\n",
      "  Epoch [70/150], Batch [350/352], Train Acc: 0.8119 Loss: 0.4984\n",
      "  Validation Accuracy after Epoch 70: 0.7824\n",
      "  Epoch [71/150], Batch [350/352], Train Acc: 0.8119 Loss: 0.3848\n",
      "  Validation Accuracy after Epoch 71: 0.6966\n",
      "  Epoch [72/150], Batch [350/352], Train Acc: 0.8125 Loss: 0.8089\n",
      "  Validation Accuracy after Epoch 72: 0.7722\n",
      "  Epoch [73/150], Batch [350/352], Train Acc: 0.8101 Loss: 0.5375\n",
      "  Validation Accuracy after Epoch 73: 0.7798\n",
      "  Epoch [74/150], Batch [350/352], Train Acc: 0.8137 Loss: 0.4596\n",
      "  Validation Accuracy after Epoch 74: 0.7764\n",
      "  Epoch [75/150], Batch [350/352], Train Acc: 0.8146 Loss: 0.5419\n",
      "  Validation Accuracy after Epoch 75: 0.7418\n",
      "  Epoch [76/150], Batch [350/352], Train Acc: 0.8150 Loss: 0.6384\n",
      "  Validation Accuracy after Epoch 76: 0.7584\n",
      "  Epoch [77/150], Batch [350/352], Train Acc: 0.8159 Loss: 0.5190\n",
      "  Validation Accuracy after Epoch 77: 0.7522\n",
      "  Epoch [78/150], Batch [350/352], Train Acc: 0.8159 Loss: 0.6050\n",
      "  Validation Accuracy after Epoch 78: 0.7864\n",
      "  Epoch [79/150], Batch [350/352], Train Acc: 0.8161 Loss: 0.4453\n",
      "  Validation Accuracy after Epoch 79: 0.7650\n",
      "  Epoch [80/150], Batch [350/352], Train Acc: 0.8180 Loss: 0.4642\n",
      "  Validation Accuracy after Epoch 80: 0.7860\n",
      "  Epoch [81/150], Batch [350/352], Train Acc: 0.8177 Loss: 0.4351\n",
      "  Validation Accuracy after Epoch 81: 0.7740\n",
      "  Epoch [82/150], Batch [350/352], Train Acc: 0.8165 Loss: 0.6863\n",
      "  Validation Accuracy after Epoch 82: 0.7822\n",
      "  Epoch [83/150], Batch [350/352], Train Acc: 0.8210 Loss: 0.5038\n",
      "  Validation Accuracy after Epoch 83: 0.8026\n",
      "  Epoch [84/150], Batch [350/352], Train Acc: 0.8189 Loss: 0.4066\n",
      "  Validation Accuracy after Epoch 84: 0.8084\n",
      "  Epoch [85/150], Batch [350/352], Train Acc: 0.8198 Loss: 0.5914\n",
      "  Validation Accuracy after Epoch 85: 0.7906\n",
      "  Epoch [86/150], Batch [350/352], Train Acc: 0.8194 Loss: 0.5586\n",
      "  Validation Accuracy after Epoch 86: 0.7984\n",
      "  Epoch [87/150], Batch [350/352], Train Acc: 0.8191 Loss: 0.5678\n",
      "  Validation Accuracy after Epoch 87: 0.7316\n",
      "  Epoch [88/150], Batch [350/352], Train Acc: 0.8218 Loss: 0.5434\n",
      "  Validation Accuracy after Epoch 88: 0.7786\n",
      "  Epoch [89/150], Batch [350/352], Train Acc: 0.8244 Loss: 0.4333\n",
      "  Validation Accuracy after Epoch 89: 0.8092\n",
      "  Epoch [90/150], Batch [350/352], Train Acc: 0.8227 Loss: 0.4934\n",
      "  Validation Accuracy after Epoch 90: 0.8072\n",
      "  Epoch [91/150], Batch [350/352], Train Acc: 0.8240 Loss: 0.6032\n",
      "  Validation Accuracy after Epoch 91: 0.8082\n",
      "  Epoch [92/150], Batch [350/352], Train Acc: 0.8219 Loss: 0.6211\n",
      "  Validation Accuracy after Epoch 92: 0.8034\n",
      "  Epoch [93/150], Batch [350/352], Train Acc: 0.8266 Loss: 0.5537\n",
      "  Validation Accuracy after Epoch 93: 0.7838\n",
      "  Epoch [94/150], Batch [350/352], Train Acc: 0.8282 Loss: 0.4263\n",
      "  Validation Accuracy after Epoch 94: 0.7830\n",
      "  Epoch [95/150], Batch [350/352], Train Acc: 0.8277 Loss: 0.4210\n",
      "  Validation Accuracy after Epoch 95: 0.8092\n",
      "  Epoch [96/150], Batch [350/352], Train Acc: 0.8294 Loss: 0.5319\n",
      "  Validation Accuracy after Epoch 96: 0.8136\n",
      "  Epoch [97/150], Batch [350/352], Train Acc: 0.8295 Loss: 0.5580\n",
      "  Validation Accuracy after Epoch 97: 0.8256\n",
      "  Epoch [98/150], Batch [350/352], Train Acc: 0.8306 Loss: 0.3503\n",
      "  Validation Accuracy after Epoch 98: 0.7884\n",
      "  Epoch [99/150], Batch [350/352], Train Acc: 0.8312 Loss: 0.4054\n",
      "  Validation Accuracy after Epoch 99: 0.8224\n",
      "  Epoch [100/150], Batch [350/352], Train Acc: 0.8340 Loss: 0.5033\n",
      "  Validation Accuracy after Epoch 100: 0.7910\n",
      "  Epoch [101/150], Batch [350/352], Train Acc: 0.8349 Loss: 0.5454\n",
      "  Validation Accuracy after Epoch 101: 0.8164\n",
      "  Epoch [102/150], Batch [350/352], Train Acc: 0.8361 Loss: 0.4984\n",
      "  Validation Accuracy after Epoch 102: 0.8124\n",
      "  Epoch [103/150], Batch [350/352], Train Acc: 0.8364 Loss: 0.4597\n",
      "  Validation Accuracy after Epoch 103: 0.8306\n",
      "  Epoch [104/150], Batch [350/352], Train Acc: 0.8380 Loss: 0.4510\n",
      "  Validation Accuracy after Epoch 104: 0.8224\n",
      "  Epoch [105/150], Batch [350/352], Train Acc: 0.8394 Loss: 0.4233\n",
      "  Validation Accuracy after Epoch 105: 0.8140\n",
      "  Epoch [106/150], Batch [350/352], Train Acc: 0.8434 Loss: 0.4187\n",
      "  Validation Accuracy after Epoch 106: 0.8246\n",
      "  Epoch [107/150], Batch [350/352], Train Acc: 0.8414 Loss: 0.4090\n",
      "  Validation Accuracy after Epoch 107: 0.8234\n",
      "  Epoch [108/150], Batch [350/352], Train Acc: 0.8455 Loss: 0.3845\n",
      "  Validation Accuracy after Epoch 108: 0.7970\n",
      "  Epoch [109/150], Batch [350/352], Train Acc: 0.8469 Loss: 0.3091\n",
      "  Validation Accuracy after Epoch 109: 0.8312\n",
      "  Epoch [110/150], Batch [350/352], Train Acc: 0.8468 Loss: 0.4983\n",
      "  Validation Accuracy after Epoch 110: 0.8110\n",
      "  Epoch [111/150], Batch [350/352], Train Acc: 0.8486 Loss: 0.4733\n",
      "  Validation Accuracy after Epoch 111: 0.8190\n",
      "  Epoch [112/150], Batch [350/352], Train Acc: 0.8499 Loss: 0.4982\n",
      "  Validation Accuracy after Epoch 112: 0.8260\n",
      "  Epoch [113/150], Batch [350/352], Train Acc: 0.8531 Loss: 0.4819\n",
      "  Validation Accuracy after Epoch 113: 0.8378\n",
      "  Epoch [114/150], Batch [350/352], Train Acc: 0.8515 Loss: 0.3175\n",
      "  Validation Accuracy after Epoch 114: 0.8346\n",
      "  Epoch [115/150], Batch [350/352], Train Acc: 0.8569 Loss: 0.4389\n",
      "  Validation Accuracy after Epoch 115: 0.8302\n",
      "  Epoch [116/150], Batch [350/352], Train Acc: 0.8580 Loss: 0.3447\n",
      "  Validation Accuracy after Epoch 116: 0.8350\n",
      "  Epoch [117/150], Batch [350/352], Train Acc: 0.8600 Loss: 0.3681\n",
      "  Validation Accuracy after Epoch 117: 0.8392\n",
      "  Epoch [118/150], Batch [350/352], Train Acc: 0.8633 Loss: 0.3889\n",
      "  Validation Accuracy after Epoch 118: 0.8280\n",
      "  Epoch [119/150], Batch [350/352], Train Acc: 0.8637 Loss: 0.4768\n",
      "  Validation Accuracy after Epoch 119: 0.8504\n",
      "  Epoch [120/150], Batch [350/352], Train Acc: 0.8642 Loss: 0.3769\n",
      "  Validation Accuracy after Epoch 120: 0.8490\n",
      "  Epoch [121/150], Batch [350/352], Train Acc: 0.8671 Loss: 0.4384\n",
      "  Validation Accuracy after Epoch 121: 0.8550\n",
      "  Epoch [122/150], Batch [350/352], Train Acc: 0.8697 Loss: 0.4857\n",
      "  Validation Accuracy after Epoch 122: 0.8462\n",
      "  Epoch [123/150], Batch [350/352], Train Acc: 0.8767 Loss: 0.3904\n",
      "  Validation Accuracy after Epoch 123: 0.8390\n",
      "  Epoch [124/150], Batch [350/352], Train Acc: 0.8764 Loss: 0.2738\n",
      "  Validation Accuracy after Epoch 124: 0.8356\n",
      "  Epoch [125/150], Batch [350/352], Train Acc: 0.8772 Loss: 0.2928\n",
      "  Validation Accuracy after Epoch 125: 0.8400\n",
      "  Epoch [126/150], Batch [350/352], Train Acc: 0.8845 Loss: 0.4384\n",
      "  Validation Accuracy after Epoch 126: 0.8616\n",
      "  Epoch [127/150], Batch [350/352], Train Acc: 0.8836 Loss: 0.2651\n",
      "  Validation Accuracy after Epoch 127: 0.8590\n",
      "  Epoch [128/150], Batch [350/352], Train Acc: 0.8917 Loss: 0.2179\n",
      "  Validation Accuracy after Epoch 128: 0.8624\n",
      "  Epoch [129/150], Batch [350/352], Train Acc: 0.8921 Loss: 0.3466\n",
      "  Validation Accuracy after Epoch 129: 0.8780\n",
      "  Epoch [130/150], Batch [350/352], Train Acc: 0.8956 Loss: 0.2662\n",
      "  Validation Accuracy after Epoch 130: 0.8534\n",
      "  Epoch [131/150], Batch [350/352], Train Acc: 0.8969 Loss: 0.3201\n",
      "  Validation Accuracy after Epoch 131: 0.8770\n",
      "  Epoch [132/150], Batch [350/352], Train Acc: 0.9033 Loss: 0.3292\n",
      "  Validation Accuracy after Epoch 132: 0.8744\n",
      "  Epoch [133/150], Batch [350/352], Train Acc: 0.9075 Loss: 0.3127\n",
      "  Validation Accuracy after Epoch 133: 0.8828\n",
      "  Epoch [134/150], Batch [350/352], Train Acc: 0.9099 Loss: 0.2361\n",
      "  Validation Accuracy after Epoch 134: 0.8752\n",
      "  Epoch [135/150], Batch [350/352], Train Acc: 0.9129 Loss: 0.3593\n",
      "  Validation Accuracy after Epoch 135: 0.8906\n",
      "  Epoch [136/150], Batch [350/352], Train Acc: 0.9178 Loss: 0.3393\n",
      "  Validation Accuracy after Epoch 136: 0.8896\n",
      "  Epoch [137/150], Batch [350/352], Train Acc: 0.9224 Loss: 0.3090\n",
      "  Validation Accuracy after Epoch 137: 0.8856\n",
      "  Epoch [138/150], Batch [350/352], Train Acc: 0.9258 Loss: 0.1408\n",
      "  Validation Accuracy after Epoch 138: 0.8918\n",
      "  Epoch [139/150], Batch [350/352], Train Acc: 0.9312 Loss: 0.2720\n",
      "  Validation Accuracy after Epoch 139: 0.8978\n",
      "  Epoch [140/150], Batch [350/352], Train Acc: 0.9337 Loss: 0.2159\n",
      "  Validation Accuracy after Epoch 140: 0.8988\n",
      "  Epoch [141/150], Batch [350/352], Train Acc: 0.9374 Loss: 0.2307\n",
      "  Validation Accuracy after Epoch 141: 0.8996\n",
      "  Epoch [142/150], Batch [350/352], Train Acc: 0.9396 Loss: 0.1972\n",
      "  Validation Accuracy after Epoch 142: 0.9066\n",
      "  Epoch [143/150], Batch [350/352], Train Acc: 0.9453 Loss: 0.2186\n",
      "  Validation Accuracy after Epoch 143: 0.9080\n",
      "  Epoch [144/150], Batch [350/352], Train Acc: 0.9468 Loss: 0.1351\n",
      "  Validation Accuracy after Epoch 144: 0.9058\n",
      "  Epoch [145/150], Batch [350/352], Train Acc: 0.9468 Loss: 0.1728\n",
      "  Validation Accuracy after Epoch 145: 0.9016\n",
      "  Epoch [146/150], Batch [350/352], Train Acc: 0.9490 Loss: 0.1509\n",
      "  Validation Accuracy after Epoch 146: 0.9056\n",
      "  Epoch [147/150], Batch [350/352], Train Acc: 0.9506 Loss: 0.1251\n",
      "  Validation Accuracy after Epoch 147: 0.9036\n",
      "  Epoch [148/150], Batch [220/352], Train Acc: 0.9526 Loss: 0.1414"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "study_name = f\"study_{timestamp}\"    \n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=study_name)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model.to(device)\n",
    "\n",
    "# checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "# with open(os.path.join(checkpoint_dir, \"study_details.json\"), \"r\") as f:\n",
    "#     study_details = json.load(f)\n",
    "# best_checkpoint_fp = study_details[str(study.best_trial.number)][\"checkpoint_path\"]\n",
    "best_checkpoint_fp = \"checkpoints_study_2025-03-10_02-34-32/model_trial_0_val_acc_0.9262.pth\"\n",
    "\n",
    "# Load the latest checkpoint\n",
    "checkpoint = torch.load(best_checkpoint_fp)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9365\n"
     ]
    }
   ],
   "source": [
    "from trainer import evaluate_model\n",
    "from data_loader import get_test_dataloader\n",
    "\n",
    "test_loader = get_test_dataloader()\n",
    "acc = evaluate_model(model, test_loader, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on cifar10.1 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.859\n"
     ]
    }
   ],
   "source": [
    "from cifar10_1_dataloader import get_dataloader_10_1\n",
    "dataloader_10_1 = get_dataloader_10_1()\n",
    "\n",
    "acc = evaluate_model(model, dataloader_10_1, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on Kaggle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_kaggle_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission file saved.\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file with test data\n",
    "kaggle_test_loader = get_kaggle_test_dataloader()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in kaggle_test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67.3k/67.3k [00:00<00:00, 330kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Deep Learning Spring 2025: CIFAR 10 classification"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import kaggle\n",
    "# kaggle.api.competition_submit(\n",
    "#     file_name=\"submission.csv\",\n",
    "#     message=\"0.9365\",\n",
    "#     competition=\"deep-learning-spring-2025-project-1\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk8i7jiGjSg0feqDTW0l2u",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
