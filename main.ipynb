{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIugLjz-A2Qd"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import optuna\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "from data_loader import get_cifar10_dataloaders, get_test_dataloader, get_kaggle_test_dataloader\n",
    "from helper import optimizer_map, scheduler_map, num_params, update_study_details\n",
    "from models import BaseResNet, EfficientNetB0, SmallResNet0, LargeResNet0\n",
    "from trainer import train_model\n",
    "from run import single_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4z7iY1pkk2C"
   },
   "source": [
    "Configure the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e3wMn_41kd5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    study_dir = f\"studies/{trial.study.study_name}\"\n",
    "    os.makedirs(study_dir, exist_ok=True) # Create a directory for checkpoints if it doesn't exist\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    num_epochs = 250 # trial.suggest_int(\"num_epochs\", 20, 35)\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"smallresnet\", \"efficientnet\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "    optimizer_type = trial.suggest_categorical(\"optimizer_type\", [\"Adam\", \"SGD\"]) # Rmed: RMSprop\n",
    "    scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"ReduceLROnPlateau\", \"OneCycleLR\"]) # Rmed: StepLR\n",
    "    \n",
    "    optimizer_params = {\n",
    "        \"weight_decay\": trial.suggest_categorical(\"weight_decay\", [1e-4, 5e-4])\n",
    "    }\n",
    "    \n",
    "    if optimizer_type == \"SGD\":\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True)\n",
    "        optimizer_params[\"momentum\"] = 0.9 # trial.suggest_float(\"momentum\", 0.8, 0.9)\n",
    "        optimizer_params[\"nesterov\"] = True #bool(trial.suggest_categorical(\"nesterov\", [0, 1]))\n",
    "        optimizer_params[\"weight_decay\"] = 5e-4\n",
    "    else:\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 0.0001, 0.001, log=True)\n",
    "        optimizer_params[\"weight_decay\"] = 1e-4\n",
    "        \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4, fill=0),  \n",
    "        transforms.RandomHorizontalFlip(p=0.5),  \n",
    "        transforms.RandomRotation(degrees=15),  \n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  \n",
    "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    \n",
    "    train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "        train_transform,\n",
    "        subset_percent=1, \n",
    "        valid_size=0.1,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        use_kaggle=True\n",
    "    )\n",
    "\n",
    "    scheduler_params = {}\n",
    "    if scheduler_type == \"StepLR\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 150, 200)\n",
    "        scheduler_params[\"step_size\"] = trial.suggest_int(\"step_size\", 5, 20)\n",
    "        scheduler_params[\"gamma\"] = trial.suggest_float(\"gamma\", 0.1, 0.9)\n",
    "        \n",
    "    elif scheduler_type == \"CosineAnnealingLR\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 100, 150)\n",
    "        scheduler_params[\"T_max\"] = num_epochs\n",
    "        \n",
    "    elif scheduler_type == \"ReduceLROnPlateau\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 75, 125)\n",
    "        scheduler_params[\"factor\"] = trial.suggest_float(\"factor\", 0.1, 0.9)\n",
    "        scheduler_params[\"patience\"] = trial.suggest_int(\"patience\", 2, 10)\n",
    "        scheduler_params[\"mode\"] = \"min\"\n",
    "        \n",
    "    elif scheduler_type == \"OneCycleLR\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 50, 75)\n",
    "        scheduler_params[\"max_lr\"] = 0.1\n",
    "        scheduler_params[\"steps_per_epoch\"] = len(train_loader)\n",
    "        scheduler_params[\"epochs\"] = num_epochs\n",
    "            \n",
    "    # Select Model\n",
    "    if model_type == \"smallresnet\":\n",
    "        model = SmallResNet0()\n",
    "    elif model_type == \"efficientnet\":\n",
    "        model = EfficientNetB0()\n",
    "    else:\n",
    "        model = BaseResNet()\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    trial_details = trial.params.copy()\n",
    "    trial_details[\"model_name\"] = model.__class__.__name__\n",
    "    trial_details[\"trainable_parameters\"] = num_params(model)\n",
    "    \n",
    "    # Print trial details\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{trial.number=}\")\n",
    "    for param, val in trial_details.items():\n",
    "        print(f\"{param}: {val}\")\n",
    "    print(\"- \" * 25)\n",
    "    update_study_details(study_dir, trial.number, trial_details)\n",
    "\n",
    "    optimizer = optimizer_map[optimizer_type](model.parameters(), **optimizer_params)\n",
    "    scheduler = scheduler_map[scheduler_type](optimizer, **scheduler_params)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # Checkpoint the model with the best validation accuracy\n",
    "    chkpt_dir = os.path.join(study_dir, \"checkpoint\")\n",
    "    plot_dir = os.path.join(study_dir, \"plots\")\n",
    "    os.makedirs(chkpt_dir, exist_ok=True)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        model, train_loader, criterion, optimizer, valid_loader=valid_loader, num_epochs=num_epochs, \n",
    "        device=device, scheduler=scheduler, trial=trial, chkpt_dir=chkpt_dir, plot_dir=plot_dir\n",
    "    )\n",
    "    \n",
    "    trial_details[\"best_val_accuracy\"] = best_val_accuracy\n",
    "    update_study_details(study_dir, trial.number, trial_details)\n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start new study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 01:51:42,621] A new study created in RDB with name: study_2025-03-11_01-51-41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=0\n",
      "model_type: smallresnet\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "weight_decay: 0.0005\n",
      "learning_rate: 0.00032214137835438034\n",
      "num_epochs: 115\n",
      "factor: 0.3825196441327009\n",
      "patience: 6\n",
      "model_name: SmallResNet\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/115], Batch [350/352], Train Acc: 29.2232 Loss: 1.8798\n",
      "  Validation Accuracy after Epoch 1: 37.3200\n",
      "  Epoch [2/115], Batch [350/352], Train Acc: 41.5246 Loss: 1.6083\n",
      "  Validation Accuracy after Epoch 2: 44.4000\n",
      "  Epoch [3/115], Batch [350/352], Train Acc: 48.6205 Loss: 1.5436\n",
      "  Validation Accuracy after Epoch 3: 47.8200\n",
      "  Epoch [4/115], Batch [350/352], Train Acc: 53.0580 Loss: 1.6191\n",
      "  Validation Accuracy after Epoch 4: 51.8200\n",
      "  Epoch [5/115], Batch [350/352], Train Acc: 56.9330 Loss: 1.5187\n",
      "  Validation Accuracy after Epoch 5: 54.1400\n",
      "  Epoch [6/115], Batch [350/352], Train Acc: 60.1250 Loss: 1.2948\n",
      "  Validation Accuracy after Epoch 6: 57.7000\n",
      "  Epoch [7/115], Batch [350/352], Train Acc: 62.4576 Loss: 1.3258\n",
      "  Validation Accuracy after Epoch 7: 57.3000\n",
      "  Epoch [8/115], Batch [350/352], Train Acc: 64.6741 Loss: 1.2359\n",
      "  Validation Accuracy after Epoch 8: 62.0600\n",
      "  Epoch [9/115], Batch [350/352], Train Acc: 66.1875 Loss: 1.2882\n",
      "  Validation Accuracy after Epoch 9: 63.5600\n",
      "  Epoch [10/115], Batch [350/352], Train Acc: 67.6830 Loss: 1.1963\n",
      "  Validation Accuracy after Epoch 10: 59.9000\n",
      "  Epoch [11/115], Batch [350/352], Train Acc: 68.8460 Loss: 1.1710\n",
      "  Validation Accuracy after Epoch 11: 66.5800\n",
      "  Epoch [12/115], Batch [350/352], Train Acc: 69.3371 Loss: 1.1564\n",
      "  Validation Accuracy after Epoch 12: 63.2200\n",
      "  Epoch [13/115], Batch [350/352], Train Acc: 70.6629 Loss: 1.1124\n",
      "  Validation Accuracy after Epoch 13: 67.9600\n",
      "  Epoch [14/115], Batch [350/352], Train Acc: 71.8170 Loss: 1.1207\n",
      "  Validation Accuracy after Epoch 14: 69.0000\n",
      "  Epoch [15/115], Batch [350/352], Train Acc: 72.2835 Loss: 1.1338\n",
      "  Validation Accuracy after Epoch 15: 70.2200\n",
      "  Epoch [16/115], Batch [350/352], Train Acc: 72.7991 Loss: 1.0157\n",
      "  Validation Accuracy after Epoch 16: 70.5800\n",
      "  Epoch [17/115], Batch [350/352], Train Acc: 73.6786 Loss: 1.1449\n",
      "  Validation Accuracy after Epoch 17: 70.8200\n",
      "  Epoch [18/115], Batch [350/352], Train Acc: 74.1071 Loss: 1.0693\n",
      "  Validation Accuracy after Epoch 18: 69.8400\n",
      "  Epoch [19/115], Batch [350/352], Train Acc: 74.8571 Loss: 1.1466\n",
      "  Validation Accuracy after Epoch 19: 73.6400\n",
      "  Epoch [20/115], Batch [350/352], Train Acc: 75.5246 Loss: 1.0456\n",
      "  Validation Accuracy after Epoch 20: 73.1800\n",
      "  Epoch [21/115], Batch [350/352], Train Acc: 75.3772 Loss: 1.0488\n",
      "  Validation Accuracy after Epoch 21: 71.7200\n",
      "  Epoch [22/115], Batch [350/352], Train Acc: 76.3438 Loss: 1.0445\n",
      "  Validation Accuracy after Epoch 22: 73.5000\n",
      "  Epoch [23/115], Batch [350/352], Train Acc: 76.7009 Loss: 1.0149\n",
      "  Validation Accuracy after Epoch 23: 74.8400\n",
      "  Epoch [24/115], Batch [350/352], Train Acc: 77.0179 Loss: 1.0141\n",
      "  Validation Accuracy after Epoch 24: 72.3000\n",
      "  Epoch [25/115], Batch [350/352], Train Acc: 77.3683 Loss: 0.9575\n",
      "  Validation Accuracy after Epoch 25: 74.8200\n",
      "  Epoch [26/115], Batch [350/352], Train Acc: 77.4955 Loss: 0.9963\n",
      "  Validation Accuracy after Epoch 26: 74.1200\n",
      "  Epoch [27/115], Batch [350/352], Train Acc: 78.0201 Loss: 0.9688\n",
      "  Validation Accuracy after Epoch 27: 76.2000\n",
      "  Epoch [28/115], Batch [350/352], Train Acc: 78.3705 Loss: 0.9920\n",
      "  Validation Accuracy after Epoch 28: 76.2400\n",
      "  Epoch [29/115], Batch [350/352], Train Acc: 78.6272 Loss: 0.9276\n",
      "  Validation Accuracy after Epoch 29: 75.3400\n",
      "  Epoch [30/115], Batch [350/352], Train Acc: 79.0112 Loss: 0.9816\n",
      "  Validation Accuracy after Epoch 30: 77.2800\n",
      "  Epoch [31/115], Batch [350/352], Train Acc: 79.4018 Loss: 0.8373\n",
      "  Validation Accuracy after Epoch 31: 76.6600\n",
      "  Epoch [32/115], Batch [350/352], Train Acc: 79.5647 Loss: 0.9817\n",
      "  Validation Accuracy after Epoch 32: 76.4000\n",
      "  Epoch [33/115], Batch [350/352], Train Acc: 79.8281 Loss: 0.9703\n",
      "  Validation Accuracy after Epoch 33: 77.2000\n",
      "  Epoch [34/115], Batch [350/352], Train Acc: 80.2545 Loss: 0.9980\n",
      "  Validation Accuracy after Epoch 34: 76.3400\n",
      "  Epoch [35/115], Batch [350/352], Train Acc: 80.1384 Loss: 0.9098\n",
      "  Validation Accuracy after Epoch 35: 78.8600\n",
      "  Epoch [36/115], Batch [350/352], Train Acc: 80.7411 Loss: 1.0712\n",
      "  Validation Accuracy after Epoch 36: 77.9000\n",
      "  Epoch [37/115], Batch [350/352], Train Acc: 81.1049 Loss: 0.9748\n",
      "  Validation Accuracy after Epoch 37: 78.2600\n",
      "  Epoch [38/115], Batch [350/352], Train Acc: 80.9286 Loss: 0.9373\n",
      "  Validation Accuracy after Epoch 38: 77.8000\n",
      "  Epoch [39/115], Batch [350/352], Train Acc: 81.2210 Loss: 0.8792\n",
      "  Validation Accuracy after Epoch 39: 78.0600\n",
      "  Epoch [40/115], Batch [350/352], Train Acc: 81.3996 Loss: 0.8968\n",
      "  Validation Accuracy after Epoch 40: 79.1000\n",
      "  Epoch [41/115], Batch [350/352], Train Acc: 81.7902 Loss: 0.9228\n",
      "  Validation Accuracy after Epoch 41: 78.8000\n",
      "  Epoch [42/115], Batch [350/352], Train Acc: 82.0112 Loss: 0.8493\n",
      "  Validation Accuracy after Epoch 42: 79.4800\n",
      "  Epoch [43/115], Batch [350/352], Train Acc: 82.1607 Loss: 0.9216\n",
      "  Validation Accuracy after Epoch 43: 78.3400\n",
      "  Epoch [44/115], Batch [350/352], Train Acc: 82.2277 Loss: 0.9236\n",
      "  Validation Accuracy after Epoch 44: 76.5800\n",
      "  Epoch [45/115], Batch [350/352], Train Acc: 82.4665 Loss: 1.0150\n",
      "  Validation Accuracy after Epoch 45: 79.4800\n",
      "  Epoch [46/115], Batch [350/352], Train Acc: 82.6250 Loss: 0.9646\n",
      "  Validation Accuracy after Epoch 46: 79.6000\n",
      "  Epoch [47/115], Batch [350/352], Train Acc: 82.7545 Loss: 0.8821\n",
      "  Validation Accuracy after Epoch 47: 78.8400\n",
      "  Epoch [48/115], Batch [350/352], Train Acc: 83.1362 Loss: 0.8642\n",
      "  Validation Accuracy after Epoch 48: 79.2200\n",
      "  Epoch [49/115], Batch [350/352], Train Acc: 83.0603 Loss: 0.8774\n",
      "  Validation Accuracy after Epoch 49: 78.6600\n",
      "  Epoch [50/115], Batch [350/352], Train Acc: 83.2991 Loss: 0.9652\n",
      "  Validation Accuracy after Epoch 50: 79.6400\n",
      "  Epoch [51/115], Batch [350/352], Train Acc: 83.5179 Loss: 0.8064\n",
      "  Validation Accuracy after Epoch 51: 80.0000\n",
      "  Epoch [52/115], Batch [350/352], Train Acc: 83.5982 Loss: 1.0239\n",
      "  Validation Accuracy after Epoch 52: 80.1400\n",
      "  Epoch [53/115], Batch [350/352], Train Acc: 83.6652 Loss: 0.9564\n",
      "  Validation Accuracy after Epoch 53: 79.6800\n",
      "  Epoch [54/115], Batch [350/352], Train Acc: 83.7321 Loss: 0.9082\n",
      "  Validation Accuracy after Epoch 54: 80.7800\n",
      "  Epoch [55/115], Batch [350/352], Train Acc: 83.8638 Loss: 0.9042\n",
      "  Validation Accuracy after Epoch 55: 80.4200\n",
      "  Epoch [56/115], Batch [350/352], Train Acc: 84.2232 Loss: 0.8896\n",
      "  Validation Accuracy after Epoch 56: 80.0200\n",
      "  Epoch [57/115], Batch [350/352], Train Acc: 84.2478 Loss: 0.8788\n",
      "  Validation Accuracy after Epoch 57: 80.1000\n",
      "  Epoch [58/115], Batch [350/352], Train Acc: 84.5223 Loss: 0.7202\n",
      "  Validation Accuracy after Epoch 58: 81.1400\n",
      "  Epoch [59/115], Batch [350/352], Train Acc: 84.3884 Loss: 0.8642\n",
      "  Validation Accuracy after Epoch 59: 79.9000\n",
      "  Epoch [60/115], Batch [350/352], Train Acc: 84.6562 Loss: 0.9752\n",
      "  Validation Accuracy after Epoch 60: 81.0400\n",
      "  Epoch [61/115], Batch [350/352], Train Acc: 84.5513 Loss: 0.9128\n",
      "  Validation Accuracy after Epoch 61: 81.2400\n",
      "  Epoch [62/115], Batch [350/352], Train Acc: 84.9732 Loss: 0.7898\n",
      "  Validation Accuracy after Epoch 62: 80.9600\n",
      "  Epoch [63/115], Batch [350/352], Train Acc: 85.0513 Loss: 0.8846\n",
      "  Validation Accuracy after Epoch 63: 81.9200\n",
      "  Epoch [64/115], Batch [350/352], Train Acc: 85.3281 Loss: 0.8811\n",
      "  Validation Accuracy after Epoch 64: 81.2000\n",
      "  Epoch [65/115], Batch [350/352], Train Acc: 85.2790 Loss: 0.8690\n",
      "  Validation Accuracy after Epoch 65: 81.6800\n",
      "  Epoch [66/115], Batch [350/352], Train Acc: 85.3460 Loss: 0.7897\n",
      "  Validation Accuracy after Epoch 66: 81.6600\n",
      "  Epoch [67/115], Batch [350/352], Train Acc: 85.4062 Loss: 0.8913\n",
      "  Validation Accuracy after Epoch 67: 82.0000\n",
      "  Epoch [68/115], Batch [350/352], Train Acc: 85.6674 Loss: 0.8478\n",
      "  Validation Accuracy after Epoch 68: 80.3400\n",
      "  Epoch [69/115], Batch [350/352], Train Acc: 85.8281 Loss: 0.8682\n",
      "  Validation Accuracy after Epoch 69: 80.8800\n",
      "  Epoch [70/115], Batch [350/352], Train Acc: 85.6272 Loss: 0.8430\n",
      "  Validation Accuracy after Epoch 70: 81.8800\n",
      "  Epoch [71/115], Batch [350/352], Train Acc: 87.4487 Loss: 0.8366\n",
      "  Validation Accuracy after Epoch 71: 83.6200\n",
      "  Epoch [72/115], Batch [350/352], Train Acc: 87.9241 Loss: 0.6763\n",
      "  Validation Accuracy after Epoch 72: 84.7400\n",
      "  Epoch [73/115], Batch [350/352], Train Acc: 88.0379 Loss: 0.7668\n",
      "  Validation Accuracy after Epoch 73: 84.4200\n",
      "  Epoch [74/115], Batch [350/352], Train Acc: 88.2545 Loss: 0.8400\n",
      "  Validation Accuracy after Epoch 74: 84.8600\n",
      "  Epoch [75/115], Batch [350/352], Train Acc: 88.4286 Loss: 0.7426\n",
      "  Validation Accuracy after Epoch 75: 83.6600\n",
      "  Epoch [76/115], Batch [350/352], Train Acc: 88.4933 Loss: 0.7218\n",
      "  Validation Accuracy after Epoch 76: 84.7400\n",
      "  Epoch [77/115], Batch [350/352], Train Acc: 88.7388 Loss: 0.7038\n",
      "  Validation Accuracy after Epoch 77: 84.5600\n",
      "  Epoch [78/115], Batch [350/352], Train Acc: 88.6384 Loss: 0.7599\n",
      "  Validation Accuracy after Epoch 78: 84.2600\n",
      "  Epoch [79/115], Batch [350/352], Train Acc: 88.8393 Loss: 0.7931\n",
      "  Validation Accuracy after Epoch 79: 83.6400\n",
      "  Epoch [80/115], Batch [350/352], Train Acc: 89.2991 Loss: 0.7227\n",
      "  Validation Accuracy after Epoch 80: 84.7400\n",
      "  Epoch [81/115], Batch [350/352], Train Acc: 89.6228 Loss: 0.7415\n",
      "  Validation Accuracy after Epoch 81: 85.3000\n",
      "  Epoch [82/115], Batch [350/352], Train Acc: 89.6964 Loss: 0.7496\n",
      "  Validation Accuracy after Epoch 82: 85.4200\n",
      "  Epoch [83/115], Batch [350/352], Train Acc: 89.8750 Loss: 0.6824\n",
      "  Validation Accuracy after Epoch 83: 85.7200\n",
      "  Epoch [84/115], Batch [350/352], Train Acc: 89.7009 Loss: 0.7929\n",
      "  Validation Accuracy after Epoch 84: 85.8400\n",
      "  Epoch [85/115], Batch [350/352], Train Acc: 89.6875 Loss: 0.7631\n",
      "  Validation Accuracy after Epoch 85: 85.9800\n",
      "  Epoch [86/115], Batch [350/352], Train Acc: 89.7946 Loss: 0.7217\n",
      "  Validation Accuracy after Epoch 86: 85.5400\n",
      "  Epoch [87/115], Batch [350/352], Train Acc: 89.7879 Loss: 0.7229\n",
      "  Validation Accuracy after Epoch 87: 84.9800\n",
      "  Epoch [88/115], Batch [350/352], Train Acc: 90.1295 Loss: 0.7541\n",
      "  Validation Accuracy after Epoch 88: 85.0600\n",
      "  Epoch [89/115], Batch [350/352], Train Acc: 89.9866 Loss: 0.7017\n",
      "  Validation Accuracy after Epoch 89: 85.0800\n",
      "  Epoch [90/115], Batch [350/352], Train Acc: 90.0692 Loss: 0.7506\n",
      "  Validation Accuracy after Epoch 90: 85.2200\n",
      "  Epoch [91/115], Batch [350/352], Train Acc: 90.0469 Loss: 0.6833\n",
      "  Validation Accuracy after Epoch 91: 85.6600\n",
      "  Epoch [92/115], Batch [350/352], Train Acc: 90.2232 Loss: 0.7168\n",
      "  Validation Accuracy after Epoch 92: 85.9600\n",
      "  Epoch [93/115], Batch [350/352], Train Acc: 90.3326 Loss: 0.7036\n",
      "  Validation Accuracy after Epoch 93: 86.3000\n",
      "  Epoch [94/115], Batch [350/352], Train Acc: 90.4085 Loss: 0.7094\n",
      "  Validation Accuracy after Epoch 94: 85.5800\n",
      "  Epoch [95/115], Batch [350/352], Train Acc: 90.3884 Loss: 0.7590\n",
      "  Validation Accuracy after Epoch 95: 86.2600\n",
      "  Epoch [96/115], Batch [350/352], Train Acc: 90.3438 Loss: 0.6863\n",
      "  Validation Accuracy after Epoch 96: 85.6800\n",
      "  Epoch [97/115], Batch [350/352], Train Acc: 90.4732 Loss: 0.6811\n",
      "  Validation Accuracy after Epoch 97: 85.6400\n",
      "  Epoch [98/115], Batch [350/352], Train Acc: 90.5402 Loss: 0.6928\n",
      "  Validation Accuracy after Epoch 98: 85.9400\n",
      "  Epoch [99/115], Batch [350/352], Train Acc: 90.5134 Loss: 0.6476\n",
      "  Validation Accuracy after Epoch 99: 85.9600\n",
      "  Epoch [100/115], Batch [350/352], Train Acc: 90.5156 Loss: 0.7884\n",
      "  Validation Accuracy after Epoch 100: 85.9000\n",
      "  Epoch [101/115], Batch [350/352], Train Acc: 90.5000 Loss: 0.8034\n",
      "  Validation Accuracy after Epoch 101: 86.7000\n",
      "  Epoch [102/115], Batch [350/352], Train Acc: 90.5982 Loss: 0.6364\n",
      "  Validation Accuracy after Epoch 102: 85.8000\n",
      "  Epoch [103/115], Batch [350/352], Train Acc: 90.5134 Loss: 0.7504\n",
      "  Validation Accuracy after Epoch 103: 85.1400\n",
      "  Epoch [104/115], Batch [350/352], Train Acc: 90.5871 Loss: 0.7483\n",
      "  Validation Accuracy after Epoch 104: 86.4800\n",
      "  Epoch [105/115], Batch [350/352], Train Acc: 90.8326 Loss: 0.6271\n",
      "  Validation Accuracy after Epoch 105: 85.4200\n",
      "  Epoch [106/115], Batch [350/352], Train Acc: 90.7165 Loss: 0.7582\n",
      "  Validation Accuracy after Epoch 106: 86.2000\n",
      "  Epoch [107/115], Batch [350/352], Train Acc: 90.7098 Loss: 0.7661\n",
      "  Validation Accuracy after Epoch 107: 85.8800\n",
      "  Epoch [108/115], Batch [350/352], Train Acc: 90.7165 Loss: 0.6859\n",
      "  Validation Accuracy after Epoch 108: 86.2400\n",
      "  Epoch [109/115], Batch [350/352], Train Acc: 90.8192 Loss: 0.7571\n",
      "  Validation Accuracy after Epoch 109: 85.7600\n",
      "  Epoch [110/115], Batch [350/352], Train Acc: 90.7545 Loss: 0.6855\n",
      "  Validation Accuracy after Epoch 110: 86.3600\n",
      "  Epoch [111/115], Batch [350/352], Train Acc: 90.7031 Loss: 0.6770\n",
      "  Validation Accuracy after Epoch 111: 86.4200\n",
      "  Epoch [112/115], Batch [350/352], Train Acc: 90.8862 Loss: 0.6990\n",
      "  Validation Accuracy after Epoch 112: 85.9200\n",
      "  Epoch [113/115], Batch [350/352], Train Acc: 90.6853 Loss: 0.7066\n",
      "  Validation Accuracy after Epoch 113: 84.9400\n",
      "  Epoch [114/115], Batch [350/352], Train Acc: 90.8504 Loss: 0.6548\n",
      "  Validation Accuracy after Epoch 114: 85.9800\n",
      "  Epoch [115/115], Batch [350/352], Train Acc: 90.8192 Loss: 0.7148\n",
      "  Validation Accuracy after Epoch 115: 86.5200\n",
      "Trial 0 complete. Best Validation Accuracy: 86.7000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 02:15:35,733] Trial 0 finished with value: 86.7 and parameters: {'model_type': 'smallresnet', 'batch_size': 128, 'optimizer_type': 'Adam', 'scheduler_type': 'ReduceLROnPlateau', 'weight_decay': 0.0005, 'learning_rate': 0.00032214137835438034, 'num_epochs': 115, 'factor': 0.3825196441327009, 'patience': 6}. Best is trial 0 with value: 86.7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=1\n",
      "model_type: efficientnet\n",
      "batch_size: 256\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "weight_decay: 0.0005\n",
      "learning_rate: 0.0003941830586218311\n",
      "num_epochs: 92\n",
      "factor: 0.12924857724297942\n",
      "patience: 6\n",
      "model_name: EfficientNet\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/92], Batch [170/176], Train Acc: 20.1333 Loss: 2.0302\n",
      "  Validation Accuracy after Epoch 1: 26.9000\n",
      "  Epoch [2/92], Batch [170/176], Train Acc: 29.9563 Loss: 1.8351\n",
      "  Validation Accuracy after Epoch 2: 33.2200\n",
      "  Epoch [3/92], Batch [170/176], Train Acc: 35.9283 Loss: 1.8577\n",
      "  Validation Accuracy after Epoch 3: 38.8200\n",
      "  Epoch [4/92], Batch [170/176], Train Acc: 39.8966 Loss: 1.7842\n",
      "  Validation Accuracy after Epoch 4: 41.0800\n",
      "  Epoch [5/92], Batch [170/176], Train Acc: 43.2950 Loss: 1.6887\n",
      "  Validation Accuracy after Epoch 5: 44.2200\n",
      "  Epoch [6/92], Batch [170/176], Train Acc: 45.8019 Loss: 1.5933\n",
      "  Validation Accuracy after Epoch 6: 45.8600\n",
      "  Epoch [7/92], Batch [170/176], Train Acc: 48.3824 Loss: 1.6204\n",
      "  Validation Accuracy after Epoch 7: 49.7400\n",
      "  Epoch [8/92], Batch [170/176], Train Acc: 51.0731 Loss: 1.5040\n",
      "  Validation Accuracy after Epoch 8: 52.2600\n",
      "  Epoch [9/92], Batch [170/176], Train Acc: 52.9435 Loss: 1.4498\n",
      "  Validation Accuracy after Epoch 9: 53.9800\n",
      "  Epoch [10/92], Batch [170/176], Train Acc: 54.8943 Loss: 1.4642\n",
      "  Validation Accuracy after Epoch 10: 55.7000\n",
      "  Epoch [11/92], Batch [170/176], Train Acc: 56.2431 Loss: 1.5708\n",
      "  Validation Accuracy after Epoch 11: 56.7000\n",
      "  Epoch [12/92], Batch [170/176], Train Acc: 57.8217 Loss: 1.3353\n",
      "  Validation Accuracy after Epoch 12: 58.9000\n",
      "  Epoch [13/92], Batch [170/176], Train Acc: 59.2233 Loss: 1.4021\n",
      "  Validation Accuracy after Epoch 13: 58.4000\n",
      "  Epoch [14/92], Batch [170/176], Train Acc: 60.3768 Loss: 1.3974\n",
      "  Validation Accuracy after Epoch 14: 60.6000\n",
      "  Epoch [15/92], Batch [170/176], Train Acc: 61.6935 Loss: 1.4661\n",
      "  Validation Accuracy after Epoch 15: 61.5400\n",
      "  Epoch [16/92], Batch [170/176], Train Acc: 62.9274 Loss: 1.3081\n",
      "  Validation Accuracy after Epoch 16: 62.8800\n",
      "  Epoch [17/92], Batch [170/176], Train Acc: 63.9384 Loss: 1.2807\n",
      "  Validation Accuracy after Epoch 17: 63.6600\n",
      "  Epoch [18/92], Batch [170/176], Train Acc: 64.5106 Loss: 1.2522\n",
      "  Validation Accuracy after Epoch 18: 63.2200\n",
      "  Epoch [19/92], Batch [170/176], Train Acc: 65.7652 Loss: 1.2249\n",
      "  Validation Accuracy after Epoch 19: 65.3800\n",
      "  Epoch [20/92], Batch [170/176], Train Acc: 66.4407 Loss: 1.1891\n",
      "  Validation Accuracy after Epoch 20: 65.2800\n",
      "  Epoch [21/92], Batch [170/176], Train Acc: 66.8290 Loss: 1.2670\n",
      "  Validation Accuracy after Epoch 21: 67.3200\n",
      "  Epoch [22/92], Batch [170/176], Train Acc: 67.8056 Loss: 1.2406\n",
      "  Validation Accuracy after Epoch 22: 66.1800\n",
      "  Epoch [23/92], Batch [170/176], Train Acc: 68.0836 Loss: 1.1884\n",
      "  Validation Accuracy after Epoch 23: 68.0200\n",
      "  Epoch [24/92], Batch [170/176], Train Acc: 68.7362 Loss: 1.1801\n",
      "  Validation Accuracy after Epoch 24: 68.9600\n",
      "  Epoch [25/92], Batch [170/176], Train Acc: 69.7472 Loss: 1.1445\n",
      "  Validation Accuracy after Epoch 25: 67.6200\n",
      "  Epoch [26/92], Batch [170/176], Train Acc: 69.9609 Loss: 1.1851\n",
      "  Validation Accuracy after Epoch 26: 68.3800\n",
      "  Epoch [27/92], Batch [170/176], Train Acc: 70.3493 Loss: 1.1326\n",
      "  Validation Accuracy after Epoch 27: 69.0000\n",
      "  Epoch [28/92], Batch [170/176], Train Acc: 70.6801 Loss: 1.1500\n",
      "  Validation Accuracy after Epoch 28: 70.9800\n",
      "  Epoch [29/92], Batch [170/176], Train Acc: 71.5832 Loss: 1.1611\n",
      "  Validation Accuracy after Epoch 29: 70.1600\n",
      "  Epoch [30/92], Batch [170/176], Train Acc: 71.4729 Loss: 1.1452\n",
      "  Validation Accuracy after Epoch 30: 70.8400\n",
      "  Epoch [31/92], Batch [170/176], Train Acc: 72.3438 Loss: 1.1137\n",
      "  Validation Accuracy after Epoch 31: 70.5400\n",
      "  Epoch [32/92], Batch [170/176], Train Acc: 72.6930 Loss: 1.1612\n",
      "  Validation Accuracy after Epoch 32: 71.0600\n",
      "  Epoch [33/92], Batch [170/176], Train Acc: 72.9044 Loss: 1.0334\n",
      "  Validation Accuracy after Epoch 33: 71.2000\n",
      "  Epoch [34/92], Batch [170/176], Train Acc: 73.3663 Loss: 1.1040\n",
      "  Validation Accuracy after Epoch 34: 71.7000\n",
      "  Epoch [35/92], Batch [170/176], Train Acc: 74.1521 Loss: 1.2095\n",
      "  Validation Accuracy after Epoch 35: 72.0800\n",
      "  Epoch [36/92], Batch [170/176], Train Acc: 73.7592 Loss: 1.0414\n",
      "  Validation Accuracy after Epoch 36: 72.3400\n",
      "  Epoch [37/92], Batch [170/176], Train Acc: 74.3015 Loss: 1.1671\n",
      "  Validation Accuracy after Epoch 37: 70.8000\n",
      "  Epoch [38/92], Batch [170/176], Train Acc: 74.3796 Loss: 1.1185\n",
      "  Validation Accuracy after Epoch 38: 73.4400\n",
      "  Epoch [39/92], Batch [170/176], Train Acc: 75.0391 Loss: 1.0530\n",
      "  Validation Accuracy after Epoch 39: 72.5800\n",
      "  Epoch [40/92], Batch [170/176], Train Acc: 75.2436 Loss: 1.0861\n",
      "  Validation Accuracy after Epoch 40: 73.8400\n",
      "  Epoch [41/92], Batch [170/176], Train Acc: 75.3837 Loss: 1.0564\n",
      "  Validation Accuracy after Epoch 41: 72.2600\n",
      "  Epoch [42/92], Batch [170/176], Train Acc: 75.9513 Loss: 1.0120\n",
      "  Validation Accuracy after Epoch 42: 74.1200\n",
      "  Epoch [43/92], Batch [170/176], Train Acc: 76.0892 Loss: 0.9555\n",
      "  Validation Accuracy after Epoch 43: 74.5800\n",
      "  Epoch [44/92], Batch [170/176], Train Acc: 76.5005 Loss: 1.0590\n",
      "  Validation Accuracy after Epoch 44: 74.1000\n",
      "  Epoch [45/92], Batch [170/176], Train Acc: 76.6590 Loss: 0.9947\n",
      "  Validation Accuracy after Epoch 45: 74.5800\n",
      "  Epoch [46/92], Batch [170/176], Train Acc: 76.7647 Loss: 1.0655\n",
      "  Validation Accuracy after Epoch 46: 74.0600\n",
      "  Epoch [47/92], Batch [170/176], Train Acc: 77.0956 Loss: 1.0176\n",
      "  Validation Accuracy after Epoch 47: 75.0000\n",
      "  Epoch [48/92], Batch [170/176], Train Acc: 77.4403 Loss: 1.1382\n",
      "  Validation Accuracy after Epoch 48: 75.3600\n",
      "  Epoch [49/92], Batch [170/176], Train Acc: 77.5437 Loss: 1.0558\n",
      "  Validation Accuracy after Epoch 49: 75.2000\n",
      "  Epoch [50/92], Batch [170/176], Train Acc: 77.8010 Loss: 1.0518\n",
      "  Validation Accuracy after Epoch 50: 75.3800\n",
      "  Epoch [51/92], Batch [170/176], Train Acc: 77.9825 Loss: 1.0625\n",
      "  Validation Accuracy after Epoch 51: 75.9600\n",
      "  Epoch [52/92], Batch [170/176], Train Acc: 78.0813 Loss: 1.0092\n",
      "  Validation Accuracy after Epoch 52: 75.2000\n",
      "  Epoch [53/92], Batch [170/176], Train Acc: 78.6880 Loss: 0.9678\n",
      "  Validation Accuracy after Epoch 53: 76.1400\n",
      "  Epoch [54/92], Batch [170/176], Train Acc: 78.4237 Loss: 0.9884\n",
      "  Validation Accuracy after Epoch 54: 76.1400\n",
      "  Epoch [55/92], Batch [170/176], Train Acc: 78.8971 Loss: 0.9399\n",
      "  Validation Accuracy after Epoch 55: 76.3400\n",
      "  Epoch [56/92], Batch [170/176], Train Acc: 78.8051 Loss: 0.9941\n",
      "  Validation Accuracy after Epoch 56: 76.3000\n",
      "  Epoch [57/92], Batch [170/176], Train Acc: 79.0901 Loss: 0.9820\n",
      "  Validation Accuracy after Epoch 57: 76.6400\n",
      "  Epoch [58/92], Batch [170/176], Train Acc: 79.3130 Loss: 0.9803\n",
      "  Validation Accuracy after Epoch 58: 76.6400\n",
      "  Epoch [59/92], Batch [170/176], Train Acc: 79.2119 Loss: 1.0125\n",
      "  Validation Accuracy after Epoch 59: 76.5200\n",
      "  Epoch [60/92], Batch [170/176], Train Acc: 79.5749 Loss: 0.9811\n",
      "  Validation Accuracy after Epoch 60: 76.3400\n",
      "  Epoch [61/92], Batch [170/176], Train Acc: 79.9494 Loss: 0.9235\n",
      "  Validation Accuracy after Epoch 61: 76.3800\n",
      "  Epoch [62/92], Batch [170/176], Train Acc: 81.1259 Loss: 0.9164\n",
      "  Validation Accuracy after Epoch 62: 78.5400\n",
      "  Epoch [63/92], Batch [170/176], Train Acc: 82.0381 Loss: 0.8746\n",
      "  Validation Accuracy after Epoch 63: 78.4000\n",
      "  Epoch [64/92], Batch [170/176], Train Acc: 82.0358 Loss: 0.8395\n",
      "  Validation Accuracy after Epoch 64: 79.5800\n",
      "  Epoch [65/92], Batch [170/176], Train Acc: 82.5620 Loss: 0.9175\n",
      "  Validation Accuracy after Epoch 65: 77.9000\n",
      "  Epoch [66/92], Batch [170/176], Train Acc: 82.5000 Loss: 0.9012\n",
      "  Validation Accuracy after Epoch 66: 79.5800\n",
      "  Epoch [67/92], Batch [170/176], Train Acc: 82.6815 Loss: 0.8415\n",
      "  Validation Accuracy after Epoch 67: 78.3000\n",
      "  Epoch [68/92], Batch [170/176], Train Acc: 82.6172 Loss: 0.8914\n",
      "  Validation Accuracy after Epoch 68: 78.8800\n",
      "  Epoch [69/92], Batch [170/176], Train Acc: 83.0905 Loss: 0.8734\n",
      "  Validation Accuracy after Epoch 69: 79.1400\n",
      "  Epoch [70/92], Batch [170/176], Train Acc: 82.8194 Loss: 0.8814\n",
      "  Validation Accuracy after Epoch 70: 79.0400\n",
      "  Epoch [71/92], Batch [170/176], Train Acc: 82.8860 Loss: 0.8012\n",
      "  Validation Accuracy after Epoch 71: 78.8400\n",
      "  Epoch [72/92], Batch [170/176], Train Acc: 83.1204 Loss: 0.9637\n",
      "  Validation Accuracy after Epoch 72: 80.1800\n",
      "  Epoch [73/92], Batch [170/176], Train Acc: 83.1135 Loss: 0.8616\n",
      "  Validation Accuracy after Epoch 73: 79.9400\n",
      "  Epoch [74/92], Batch [170/176], Train Acc: 83.2583 Loss: 0.8164\n",
      "  Validation Accuracy after Epoch 74: 79.3800\n",
      "  Epoch [75/92], Batch [170/176], Train Acc: 83.0607 Loss: 0.9143\n",
      "  Validation Accuracy after Epoch 75: 79.0400\n",
      "  Epoch [76/92], Batch [170/176], Train Acc: 83.3272 Loss: 0.8979\n",
      "  Validation Accuracy after Epoch 76: 79.5600\n",
      "  Epoch [77/92], Batch [170/176], Train Acc: 83.6305 Loss: 0.8150\n",
      "  Validation Accuracy after Epoch 77: 80.1600\n",
      "  Epoch [78/92], Batch [170/176], Train Acc: 83.4697 Loss: 0.8802\n",
      "  Validation Accuracy after Epoch 78: 79.2800\n",
      "  Epoch [79/92], Batch [170/176], Train Acc: 83.5202 Loss: 0.8515\n",
      "  Validation Accuracy after Epoch 79: 78.8600\n",
      "  Epoch [80/92], Batch [170/176], Train Acc: 83.5547 Loss: 0.8726\n",
      "  Validation Accuracy after Epoch 80: 80.2000\n",
      "  Epoch [81/92], Batch [170/176], Train Acc: 83.5110 Loss: 0.8802\n",
      "  Validation Accuracy after Epoch 81: 79.0400\n",
      "  Epoch [82/92], Batch [10/176], Train Acc: 85.1953 Loss: 0.8273"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=\"sqlite:///study.db\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume study\n",
    "Helps run more studies since we only have 4 hour time limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 08:27:39,067] Using an existing study with name 'study_2025-03-11_01-51-41' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=5\n",
      "model_type: efficientnet\n",
      "batch_size: 64\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.0005113906292921991\n",
      "factor: 0.13060806437027034\n",
      "patience: 9\n",
      "model_name: EfficientNet\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/250], Batch [700/704], Train Acc: 25.2210 Loss: 1.8978\n",
      "  Validation Accuracy after Epoch 1: 32.8600\n",
      "  Epoch [2/250], Batch [700/704], Train Acc: 36.2232 Loss: 1.5889\n",
      "  Validation Accuracy after Epoch 2: 40.1200\n",
      "  Epoch [3/250], Batch [700/704], Train Acc: 42.4107 Loss: 1.6440\n",
      "  Validation Accuracy after Epoch 3: 46.6800\n",
      "  Epoch [4/250], Batch [700/704], Train Acc: 47.7969 Loss: 1.4218\n",
      "  Validation Accuracy after Epoch 4: 50.4800\n",
      "  Epoch [5/250], Batch [700/704], Train Acc: 52.0335 Loss: 1.5002\n",
      "  Validation Accuracy after Epoch 5: 52.7600\n",
      "  Epoch [6/250], Batch [700/704], Train Acc: 54.8326 Loss: 1.2450\n",
      "  Validation Accuracy after Epoch 6: 56.5800\n",
      "  Epoch [7/250], Batch [700/704], Train Acc: 57.7210 Loss: 1.5789\n",
      "  Validation Accuracy after Epoch 7: 58.9400\n",
      "  Epoch [8/250], Batch [700/704], Train Acc: 59.7232 Loss: 1.4684\n",
      "  Validation Accuracy after Epoch 8: 61.1200\n",
      "  Epoch [9/250], Batch [700/704], Train Acc: 61.5335 Loss: 1.3701\n",
      "  Validation Accuracy after Epoch 9: 62.7200\n",
      "  Epoch [10/250], Batch [700/704], Train Acc: 63.5781 Loss: 1.3380\n",
      "  Validation Accuracy after Epoch 10: 64.1600\n",
      "  Epoch [11/250], Batch [700/704], Train Acc: 64.7344 Loss: 1.3142\n",
      "  Validation Accuracy after Epoch 11: 66.1400\n",
      "  Epoch [12/250], Batch [700/704], Train Acc: 66.0156 Loss: 1.1430\n",
      "  Validation Accuracy after Epoch 12: 65.9400\n",
      "  Epoch [13/250], Batch [700/704], Train Acc: 66.8192 Loss: 1.3248\n",
      "  Validation Accuracy after Epoch 13: 68.6000\n",
      "  Epoch [14/250], Batch [700/704], Train Acc: 68.2232 Loss: 1.1783\n",
      "  Validation Accuracy after Epoch 14: 69.3200\n",
      "  Epoch [15/250], Batch [700/704], Train Acc: 69.0424 Loss: 1.0921\n",
      "  Validation Accuracy after Epoch 15: 70.0000\n",
      "  Epoch [16/250], Batch [700/704], Train Acc: 69.7299 Loss: 1.2985\n",
      "  Validation Accuracy after Epoch 16: 68.6600\n",
      "  Epoch [17/250], Batch [700/704], Train Acc: 70.2790 Loss: 1.1145\n",
      "  Validation Accuracy after Epoch 17: 70.6800\n",
      "  Epoch [18/250], Batch [700/704], Train Acc: 70.9621 Loss: 1.0622\n",
      "  Validation Accuracy after Epoch 18: 71.8600\n",
      "  Epoch [19/250], Batch [700/704], Train Acc: 71.6875 Loss: 1.1166\n",
      "  Validation Accuracy after Epoch 19: 71.7600\n",
      "  Epoch [20/250], Batch [700/704], Train Acc: 72.3951 Loss: 1.1482\n",
      "  Validation Accuracy after Epoch 20: 71.9400\n",
      "  Epoch [21/250], Batch [700/704], Train Acc: 72.8438 Loss: 1.0025\n",
      "  Validation Accuracy after Epoch 21: 72.8600\n",
      "  Epoch [22/250], Batch [700/704], Train Acc: 73.2545 Loss: 1.2339\n",
      "  Validation Accuracy after Epoch 22: 73.7400\n",
      "  Epoch [23/250], Batch [700/704], Train Acc: 73.8504 Loss: 0.9253\n",
      "  Validation Accuracy after Epoch 23: 73.3600\n",
      "  Epoch [24/250], Batch [700/704], Train Acc: 74.4866 Loss: 1.1142\n",
      "  Validation Accuracy after Epoch 24: 74.1400\n",
      "  Epoch [25/250], Batch [700/704], Train Acc: 75.0045 Loss: 0.9956\n",
      "  Validation Accuracy after Epoch 25: 74.0200\n",
      "  Epoch [26/250], Batch [700/704], Train Acc: 75.2723 Loss: 1.1259\n",
      "  Validation Accuracy after Epoch 26: 75.2800\n",
      "  Epoch [27/250], Batch [700/704], Train Acc: 75.4821 Loss: 1.0282\n",
      "  Validation Accuracy after Epoch 27: 74.1400\n",
      "  Epoch [28/250], Batch [700/704], Train Acc: 75.8683 Loss: 0.9517\n",
      "  Validation Accuracy after Epoch 28: 75.7000\n",
      "  Epoch [29/250], Batch [700/704], Train Acc: 75.7210 Loss: 1.2197\n",
      "  Validation Accuracy after Epoch 29: 74.8000\n",
      "  Epoch [30/250], Batch [700/704], Train Acc: 76.5045 Loss: 0.9147\n",
      "  Validation Accuracy after Epoch 30: 75.4600\n",
      "  Epoch [31/250], Batch [700/704], Train Acc: 76.6518 Loss: 1.0983\n",
      "  Validation Accuracy after Epoch 31: 76.2000\n",
      "  Epoch [32/250], Batch [700/704], Train Acc: 76.8772 Loss: 1.1339\n",
      "  Validation Accuracy after Epoch 32: 75.4400\n",
      "  Epoch [33/250], Batch [700/704], Train Acc: 77.5246 Loss: 0.8982\n",
      "  Validation Accuracy after Epoch 33: 76.6400\n",
      "  Epoch [34/250], Batch [700/704], Train Acc: 77.8817 Loss: 0.9993\n",
      "  Validation Accuracy after Epoch 34: 76.3600\n",
      "  Epoch [35/250], Batch [700/704], Train Acc: 77.9911 Loss: 1.1207\n",
      "  Validation Accuracy after Epoch 35: 77.2000\n",
      "  Epoch [36/250], Batch [700/704], Train Acc: 77.8438 Loss: 0.9069\n",
      "  Validation Accuracy after Epoch 36: 77.1400\n",
      "  Epoch [37/250], Batch [700/704], Train Acc: 78.5335 Loss: 1.0073\n",
      "  Validation Accuracy after Epoch 37: 77.2600\n",
      "  Epoch [38/250], Batch [700/704], Train Acc: 78.8170 Loss: 0.9529\n",
      "  Validation Accuracy after Epoch 38: 77.0800\n",
      "  Epoch [39/250], Batch [700/704], Train Acc: 78.8884 Loss: 0.9842\n",
      "  Validation Accuracy after Epoch 39: 77.7800\n",
      "  Epoch [40/250], Batch [700/704], Train Acc: 79.1652 Loss: 1.0827\n",
      "  Validation Accuracy after Epoch 40: 77.6800\n",
      "  Epoch [41/250], Batch [700/704], Train Acc: 79.4286 Loss: 0.9319\n",
      "  Validation Accuracy after Epoch 41: 77.8800\n",
      "  Epoch [42/250], Batch [700/704], Train Acc: 79.4129 Loss: 0.8973\n",
      "  Validation Accuracy after Epoch 42: 78.4200\n",
      "  Epoch [43/250], Batch [700/704], Train Acc: 79.8906 Loss: 1.0042\n",
      "  Validation Accuracy after Epoch 43: 77.9200\n",
      "  Epoch [44/250], Batch [700/704], Train Acc: 80.4174 Loss: 1.0591\n",
      "  Validation Accuracy after Epoch 44: 78.6800\n",
      "  Epoch [45/250], Batch [700/704], Train Acc: 79.8527 Loss: 0.8730\n",
      "  Validation Accuracy after Epoch 45: 79.1000\n",
      "  Epoch [46/250], Batch [700/704], Train Acc: 80.4085 Loss: 0.9738\n",
      "  Validation Accuracy after Epoch 46: 79.3000\n",
      "  Epoch [47/250], Batch [700/704], Train Acc: 80.6138 Loss: 0.8973\n",
      "  Validation Accuracy after Epoch 47: 79.2800\n",
      "  Epoch [48/250], Batch [700/704], Train Acc: 80.7991 Loss: 0.9736\n",
      "  Validation Accuracy after Epoch 48: 78.9200\n",
      "  Epoch [49/250], Batch [700/704], Train Acc: 80.8996 Loss: 0.9923\n",
      "  Validation Accuracy after Epoch 49: 79.2000\n",
      "  Epoch [50/250], Batch [700/704], Train Acc: 81.1071 Loss: 1.0438\n",
      "  Validation Accuracy after Epoch 50: 80.5800\n",
      "  Epoch [51/250], Batch [700/704], Train Acc: 81.2121 Loss: 0.8983\n",
      "  Validation Accuracy after Epoch 51: 79.0400\n",
      "  Epoch [52/250], Batch [700/704], Train Acc: 81.5000 Loss: 0.9810\n",
      "  Validation Accuracy after Epoch 52: 79.4200\n",
      "  Epoch [53/250], Batch [700/704], Train Acc: 81.6719 Loss: 0.9309\n",
      "  Validation Accuracy after Epoch 53: 80.0000\n",
      "  Epoch [54/250], Batch [700/704], Train Acc: 81.6473 Loss: 0.8372\n",
      "  Validation Accuracy after Epoch 54: 79.3000\n",
      "  Epoch [55/250], Batch [700/704], Train Acc: 82.2076 Loss: 1.0055\n",
      "  Validation Accuracy after Epoch 55: 79.4800\n",
      "  Epoch [56/250], Batch [700/704], Train Acc: 81.5759 Loss: 0.8933\n",
      "  Validation Accuracy after Epoch 56: 80.4200\n",
      "  Epoch [57/250], Batch [700/704], Train Acc: 82.5357 Loss: 0.9446\n",
      "  Validation Accuracy after Epoch 57: 79.9800\n",
      "  Epoch [58/250], Batch [700/704], Train Acc: 82.6071 Loss: 1.2009\n",
      "  Validation Accuracy after Epoch 58: 80.5600\n",
      "  Epoch [59/250], Batch [700/704], Train Acc: 82.5424 Loss: 0.8535\n",
      "  Validation Accuracy after Epoch 59: 80.0800\n",
      "  Epoch [60/250], Batch [700/704], Train Acc: 82.4844 Loss: 0.9859\n",
      "  Validation Accuracy after Epoch 60: 80.5200\n",
      "  Epoch [61/250], Batch [700/704], Train Acc: 82.9174 Loss: 0.8952\n",
      "  Validation Accuracy after Epoch 61: 80.3000\n",
      "  Epoch [62/250], Batch [700/704], Train Acc: 82.8415 Loss: 0.9473\n",
      "  Validation Accuracy after Epoch 62: 80.8400\n",
      "  Epoch [63/250], Batch [700/704], Train Acc: 83.0714 Loss: 0.9519\n",
      "  Validation Accuracy after Epoch 63: 81.0600\n",
      "  Epoch [64/250], Batch [700/704], Train Acc: 83.1585 Loss: 0.8187\n",
      "  Validation Accuracy after Epoch 64: 80.1800\n",
      "  Epoch [65/250], Batch [700/704], Train Acc: 83.4040 Loss: 0.8635\n",
      "  Validation Accuracy after Epoch 65: 80.9800\n",
      "  Epoch [66/250], Batch [700/704], Train Acc: 83.2545 Loss: 0.8791\n",
      "  Validation Accuracy after Epoch 66: 80.8200\n",
      "  Epoch [67/250], Batch [700/704], Train Acc: 83.5379 Loss: 1.0196\n",
      "  Validation Accuracy after Epoch 67: 80.4800\n",
      "  Epoch [68/250], Batch [700/704], Train Acc: 83.3951 Loss: 0.8591\n",
      "  Validation Accuracy after Epoch 68: 81.1400\n",
      "  Epoch [69/250], Batch [700/704], Train Acc: 83.7969 Loss: 0.8884\n",
      "  Validation Accuracy after Epoch 69: 80.3200\n",
      "  Epoch [70/250], Batch [700/704], Train Acc: 84.1674 Loss: 0.8984\n",
      "  Validation Accuracy after Epoch 70: 80.6400\n",
      "  Epoch [71/250], Batch [700/704], Train Acc: 84.2768 Loss: 0.7803\n",
      "  Validation Accuracy after Epoch 71: 80.8200\n",
      "  Epoch [72/250], Batch [700/704], Train Acc: 84.0491 Loss: 0.8806\n",
      "  Validation Accuracy after Epoch 72: 81.6200\n",
      "  Epoch [73/250], Batch [700/704], Train Acc: 84.4085 Loss: 0.9943\n",
      "  Validation Accuracy after Epoch 73: 81.5000\n",
      "  Epoch [74/250], Batch [700/704], Train Acc: 84.4754 Loss: 0.7945\n",
      "  Validation Accuracy after Epoch 74: 81.7000\n",
      "  Epoch [75/250], Batch [700/704], Train Acc: 84.5804 Loss: 0.7408\n",
      "  Validation Accuracy after Epoch 75: 81.9400\n",
      "  Epoch [76/250], Batch [700/704], Train Acc: 84.4665 Loss: 0.8872\n",
      "  Validation Accuracy after Epoch 76: 81.9000\n",
      "  Epoch [77/250], Batch [700/704], Train Acc: 84.6205 Loss: 0.7899\n",
      "  Validation Accuracy after Epoch 77: 82.6600\n",
      "  Epoch [78/250], Batch [700/704], Train Acc: 84.9375 Loss: 0.9652\n",
      "  Validation Accuracy after Epoch 78: 82.6200\n",
      "  Epoch [79/250], Batch [700/704], Train Acc: 84.9955 Loss: 0.7850\n",
      "  Validation Accuracy after Epoch 79: 81.8600\n",
      "  Epoch [80/250], Batch [700/704], Train Acc: 85.0580 Loss: 0.8547\n",
      "  Validation Accuracy after Epoch 80: 82.3000\n",
      "  Epoch [81/250], Batch [700/704], Train Acc: 85.2433 Loss: 0.9530\n",
      "  Validation Accuracy after Epoch 81: 81.9200\n",
      "  Epoch [82/250], Batch [700/704], Train Acc: 85.2857 Loss: 0.8173\n",
      "  Validation Accuracy after Epoch 82: 82.1000\n",
      "  Epoch [83/250], Batch [700/704], Train Acc: 85.6429 Loss: 0.7168\n",
      "  Validation Accuracy after Epoch 83: 82.0800\n",
      "  Epoch [84/250], Batch [700/704], Train Acc: 85.5112 Loss: 0.7208\n",
      "  Validation Accuracy after Epoch 84: 81.8200\n",
      "  Epoch [85/250], Batch [700/704], Train Acc: 85.8125 Loss: 0.8480\n",
      "  Validation Accuracy after Epoch 85: 82.2400\n",
      "  Epoch [86/250], Batch [700/704], Train Acc: 85.9219 Loss: 0.7801\n",
      "  Validation Accuracy after Epoch 86: 82.8800\n",
      "  Epoch [87/250], Batch [700/704], Train Acc: 85.9821 Loss: 0.7604\n",
      "  Validation Accuracy after Epoch 87: 82.2400\n",
      "  Epoch [88/250], Batch [700/704], Train Acc: 85.9509 Loss: 0.7966\n",
      "  Validation Accuracy after Epoch 88: 82.1400\n",
      "  Epoch [89/250], Batch [700/704], Train Acc: 85.5625 Loss: 0.7202\n",
      "  Validation Accuracy after Epoch 89: 80.7600\n",
      "  Epoch [90/250], Batch [700/704], Train Acc: 86.1987 Loss: 0.8917\n",
      "  Validation Accuracy after Epoch 90: 82.3800\n",
      "  Epoch [91/250], Batch [700/704], Train Acc: 86.0067 Loss: 0.8916\n",
      "  Validation Accuracy after Epoch 91: 82.3600\n",
      "  Epoch [92/250], Batch [700/704], Train Acc: 86.2790 Loss: 0.7935\n",
      "  Validation Accuracy after Epoch 92: 82.2800\n",
      "  Epoch [93/250], Batch [700/704], Train Acc: 86.1987 Loss: 0.8105\n",
      "  Validation Accuracy after Epoch 93: 83.1000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 09:13:30,198] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=6\n",
      "model_type: efficientnet\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: OneCycleLR\n",
      "weight_decay: 0.0005\n",
      "learning_rate: 0.0008843166259581984\n",
      "model_name: EfficientNet\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/250], Batch [350/352], Train Acc: 23.2478 Loss: 1.8883\n",
      "  Validation Accuracy after Epoch 1: 31.0800\n",
      "  Epoch [2/250], Batch [350/352], Train Acc: 34.7188 Loss: 1.5569\n",
      "  Validation Accuracy after Epoch 2: 39.1000\n",
      "  Epoch [3/250], Batch [350/352], Train Acc: 43.9152 Loss: 1.7054\n",
      "  Validation Accuracy after Epoch 3: 43.8200\n",
      "  Epoch [4/250], Batch [350/352], Train Acc: 49.5246 Loss: 1.4229\n",
      "  Validation Accuracy after Epoch 4: 49.6200\n",
      "  Epoch [5/250], Batch [350/352], Train Acc: 53.7679 Loss: 1.5889\n",
      "  Validation Accuracy after Epoch 5: 54.0200\n",
      "  Epoch [6/250], Batch [350/352], Train Acc: 56.6987 Loss: 1.3183\n",
      "  Validation Accuracy after Epoch 6: 56.6200\n",
      "  Epoch [7/250], Batch [350/352], Train Acc: 59.0067 Loss: 1.4915\n",
      "  Validation Accuracy after Epoch 7: 59.7200\n",
      "  Epoch [8/250], Batch [350/352], Train Acc: 61.3170 Loss: 1.3737\n",
      "  Validation Accuracy after Epoch 8: 59.3200\n",
      "  Epoch [9/250], Batch [350/352], Train Acc: 62.8661 Loss: 1.3969\n",
      "  Validation Accuracy after Epoch 9: 64.6600\n",
      "  Epoch [10/250], Batch [350/352], Train Acc: 64.6272 Loss: 1.1849\n",
      "  Validation Accuracy after Epoch 10: 64.7400\n",
      "  Epoch [11/250], Batch [350/352], Train Acc: 65.5357 Loss: 1.2934\n",
      "  Validation Accuracy after Epoch 11: 65.2000\n",
      "  Epoch [12/250], Batch [350/352], Train Acc: 66.4107 Loss: 1.1466\n",
      "  Validation Accuracy after Epoch 12: 64.8400\n",
      "  Epoch [13/250], Batch [350/352], Train Acc: 67.4464 Loss: 1.2307\n",
      "  Validation Accuracy after Epoch 13: 64.8800\n",
      "  Epoch [14/250], Batch [350/352], Train Acc: 67.8683 Loss: 1.3298\n",
      "  Validation Accuracy after Epoch 14: 66.8400\n",
      "  Epoch [15/250], Batch [350/352], Train Acc: 68.0379 Loss: 1.2572\n",
      "  Validation Accuracy after Epoch 15: 65.6400\n",
      "  Epoch [16/250], Batch [350/352], Train Acc: 67.8438 Loss: 1.2142\n",
      "  Validation Accuracy after Epoch 16: 66.2400\n",
      "  Epoch [17/250], Batch [350/352], Train Acc: 68.2031 Loss: 1.0559\n",
      "  Validation Accuracy after Epoch 17: 64.0000\n",
      "  Epoch [18/250], Batch [350/352], Train Acc: 68.3906 Loss: 1.2145\n",
      "  Validation Accuracy after Epoch 18: 68.1200\n",
      "  Epoch [19/250], Batch [350/352], Train Acc: 69.5513 Loss: 1.2318\n",
      "  Validation Accuracy after Epoch 19: 66.9200\n",
      "  Epoch [20/250], Batch [350/352], Train Acc: 69.5804 Loss: 1.2619\n",
      "  Validation Accuracy after Epoch 20: 66.5000\n",
      "  Epoch [21/250], Batch [350/352], Train Acc: 69.6049 Loss: 1.2669\n",
      "  Validation Accuracy after Epoch 21: 66.1800\n",
      "  Epoch [22/250], Batch [350/352], Train Acc: 69.5938 Loss: 1.1715\n",
      "  Validation Accuracy after Epoch 22: 68.4600\n",
      "  Epoch [23/250], Batch [350/352], Train Acc: 70.0603 Loss: 1.1572\n",
      "  Validation Accuracy after Epoch 23: 69.4600\n",
      "  Epoch [24/250], Batch [350/352], Train Acc: 70.2701 Loss: 1.1762\n",
      "  Validation Accuracy after Epoch 24: 65.3400\n",
      "  Epoch [25/250], Batch [350/352], Train Acc: 70.0469 Loss: 1.1267\n",
      "  Validation Accuracy after Epoch 25: 69.0200\n",
      "  Epoch [26/250], Batch [350/352], Train Acc: 70.2411 Loss: 1.3327\n",
      "  Validation Accuracy after Epoch 26: 66.0000\n",
      "  Epoch [27/250], Batch [350/352], Train Acc: 70.3013 Loss: 1.0918\n",
      "  Validation Accuracy after Epoch 27: 67.4600\n",
      "  Epoch [28/250], Batch [350/352], Train Acc: 69.6518 Loss: 1.2521\n",
      "  Validation Accuracy after Epoch 28: 66.6400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 09:21:18,173] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=7\n",
      "model_type: smallresnet\n",
      "batch_size: 256\n",
      "optimizer_type: Adam\n",
      "scheduler_type: OneCycleLR\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.0005112796186151655\n",
      "model_name: SmallResNet\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/250], Batch [170/176], Train Acc: 23.2996 Loss: 1.9870\n",
      "  Validation Accuracy after Epoch 1: 27.2000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 09:21:31,567] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=8\n",
      "model_type: efficientnet\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: CosineAnnealingLR\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.00025033043537248264\n",
      "model_name: EfficientNet\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/250], Batch [350/352], Train Acc: 17.6138 Loss: 2.1723\n",
      "  Validation Accuracy after Epoch 1: 20.6200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 09:21:50,389] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=9\n",
      "model_type: efficientnet\n",
      "batch_size: 64\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "weight_decay: 0.0001\n",
      "learning_rate: 0.01570247106382465\n",
      "model_name: EfficientNet\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/250], Batch [700/704], Train Acc: 27.4844 Loss: 1.8903\n",
      "  Validation Accuracy after Epoch 1: 35.0600\n",
      "  Epoch [2/250], Batch [700/704], Train Acc: 38.6808 Loss: 1.6047\n",
      "  Validation Accuracy after Epoch 2: 39.4200\n",
      "  Epoch [3/250], Batch [700/704], Train Acc: 45.3504 Loss: 1.7497\n",
      "  Validation Accuracy after Epoch 3: 48.9600\n",
      "  Epoch [4/250], Batch [700/704], Train Acc: 50.2254 Loss: 1.3604\n",
      "  Validation Accuracy after Epoch 4: 50.9200\n",
      "  Epoch [5/250], Batch [700/704], Train Acc: 53.3839 Loss: 1.4715\n",
      "  Validation Accuracy after Epoch 5: 55.7600\n",
      "  Epoch [6/250], Batch [700/704], Train Acc: 56.3504 Loss: 1.2240\n",
      "  Validation Accuracy after Epoch 6: 56.9800\n",
      "  Epoch [7/250], Batch [700/704], Train Acc: 58.8103 Loss: 1.5431\n",
      "  Validation Accuracy after Epoch 7: 59.0800\n",
      "  Epoch [8/250], Batch [700/704], Train Acc: 60.2567 Loss: 1.3677\n",
      "  Validation Accuracy after Epoch 8: 59.3400\n",
      "  Epoch [9/250], Batch [700/704], Train Acc: 61.5335 Loss: 1.3876\n",
      "  Validation Accuracy after Epoch 9: 61.5000\n",
      "  Epoch [10/250], Batch [700/704], Train Acc: 62.6183 Loss: 1.2555\n",
      "  Validation Accuracy after Epoch 10: 63.1800\n",
      "  Epoch [11/250], Batch [700/704], Train Acc: 63.6741 Loss: 1.4261\n",
      "  Validation Accuracy after Epoch 11: 62.6600\n",
      "  Epoch [12/250], Batch [700/704], Train Acc: 64.2054 Loss: 1.1117\n",
      "  Validation Accuracy after Epoch 12: 64.4200\n",
      "  Epoch [13/250], Batch [700/704], Train Acc: 64.4129 Loss: 1.2961\n",
      "  Validation Accuracy after Epoch 13: 64.8200\n",
      "  Epoch [14/250], Batch [700/704], Train Acc: 64.7366 Loss: 1.2470\n",
      "  Validation Accuracy after Epoch 14: 64.5000\n",
      "  Epoch [15/250], Batch [700/704], Train Acc: 65.2790 Loss: 1.2019\n",
      "  Validation Accuracy after Epoch 15: 64.5400\n",
      "  Epoch [16/250], Batch [700/704], Train Acc: 65.2188 Loss: 1.2059\n",
      "  Validation Accuracy after Epoch 16: 63.5000\n",
      "  Epoch [17/250], Batch [700/704], Train Acc: 65.5469 Loss: 1.1480\n",
      "  Validation Accuracy after Epoch 17: 62.5800\n",
      "  Epoch [18/250], Batch [700/704], Train Acc: 65.5379 Loss: 1.1972\n",
      "  Validation Accuracy after Epoch 18: 61.1800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 09:30:30,570] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continued Study:\n",
      "Best trial: 0\n",
      "Best hyperparameters: {'model_type': 'smallresnet', 'batch_size': 128, 'optimizer_type': 'Adam', 'scheduler_type': 'ReduceLROnPlateau', 'weight_decay': 0.0005, 'learning_rate': 0.00032214137835438034, 'num_epochs': 115, 'factor': 0.3825196441327009, 'patience': 6}\n",
      "Best validation accuracy: 86.7\n"
     ]
    }
   ],
   "source": [
    "study_name = \"study_2025-03-11_01-51-41\"\n",
    "\n",
    "# Load and continue running trials\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=\"sqlite:///study.db\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=5)  # Run another batch\n",
    "print(\"Continued Study:\")\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(0.5),\n",
    "#     transforms.RandomRotation(15),\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "# ])\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# Aggressive Augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4, fill=0),  \n",
    "    transforms.RandomHorizontalFlip(p=0.5),  \n",
    "    transforms.RandomRotation(degrees=15),  \n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  \n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3)), # Random Erasing (Mimics `Cutout`)\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step_size_up' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr_min, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCyclicLR(optimizer, base_lr\u001b[38;5;241m=\u001b[39mlr_min, max_lr\u001b[38;5;241m=\u001b[39mlr_max, step_size_up\u001b[38;5;241m=\u001b[39mstep_size, step_size_down\u001b[38;5;241m=\u001b[39mstep_size, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9999\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_range\u001b[39m\u001b[38;5;124m\"\u001b[39m, cycle_momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m single_run(\n\u001b[1;32m     15\u001b[0m     model,\n\u001b[1;32m     16\u001b[0m     train_transform,\n\u001b[1;32m     17\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[1;32m     18\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     19\u001b[0m     optimizer_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     optimizer_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_min, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnesterov\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[1;32m     21\u001b[0m     scheduler_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCyclicLR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     scheduler_params\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_lr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_min, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_lr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_max, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size_up\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mstep_size_up\u001b[49m, \n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size_down\u001b[39m\u001b[38;5;124m\"\u001b[39m: step_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.9999\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_range\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcycle_momentum\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     }\n\u001b[1;32m     26\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'step_size_up' is not defined"
     ]
    }
   ],
   "source": [
    "model = LargeResNet0()\n",
    "num_epochs = 30\n",
    "lr_min = 1e-6\n",
    "lr_max = 1e-2\n",
    "epochs = 30\n",
    "len_train_dataset = 50_000 * 0.9\n",
    "step_size = (len_train_dataset/64) // 2\n",
    "\n",
    "single_run(\n",
    "    model,\n",
    "    train_transform,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=128,\n",
    "    optimizer_type=\"SGD\",\n",
    "    optimizer_params={\"lr\": lr_min, \"momentum\": 0.9, \"nesterov\": True},\n",
    "    scheduler_type=\"CyclicLR\",\n",
    "    scheduler_params={\n",
    "        \"base_lr\": lr_min, \"max_lr\": lr_max, \"step_size_up\": step_size, \n",
    "        \"step_size_down\": step_size, \"gamma\": 0.9999, \"mode\": \"exp_range\", \"cycle_momentum\": False\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SmallResNet0()\n",
    "model.to(device)\n",
    "\n",
    "# best_checkpoint_fp = \"checkpoints_study_2025-03-10_19-00-59/model_trial_0_val_acc_0.8604.pth\"\n",
    "best_checkpoint_fp = \"studies/study_2025-03-11_01-51-41/checkpoint/trial_0_val_acc_SmallResNet_86.7000_2025-03-11_02-15-35.pth\"\n",
    "\n",
    "if not best_checkpoint_fp:\n",
    "    checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "    with open(os.path.join(checkpoint_dir, \"study_details.json\"), \"r\") as f:\n",
    "        study_details = json.load(f)\n",
    "    best_checkpoint_fp = study_details[str(study.best_trial.number)][\"checkpoint_path\"]\n",
    "\n",
    "# Load the latest checkpoint\n",
    "checkpoint = torch.load(best_checkpoint_fp)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 77.65\n"
     ]
    }
   ],
   "source": [
    "from trainer import evaluate_model\n",
    "from data_loader import get_test_dataloader\n",
    "\n",
    "test_loader = get_test_dataloader(use_kaggle=True)\n",
    "acc, _ = evaluate_model(model, test_loader, device=device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on cifar10.1 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 65.6\n"
     ]
    }
   ],
   "source": [
    "from cifar10_1_dataloader import get_dataloader_10_1\n",
    "dataloader_10_1 = get_dataloader_10_1()\n",
    "\n",
    "acc, _ = evaluate_model(model, dataloader_10_1, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on Kaggle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_kaggle_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission file saved.\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file with test data\n",
    "kaggle_test_loader = get_kaggle_test_dataloader()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in kaggle_test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67.3k/67.3k [00:00<00:00, 330kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Deep Learning Spring 2025: CIFAR 10 classification"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import kaggle\n",
    "# kaggle.api.competition_submit(\n",
    "#     file_name=\"submission.csv\",\n",
    "#     message=\"0.9365\",\n",
    "#     competition=\"deep-learning-spring-2025-project-1\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk8i7jiGjSg0feqDTW0l2u",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
