{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIugLjz-A2Qd"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import optuna\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "from data_loader import get_cifar10_dataloaders, get_test_dataloader, get_kaggle_test_dataloader\n",
    "from helper import optimizer_map, scheduler_map, num_params, update_study_details, cifar_10_mean_std\n",
    "from models import BaseResNet, EfficientNetB0, SmallResNet0, LargeResNet0, SmallResNet1\n",
    "from trainer import train_model\n",
    "from run import single_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4z7iY1pkk2C"
   },
   "source": [
    "Configure the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e3wMn_41kd5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    study_dir = f\"studies/{trial.study.study_name}\"\n",
    "    os.makedirs(study_dir, exist_ok=True) # Create a directory for checkpoints if it doesn't exist\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 50, 125)\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"base\",\"smallresnet\", \"efficientnet\", \"largeresnet\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "    optimizer_type = trial.suggest_categorical(\"optimizer_type\", [\"Adam\", \"SGD\", \"AdamW\"])\n",
    "    scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"OneCycleLR\", \"ReduceLROnPlateau\"])\n",
    "    \n",
    "    optimizer_params = {}\n",
    "    if optimizer_type == \"SGD\":\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"lr\", 0.001, 0.1, log=True)\n",
    "        optimizer_params[\"momentum\"] = trial.suggest_float(\"momentum\", 0.8, 0.99)\n",
    "        optimizer_params[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-5, 5e-4, log=True)\n",
    "        scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"OneCycleLR\", \"ReduceLROnPlateau\"])\n",
    "        optimizer_params[\"nesterov\"] = scheduler_type != \"ReduceLROnPlateau\"\n",
    "    \n",
    "    elif optimizer_type == \"Adam\":\n",
    "        optimizer_params[\"betas\"] = (\n",
    "            trial.suggest_float(\"beta1\", 0.85, 0.95), \n",
    "            trial.suggest_float(\"beta2\", 0.99, 0.999)\n",
    "        )\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "        optimizer_params[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "        if scheduler_type == \"OneCycleLR\":\n",
    "            scheduler_type = None\n",
    "\n",
    "    elif optimizer_type == \"AdamW\":\n",
    "        optimizer_params[\"betas\"] = (\n",
    "            trial.suggest_float(\"beta1\", 0.85, 0.95), \n",
    "            trial.suggest_float(\"beta2\", 0.99, 0.999)\n",
    "        )\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"lr\", 1e-5, 5e-3, log=True)\n",
    "        optimizer_params[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-3, 1e-1, log=True)\n",
    "        scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"OneCycleLR\", \"ReduceLROnPlateau\"])\n",
    "\n",
    "    \n",
    "    # Realistic tranformation for better generalization\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),  # Mild color variations\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**cifar_10_mean_std),\n",
    "    ])\n",
    "        \n",
    "    train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "        train_transform,\n",
    "        subset_percent=1, \n",
    "        valid_size=0.1,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        use_kaggle=True\n",
    "    )\n",
    "\n",
    "    scheduler_params = {}\n",
    "    if scheduler_type == \"CosineAnnealingLR\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 100, 150)\n",
    "        scheduler_params[\"T_max\"] = num_epochs\n",
    "        scheduler_params[\"eta_min\"] = trial.suggest_float(\"eta_min\", 1e-6, 1e-3, log=True)\n",
    "        \n",
    "    elif scheduler_type == \"ReduceLROnPlateau\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 75, 125)\n",
    "        scheduler_params[\"factor\"] = trial.suggest_float(\"factor\", 0.1, 0.5)\n",
    "        scheduler_params[\"patience\"] = trial.suggest_int(\"patience\", 5, 20)\n",
    "        scheduler_params[\"threshold\"] = trial.suggest_float(\"threshold\", 0.01, 0.1)\n",
    "        scheduler_params[\"mode\"] = \"min\"\n",
    "        \n",
    "    elif scheduler_type == \"OneCycleLR\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 50, 75)\n",
    "        if optimizer_type == \"SGD\":\n",
    "            scheduler_params[\"max_lr\"] = trial.suggest_float(\"max_lr\", 0.01, 0.3)\n",
    "        else: # AdamW\n",
    "            scheduler_params[\"max_lr\"] = trial.suggest_float(\"max_lr\", 0.001, 0.01)\n",
    "        scheduler_params[\"steps_per_epoch\"] = len(train_loader)\n",
    "        scheduler_params[\"epochs\"] = num_epochs\n",
    "        scheduler_params[\"anneal_strategy\"] = \"cos\"\n",
    "\n",
    "                \n",
    "    # Select Model\n",
    "    if model_type == \"smallresnet\":\n",
    "        model = SmallResNet0()\n",
    "    elif model_type == \"efficientnet\":\n",
    "        model = EfficientNetB0()\n",
    "    elif model_type == \"largeresnet\":\n",
    "        model = LargeResNet0()\n",
    "    else:\n",
    "        model = BaseResNet()\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    trial_details = trial.params.copy()\n",
    "    trial_details[\"trainable_parameters\"] = num_params(model)\n",
    "    \n",
    "    # Print trial details\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{trial.number=}\")\n",
    "    for param, val in trial_details.items():\n",
    "        print(f\"{param}: {val}\")\n",
    "    print(\"- \" * 25)\n",
    "    update_study_details(study_dir, trial.number, trial_details)\n",
    "\n",
    "    optimizer = optimizer_map[optimizer_type](model.parameters(), **optimizer_params)\n",
    "    scheduler = scheduler_map[scheduler_type](optimizer, **scheduler_params) if scheduler_type else None\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # Checkpoint the model with the best validation accuracy\n",
    "    chkpt_dir = os.path.join(study_dir, \"checkpoint\")\n",
    "    plot_dir = os.path.join(study_dir, \"plots\")\n",
    "    os.makedirs(chkpt_dir, exist_ok=True)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        model, train_loader, criterion, optimizer, valid_loader=valid_loader, num_epochs=num_epochs, \n",
    "        device=device, scheduler=scheduler, trial=trial, chkpt_dir=chkpt_dir, plot_dir=plot_dir\n",
    "    )\n",
    "    \n",
    "    trial_details[\"best_val_accuracy\"] = best_val_accuracy\n",
    "    update_study_details(study_dir, trial.number, trial_details)\n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start new study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 02:29:53,436] A new study created in RDB with name: study_2025-03-12_02-29-51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=0\n",
      "num_epochs: 113\n",
      "model_type: smallresnet\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: CosineAnnealingLR\n",
      "beta1: 0.9202155036052446\n",
      "beta2: 0.9977411320853791\n",
      "lr: 3.494686994613835e-05\n",
      "weight_decay: 0.01796373082906369\n",
      "eta_min: 2.4823405413306104e-06\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/113], Batch [80/88], Train Acc: 16.5234 Loss: 2.1038\n",
      "  Validation Accuracy after Epoch 1: 24.0200\n",
      "  Cidar10.1 Accuracy: 22.45\n",
      "  Epoch [2/113], Batch [80/88], Train Acc: 21.4917 Loss: 2.0582\n",
      "  Validation Accuracy after Epoch 2: 24.5000\n",
      "  Cidar10.1 Accuracy: 23.35\n",
      "  Epoch [3/113], Batch [80/88], Train Acc: 27.2290 Loss: 1.9905\n",
      "  Validation Accuracy after Epoch 3: 32.2800\n",
      "  Cidar10.1 Accuracy: 27.3\n",
      "  Epoch [4/113], Batch [80/88], Train Acc: 32.4854 Loss: 1.9102\n",
      "  Validation Accuracy after Epoch 4: 35.9600\n",
      "  Cidar10.1 Accuracy: 29.4\n",
      "  Epoch [5/113], Batch [80/88], Train Acc: 33.6157 Loss: 1.8255\n",
      "  Validation Accuracy after Epoch 5: 36.5200\n",
      "  Cidar10.1 Accuracy: 30.75\n",
      "  Epoch [6/113], Batch [80/88], Train Acc: 37.6147 Loss: 1.8178\n",
      "  Validation Accuracy after Epoch 6: 40.9400\n",
      "  Cidar10.1 Accuracy: 33.45\n",
      "  Epoch [7/113], Batch [80/88], Train Acc: 39.3506 Loss: 1.7575\n",
      "  Validation Accuracy after Epoch 7: 41.5200\n",
      "  Cidar10.1 Accuracy: 33.65\n",
      "  Epoch [8/113], Batch [80/88], Train Acc: 41.1304 Loss: 1.7581\n",
      "  Validation Accuracy after Epoch 8: 41.9600\n",
      "  Cidar10.1 Accuracy: 35.1\n",
      "  Epoch [9/113], Batch [80/88], Train Acc: 43.3838 Loss: 1.6733\n",
      "  Validation Accuracy after Epoch 9: 45.4400\n",
      "  Cidar10.1 Accuracy: 35.7\n",
      "  Epoch [10/113], Batch [80/88], Train Acc: 44.4824 Loss: 1.6939\n",
      "  Validation Accuracy after Epoch 10: 43.9600\n",
      "  Cidar10.1 Accuracy: 35.15\n",
      "  Epoch [11/113], Batch [80/88], Train Acc: 45.4150 Loss: 1.6229\n",
      "  Validation Accuracy after Epoch 11: 47.8200\n",
      "  Cidar10.1 Accuracy: 38.3\n",
      "  Epoch [12/113], Batch [80/88], Train Acc: 47.1069 Loss: 1.6357\n",
      "  Validation Accuracy after Epoch 12: 47.6600\n",
      "  Cidar10.1 Accuracy: 39.4\n",
      "  Epoch [13/113], Batch [80/88], Train Acc: 47.2266 Loss: 1.6237\n",
      "  Validation Accuracy after Epoch 13: 48.2000\n",
      "  Cidar10.1 Accuracy: 38.65\n",
      "  Epoch [14/113], Batch [80/88], Train Acc: 49.4995 Loss: 1.5511\n",
      "  Validation Accuracy after Epoch 14: 50.6800\n",
      "  Cidar10.1 Accuracy: 40.85\n",
      "  Epoch [15/113], Batch [80/88], Train Acc: 49.7461 Loss: 1.5575\n",
      "  Validation Accuracy after Epoch 15: 50.7000\n",
      "  Cidar10.1 Accuracy: 41.3\n",
      "  Epoch [16/113], Batch [80/88], Train Acc: 50.7422 Loss: 1.5484\n",
      "  Validation Accuracy after Epoch 16: 52.4800\n",
      "  Cidar10.1 Accuracy: 42.7\n",
      "  Epoch [17/113], Batch [80/88], Train Acc: 52.0557 Loss: 1.4562\n",
      "  Validation Accuracy after Epoch 17: 53.2800\n",
      "  Cidar10.1 Accuracy: 43.2\n",
      "  Epoch [18/113], Batch [80/88], Train Acc: 52.5269 Loss: 1.5111\n",
      "  Validation Accuracy after Epoch 18: 52.8000\n",
      "  Cidar10.1 Accuracy: 42.7\n",
      "  Epoch [19/113], Batch [80/88], Train Acc: 53.4741 Loss: 1.5128\n",
      "  Validation Accuracy after Epoch 19: 54.2200\n",
      "  Cidar10.1 Accuracy: 44.25\n",
      "  Epoch [20/113], Batch [80/88], Train Acc: 54.7412 Loss: 1.4610\n",
      "  Validation Accuracy after Epoch 20: 55.1200\n",
      "  Cidar10.1 Accuracy: 43.75\n",
      "  Epoch [21/113], Batch [80/88], Train Acc: 54.8779 Loss: 1.5251\n",
      "  Validation Accuracy after Epoch 21: 54.3800\n",
      "  Cidar10.1 Accuracy: 43.95\n",
      "  Epoch [22/113], Batch [80/88], Train Acc: 55.6421 Loss: 1.4979\n",
      "  Validation Accuracy after Epoch 22: 56.7800\n",
      "  Cidar10.1 Accuracy: 45.85\n",
      "  Epoch [23/113], Batch [80/88], Train Acc: 56.6650 Loss: 1.4868\n",
      "  Validation Accuracy after Epoch 23: 55.8600\n",
      "  Cidar10.1 Accuracy: 45.5\n",
      "  Epoch [24/113], Batch [80/88], Train Acc: 56.7700 Loss: 1.4985\n",
      "  Validation Accuracy after Epoch 24: 57.6800\n",
      "  Cidar10.1 Accuracy: 47.35\n",
      "  Epoch [25/113], Batch [80/88], Train Acc: 57.6782 Loss: 1.4409\n",
      "  Validation Accuracy after Epoch 25: 57.7000\n",
      "  Cidar10.1 Accuracy: 47.8\n",
      "  Epoch [26/113], Batch [80/88], Train Acc: 57.4438 Loss: 1.4739\n",
      "  Validation Accuracy after Epoch 26: 58.0800\n",
      "  Cidar10.1 Accuracy: 46.3\n",
      "  Epoch [27/113], Batch [80/88], Train Acc: 59.1772 Loss: 1.4214\n",
      "  Validation Accuracy after Epoch 27: 59.5600\n",
      "  Cidar10.1 Accuracy: 48.5\n",
      "  Epoch [28/113], Batch [80/88], Train Acc: 59.3799 Loss: 1.4065\n",
      "  Validation Accuracy after Epoch 28: 58.4600\n",
      "  Cidar10.1 Accuracy: 48.45\n",
      "  Epoch [29/113], Batch [80/88], Train Acc: 59.5239 Loss: 1.3887\n",
      "  Validation Accuracy after Epoch 29: 59.9800\n",
      "  Cidar10.1 Accuracy: 48.5\n",
      "  Epoch [30/113], Batch [80/88], Train Acc: 60.8154 Loss: 1.3630\n",
      "  Validation Accuracy after Epoch 30: 60.6600\n",
      "  Cidar10.1 Accuracy: 50.15\n",
      "  Epoch [31/113], Batch [80/88], Train Acc: 61.0840 Loss: 1.3359\n",
      "  Validation Accuracy after Epoch 31: 60.5200\n",
      "  Cidar10.1 Accuracy: 49.75\n",
      "  Epoch [32/113], Batch [80/88], Train Acc: 61.4966 Loss: 1.2953\n",
      "  Validation Accuracy after Epoch 32: 61.9200\n",
      "  Cidar10.1 Accuracy: 51.2\n",
      "  Epoch [33/113], Batch [80/88], Train Acc: 62.3364 Loss: 1.3876\n",
      "  Validation Accuracy after Epoch 33: 61.5400\n",
      "  Cidar10.1 Accuracy: 49.25\n",
      "  Epoch [34/113], Batch [80/88], Train Acc: 61.8628 Loss: 1.3304\n",
      "  Validation Accuracy after Epoch 34: 61.6200\n",
      "  Cidar10.1 Accuracy: 50.3\n",
      "  Epoch [35/113], Batch [80/88], Train Acc: 63.1543 Loss: 1.3543\n",
      "  Validation Accuracy after Epoch 35: 63.1200\n",
      "  Cidar10.1 Accuracy: 52.1\n",
      "  Epoch [36/113], Batch [80/88], Train Acc: 63.1006 Loss: 1.3066\n",
      "  Validation Accuracy after Epoch 36: 61.8400\n",
      "  Cidar10.1 Accuracy: 50.95\n",
      "  Epoch [37/113], Batch [80/88], Train Acc: 63.7256 Loss: 1.3334\n",
      "  Validation Accuracy after Epoch 37: 63.6000\n",
      "  Cidar10.1 Accuracy: 53.25\n",
      "  Epoch [38/113], Batch [80/88], Train Acc: 64.5728 Loss: 1.2693\n",
      "  Validation Accuracy after Epoch 38: 64.5600\n",
      "  Cidar10.1 Accuracy: 52.0\n",
      "  Epoch [39/113], Batch [80/88], Train Acc: 64.3628 Loss: 1.2673\n",
      "  Validation Accuracy after Epoch 39: 63.9200\n",
      "  Cidar10.1 Accuracy: 52.2\n",
      "  Epoch [40/113], Batch [80/88], Train Acc: 65.1489 Loss: 1.2746\n",
      "  Validation Accuracy after Epoch 40: 65.5400\n",
      "  Cidar10.1 Accuracy: 52.7\n",
      "  Epoch [41/113], Batch [80/88], Train Acc: 65.5908 Loss: 1.2491\n",
      "  Validation Accuracy after Epoch 41: 64.2000\n",
      "  Cidar10.1 Accuracy: 53.05\n",
      "  Epoch [42/113], Batch [80/88], Train Acc: 65.6567 Loss: 1.2136\n",
      "  Validation Accuracy after Epoch 42: 64.7000\n",
      "  Cidar10.1 Accuracy: 53.35\n",
      "  Epoch [43/113], Batch [80/88], Train Acc: 66.8652 Loss: 1.2605\n",
      "  Validation Accuracy after Epoch 43: 65.7000\n",
      "  Cidar10.1 Accuracy: 54.1\n",
      "  Epoch [44/113], Batch [80/88], Train Acc: 66.2744 Loss: 1.2512\n",
      "  Validation Accuracy after Epoch 44: 64.4200\n",
      "  Cidar10.1 Accuracy: 52.7\n",
      "  Epoch [45/113], Batch [80/88], Train Acc: 66.9751 Loss: 1.2382\n",
      "  Validation Accuracy after Epoch 45: 66.1000\n",
      "  Cidar10.1 Accuracy: 54.7\n",
      "  Epoch [46/113], Batch [80/88], Train Acc: 67.6270 Loss: 1.2653\n",
      "  Validation Accuracy after Epoch 46: 64.9800\n",
      "  Cidar10.1 Accuracy: 53.3\n",
      "  Epoch [47/113], Batch [80/88], Train Acc: 67.1118 Loss: 1.1909\n",
      "  Validation Accuracy after Epoch 47: 67.3200\n",
      "  Cidar10.1 Accuracy: 54.7\n",
      "  Epoch [48/113], Batch [80/88], Train Acc: 68.3594 Loss: 1.1748\n",
      "  Validation Accuracy after Epoch 48: 67.0600\n",
      "  Cidar10.1 Accuracy: 55.6\n",
      "  Epoch [49/113], Batch [80/88], Train Acc: 68.2617 Loss: 1.2260\n",
      "  Validation Accuracy after Epoch 49: 65.0000\n",
      "  Cidar10.1 Accuracy: 53.75\n",
      "  Epoch [50/113], Batch [80/88], Train Acc: 68.3398 Loss: 1.1736\n",
      "  Validation Accuracy after Epoch 50: 67.7600\n",
      "  Cidar10.1 Accuracy: 56.5\n",
      "  Epoch [51/113], Batch [80/88], Train Acc: 69.3726 Loss: 1.1636\n",
      "  Validation Accuracy after Epoch 51: 66.6200\n",
      "  Cidar10.1 Accuracy: 55.35\n",
      "  Epoch [52/113], Batch [80/88], Train Acc: 68.7622 Loss: 1.1933\n",
      "  Validation Accuracy after Epoch 52: 66.3600\n",
      "  Cidar10.1 Accuracy: 55.15\n",
      "  Epoch [53/113], Batch [80/88], Train Acc: 69.7290 Loss: 1.1618\n",
      "  Validation Accuracy after Epoch 53: 68.6000\n",
      "  Cidar10.1 Accuracy: 55.8\n",
      "  Epoch [54/113], Batch [80/88], Train Acc: 70.0537 Loss: 1.1476\n",
      "  Validation Accuracy after Epoch 54: 67.3200\n",
      "  Cidar10.1 Accuracy: 55.1\n",
      "  Epoch [55/113], Batch [80/88], Train Acc: 69.6240 Loss: 1.2003\n",
      "  Validation Accuracy after Epoch 55: 68.4400\n",
      "  Cidar10.1 Accuracy: 56.6\n",
      "  Epoch [56/113], Batch [80/88], Train Acc: 70.7178 Loss: 1.1550\n",
      "  Validation Accuracy after Epoch 56: 68.5800\n",
      "  Cidar10.1 Accuracy: 56.2\n",
      "  Epoch [57/113], Batch [80/88], Train Acc: 70.3809 Loss: 1.1360\n",
      "  Validation Accuracy after Epoch 57: 68.1600\n",
      "  Cidar10.1 Accuracy: 55.4\n",
      "  Epoch [58/113], Batch [80/88], Train Acc: 71.2500 Loss: 1.0745\n",
      "  Validation Accuracy after Epoch 58: 69.5600\n",
      "  Cidar10.1 Accuracy: 57.3\n",
      "  Epoch [59/113], Batch [80/88], Train Acc: 71.5674 Loss: 1.1144\n",
      "  Validation Accuracy after Epoch 59: 68.2800\n",
      "  Cidar10.1 Accuracy: 56.85\n",
      "  Epoch [60/113], Batch [80/88], Train Acc: 71.4111 Loss: 1.1738\n",
      "  Validation Accuracy after Epoch 60: 69.9000\n",
      "  Cidar10.1 Accuracy: 57.2\n",
      "  Epoch [61/113], Batch [80/88], Train Acc: 72.3853 Loss: 1.1205\n",
      "  Validation Accuracy after Epoch 61: 70.1400\n",
      "  Cidar10.1 Accuracy: 57.3\n",
      "  Epoch [62/113], Batch [80/88], Train Acc: 71.6455 Loss: 1.1847\n",
      "  Validation Accuracy after Epoch 62: 68.7800\n",
      "  Cidar10.1 Accuracy: 57.45\n",
      "  Epoch [63/113], Batch [80/88], Train Acc: 72.5220 Loss: 1.0687\n",
      "  Validation Accuracy after Epoch 63: 70.8800\n",
      "  Cidar10.1 Accuracy: 58.3\n",
      "  Epoch [64/113], Batch [80/88], Train Acc: 72.8613 Loss: 1.0499\n",
      "  Validation Accuracy after Epoch 64: 69.8000\n",
      "  Cidar10.1 Accuracy: 57.0\n",
      "  Epoch [65/113], Batch [80/88], Train Acc: 72.3364 Loss: 1.0918\n",
      "  Validation Accuracy after Epoch 65: 71.1000\n",
      "  Cidar10.1 Accuracy: 57.5\n",
      "  Epoch [66/113], Batch [80/88], Train Acc: 73.7842 Loss: 1.0927\n",
      "  Validation Accuracy after Epoch 66: 71.8800\n",
      "  Cidar10.1 Accuracy: 58.65\n",
      "  Epoch [67/113], Batch [80/88], Train Acc: 73.3960 Loss: 1.1449\n",
      "  Validation Accuracy after Epoch 67: 69.5600\n",
      "  Cidar10.1 Accuracy: 57.1\n",
      "  Epoch [68/113], Batch [80/88], Train Acc: 73.4668 Loss: 1.0244\n",
      "  Validation Accuracy after Epoch 68: 71.8200\n",
      "  Cidar10.1 Accuracy: 58.7\n",
      "  Epoch [69/113], Batch [80/88], Train Acc: 74.2334 Loss: 1.1093\n",
      "  Validation Accuracy after Epoch 69: 70.8800\n",
      "  Cidar10.1 Accuracy: 58.35\n",
      "  Epoch [70/113], Batch [80/88], Train Acc: 73.7427 Loss: 1.0509\n",
      "  Validation Accuracy after Epoch 70: 71.4800\n",
      "  Cidar10.1 Accuracy: 59.2\n",
      "  Epoch [71/113], Batch [80/88], Train Acc: 74.6167 Loss: 1.0403\n",
      "  Validation Accuracy after Epoch 71: 72.0400\n",
      "  Cidar10.1 Accuracy: 59.25\n",
      "  Epoch [72/113], Batch [80/88], Train Acc: 74.4189 Loss: 1.1424\n",
      "  Validation Accuracy after Epoch 72: 71.1200\n",
      "  Cidar10.1 Accuracy: 57.4\n",
      "  Epoch [73/113], Batch [80/88], Train Acc: 74.3164 Loss: 1.1036\n",
      "  Validation Accuracy after Epoch 73: 72.6400\n",
      "  Cidar10.1 Accuracy: 59.55\n",
      "  Epoch [74/113], Batch [80/88], Train Acc: 75.2466 Loss: 1.0356\n",
      "  Validation Accuracy after Epoch 74: 72.3400\n",
      "  Cidar10.1 Accuracy: 58.5\n",
      "  Epoch [75/113], Batch [80/88], Train Acc: 74.5728 Loss: 1.0309\n",
      "  Validation Accuracy after Epoch 75: 71.4600\n",
      "  Cidar10.1 Accuracy: 59.25\n",
      "  Epoch [76/113], Batch [80/88], Train Acc: 75.6738 Loss: 0.9776\n",
      "  Validation Accuracy after Epoch 76: 73.4400\n",
      "  Cidar10.1 Accuracy: 59.75\n",
      "  Epoch [77/113], Batch [80/88], Train Acc: 75.8936 Loss: 1.0562\n",
      "  Validation Accuracy after Epoch 77: 71.9600\n",
      "  Cidar10.1 Accuracy: 57.65\n",
      "  Epoch [78/113], Batch [80/88], Train Acc: 75.7349 Loss: 1.0529\n",
      "  Validation Accuracy after Epoch 78: 73.5200\n",
      "  Cidar10.1 Accuracy: 60.2\n",
      "  Epoch [79/113], Batch [80/88], Train Acc: 76.6406 Loss: 0.9812\n",
      "  Validation Accuracy after Epoch 79: 73.0000\n",
      "  Cidar10.1 Accuracy: 59.75\n",
      "  Epoch [80/113], Batch [80/88], Train Acc: 75.9399 Loss: 1.0374\n",
      "  Validation Accuracy after Epoch 80: 73.2200\n",
      "  Cidar10.1 Accuracy: 59.4\n",
      "  Epoch [81/113], Batch [80/88], Train Acc: 76.3428 Loss: 1.0519\n",
      "  Validation Accuracy after Epoch 81: 73.9600\n",
      "  Cidar10.1 Accuracy: 61.15\n",
      "  Epoch [82/113], Batch [80/88], Train Acc: 76.9580 Loss: 1.0767\n",
      "  Validation Accuracy after Epoch 82: 72.6800\n",
      "  Cidar10.1 Accuracy: 59.7\n",
      "  Epoch [83/113], Batch [80/88], Train Acc: 76.8091 Loss: 1.0283\n",
      "  Validation Accuracy after Epoch 83: 73.5800\n",
      "  Cidar10.1 Accuracy: 59.75\n",
      "  Epoch [84/113], Batch [80/88], Train Acc: 77.5024 Loss: 0.9714\n",
      "  Validation Accuracy after Epoch 84: 73.3200\n",
      "  Cidar10.1 Accuracy: 60.0\n",
      "  Epoch [85/113], Batch [80/88], Train Acc: 76.9507 Loss: 1.0553\n",
      "  Validation Accuracy after Epoch 85: 72.9400\n",
      "  Cidar10.1 Accuracy: 58.85\n",
      "  Epoch [86/113], Batch [80/88], Train Acc: 77.0508 Loss: 0.9973\n",
      "  Validation Accuracy after Epoch 86: 74.1800\n",
      "  Cidar10.1 Accuracy: 60.9\n",
      "  Epoch [87/113], Batch [80/88], Train Acc: 77.9810 Loss: 0.9710\n",
      "  Validation Accuracy after Epoch 87: 73.5000\n",
      "  Cidar10.1 Accuracy: 60.7\n",
      "  Epoch [88/113], Batch [80/88], Train Acc: 77.8418 Loss: 1.0622\n",
      "  Validation Accuracy after Epoch 88: 74.0200\n",
      "  Cidar10.1 Accuracy: 59.9\n",
      "  Epoch [89/113], Batch [80/88], Train Acc: 78.4521 Loss: 1.0029\n",
      "  Validation Accuracy after Epoch 89: 74.6600\n",
      "  Cidar10.1 Accuracy: 61.4\n",
      "  Epoch [90/113], Batch [80/88], Train Acc: 78.0273 Loss: 1.0764\n",
      "  Validation Accuracy after Epoch 90: 74.4600\n",
      "  Cidar10.1 Accuracy: 59.9\n",
      "  Epoch [91/113], Batch [80/88], Train Acc: 78.3203 Loss: 0.9785\n",
      "  Validation Accuracy after Epoch 91: 74.9000\n",
      "  Cidar10.1 Accuracy: 61.4\n",
      "  Epoch [92/113], Batch [80/88], Train Acc: 79.0039 Loss: 0.9854\n",
      "  Validation Accuracy after Epoch 92: 73.8800\n",
      "  Cidar10.1 Accuracy: 60.0\n",
      "  Epoch [93/113], Batch [80/88], Train Acc: 78.1812 Loss: 0.9911\n",
      "  Validation Accuracy after Epoch 93: 74.6400\n",
      "  Cidar10.1 Accuracy: 59.9\n",
      "  Epoch [94/113], Batch [80/88], Train Acc: 79.0820 Loss: 0.9341\n",
      "  Validation Accuracy after Epoch 94: 74.4400\n",
      "  Cidar10.1 Accuracy: 60.9\n",
      "  Epoch [95/113], Batch [80/88], Train Acc: 78.9282 Loss: 0.9739\n",
      "  Validation Accuracy after Epoch 95: 74.3200\n",
      "  Cidar10.1 Accuracy: 59.85\n",
      "  Epoch [96/113], Batch [80/88], Train Acc: 78.9990 Loss: 0.9377\n",
      "  Validation Accuracy after Epoch 96: 75.5800\n",
      "  Cidar10.1 Accuracy: 61.5\n",
      "  Epoch [97/113], Batch [80/88], Train Acc: 80.0244 Loss: 0.9673\n",
      "  Validation Accuracy after Epoch 97: 74.3600\n",
      "  Cidar10.1 Accuracy: 61.2\n",
      "  Epoch [98/113], Batch [80/88], Train Acc: 79.2749 Loss: 1.0080\n",
      "  Validation Accuracy after Epoch 98: 74.9600\n",
      "  Cidar10.1 Accuracy: 60.75\n",
      "  Epoch [99/113], Batch [80/88], Train Acc: 79.9536 Loss: 0.9084\n",
      "  Validation Accuracy after Epoch 99: 75.6000\n",
      "  Cidar10.1 Accuracy: 61.95\n",
      "  Epoch [100/113], Batch [80/88], Train Acc: 80.2612 Loss: 0.9474\n",
      "  Validation Accuracy after Epoch 100: 75.4400\n",
      "  Cidar10.1 Accuracy: 60.0\n",
      "  Epoch [101/113], Batch [80/88], Train Acc: 79.7974 Loss: 0.9282\n",
      "  Validation Accuracy after Epoch 101: 75.9600\n",
      "  Cidar10.1 Accuracy: 61.8\n",
      "  Epoch [102/113], Batch [80/88], Train Acc: 80.8643 Loss: 0.9314\n",
      "  Validation Accuracy after Epoch 102: 76.3400\n",
      "  Cidar10.1 Accuracy: 62.4\n",
      "  Epoch [103/113], Batch [80/88], Train Acc: 80.2881 Loss: 0.9319\n",
      "  Validation Accuracy after Epoch 103: 75.1800\n",
      "  Cidar10.1 Accuracy: 61.2\n",
      "  Epoch [104/113], Batch [80/88], Train Acc: 80.7471 Loss: 0.9448\n",
      "  Validation Accuracy after Epoch 104: 77.2400\n",
      "  Cidar10.1 Accuracy: 62.4\n",
      "  Epoch [105/113], Batch [80/88], Train Acc: 81.2427 Loss: 0.9711\n",
      "  Validation Accuracy after Epoch 105: 75.3000\n",
      "  Cidar10.1 Accuracy: 61.3\n",
      "  Epoch [106/113], Batch [80/88], Train Acc: 80.5225 Loss: 0.9011\n",
      "  Validation Accuracy after Epoch 106: 75.8200\n",
      "  Cidar10.1 Accuracy: 63.05\n",
      "  Epoch [107/113], Batch [80/88], Train Acc: 81.6113 Loss: 0.9586\n",
      "  Validation Accuracy after Epoch 107: 77.5000\n",
      "  Cidar10.1 Accuracy: 63.45\n",
      "  Epoch [108/113], Batch [80/88], Train Acc: 81.1377 Loss: 0.9181\n",
      "  Validation Accuracy after Epoch 108: 76.4800\n",
      "  Cidar10.1 Accuracy: 62.2\n",
      "  Epoch [109/113], Batch [80/88], Train Acc: 80.9277 Loss: 0.9370\n",
      "  Validation Accuracy after Epoch 109: 76.7400\n",
      "  Cidar10.1 Accuracy: 63.85\n",
      "  Epoch [110/113], Batch [80/88], Train Acc: 82.2778 Loss: 0.9545\n",
      "  Validation Accuracy after Epoch 110: 76.8400\n",
      "  Cidar10.1 Accuracy: 62.4\n",
      "  Epoch [111/113], Batch [80/88], Train Acc: 81.4209 Loss: 0.9295\n",
      "  Validation Accuracy after Epoch 111: 76.7800\n",
      "  Cidar10.1 Accuracy: 62.95\n",
      "  Epoch [112/113], Batch [80/88], Train Acc: 82.3560 Loss: 0.9162\n",
      "  Validation Accuracy after Epoch 112: 76.8000\n",
      "  Cidar10.1 Accuracy: 63.55\n",
      "  Epoch [113/113], Batch [80/88], Train Acc: 81.9043 Loss: 0.9637\n",
      "  Validation Accuracy after Epoch 113: 76.1000\n",
      "  Cidar10.1 Accuracy: 61.95\n",
      "Trial 0 complete. Best Validation Accuracy: 77.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 02:48:33,594] Trial 0 finished with value: 77.5 and parameters: {'num_epochs': 113, 'model_type': 'smallresnet', 'batch_size': 512, 'optimizer_type': 'AdamW', 'scheduler_type': 'CosineAnnealingLR', 'beta1': 0.9202155036052446, 'beta2': 0.9977411320853791, 'lr': 3.494686994613835e-05, 'weight_decay': 0.01796373082906369, 'eta_min': 2.4823405413306104e-06}. Best is trial 0 with value: 77.5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=1\n",
      "num_epochs: 99\n",
      "model_type: efficientnet\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.879263309837687\n",
      "beta2: 0.9902483573125087\n",
      "lr: 1.0489767423709725e-05\n",
      "weight_decay: 6.32754805913792e-06\n",
      "factor: 0.11188403904979145\n",
      "patience: 6\n",
      "threshold: 0.092594865117007\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/99], Batch [350/352], Train Acc: 13.0625 Loss: 2.3211\n",
      "  Validation Accuracy after Epoch 1: 14.4400\n",
      "  Cidar10.1 Accuracy: 13.95\n",
      "  Epoch [2/99], Batch [350/352], Train Acc: 14.7612 Loss: 2.2246\n",
      "  Validation Accuracy after Epoch 2: 15.4200\n",
      "  Cidar10.1 Accuracy: 15.3\n",
      "  Epoch [3/99], Batch [350/352], Train Acc: 16.6272 Loss: 2.2201\n",
      "  Validation Accuracy after Epoch 3: 19.8200\n",
      "  Cidar10.1 Accuracy: 17.75\n",
      "  Epoch [4/99], Batch [350/352], Train Acc: 19.0781 Loss: 2.1436\n",
      "  Validation Accuracy after Epoch 4: 20.7400\n",
      "  Cidar10.1 Accuracy: 18.95\n",
      "  Epoch [5/99], Batch [350/352], Train Acc: 21.6942 Loss: 2.1016\n",
      "  Validation Accuracy after Epoch 5: 23.3600\n",
      "  Cidar10.1 Accuracy: 20.1\n",
      "  Epoch [6/99], Batch [350/352], Train Acc: 23.8482 Loss: 2.0228\n",
      "  Validation Accuracy after Epoch 6: 25.3800\n",
      "  Cidar10.1 Accuracy: 21.2\n",
      "  Epoch [7/99], Batch [350/352], Train Acc: 25.8884 Loss: 2.1203\n",
      "  Validation Accuracy after Epoch 7: 27.7200\n",
      "  Cidar10.1 Accuracy: 22.45\n",
      "  Epoch [8/99], Batch [350/352], Train Acc: 27.1205 Loss: 1.9476\n",
      "  Validation Accuracy after Epoch 8: 28.7600\n",
      "  Cidar10.1 Accuracy: 23.35\n",
      "  Epoch [9/99], Batch [350/352], Train Acc: 28.8170 Loss: 1.9420\n",
      "  Validation Accuracy after Epoch 9: 30.5000\n",
      "  Cidar10.1 Accuracy: 24.9\n",
      "  Epoch [10/99], Batch [350/352], Train Acc: 29.7946 Loss: 1.9914\n",
      "  Validation Accuracy after Epoch 10: 30.7600\n",
      "  Cidar10.1 Accuracy: 25.4\n",
      "  Epoch [11/99], Batch [350/352], Train Acc: 31.6540 Loss: 1.8215\n",
      "  Validation Accuracy after Epoch 11: 31.6400\n",
      "  Cidar10.1 Accuracy: 26.85\n",
      "  Epoch [12/99], Batch [350/352], Train Acc: 32.4241 Loss: 1.9025\n",
      "  Validation Accuracy after Epoch 12: 32.8000\n",
      "  Cidar10.1 Accuracy: 28.0\n",
      "  Epoch [13/99], Batch [350/352], Train Acc: 33.3214 Loss: 2.0175\n",
      "  Validation Accuracy after Epoch 13: 34.7800\n",
      "  Cidar10.1 Accuracy: 27.9\n",
      "  Epoch [14/99], Batch [350/352], Train Acc: 34.0871 Loss: 1.9550\n",
      "  Validation Accuracy after Epoch 14: 34.4400\n",
      "  Cidar10.1 Accuracy: 28.45\n",
      "  Epoch [15/99], Batch [350/352], Train Acc: 34.2165 Loss: 1.8364\n",
      "  Validation Accuracy after Epoch 15: 35.5200\n",
      "  Cidar10.1 Accuracy: 27.6\n",
      "  Epoch [16/99], Batch [350/352], Train Acc: 34.2701 Loss: 2.0025\n",
      "  Validation Accuracy after Epoch 16: 35.1800\n",
      "  Cidar10.1 Accuracy: 27.9\n",
      "  Epoch [17/99], Batch [350/352], Train Acc: 34.7768 Loss: 1.9067\n",
      "  Validation Accuracy after Epoch 17: 35.5400\n",
      "  Cidar10.1 Accuracy: 27.6\n",
      "  Epoch [18/99], Batch [350/352], Train Acc: 34.7009 Loss: 1.8672\n",
      "  Validation Accuracy after Epoch 18: 35.4200\n",
      "  Cidar10.1 Accuracy: 27.9\n",
      "  Epoch [19/99], Batch [350/352], Train Acc: 34.3237 Loss: 1.8318\n",
      "  Validation Accuracy after Epoch 19: 35.2000\n",
      "  Cidar10.1 Accuracy: 28.55\n",
      "  Epoch [20/99], Batch [350/352], Train Acc: 35.2344 Loss: 1.8242\n",
      "  Validation Accuracy after Epoch 20: 34.7800\n",
      "  Cidar10.1 Accuracy: 28.5\n",
      "  Epoch [21/99], Batch [350/352], Train Acc: 34.7969 Loss: 1.8714\n",
      "  Validation Accuracy after Epoch 21: 36.3200\n",
      "  Cidar10.1 Accuracy: 28.55\n",
      "  Epoch [22/99], Batch [350/352], Train Acc: 35.3616 Loss: 1.8413\n",
      "  Validation Accuracy after Epoch 22: 34.2800\n",
      "  Cidar10.1 Accuracy: 28.35\n",
      "  Epoch [23/99], Batch [350/352], Train Acc: 35.0558 Loss: 1.9553\n",
      "  Validation Accuracy after Epoch 23: 36.9200\n",
      "  Cidar10.1 Accuracy: 28.5\n",
      "  Epoch [24/99], Batch [350/352], Train Acc: 34.9710 Loss: 1.8584\n",
      "  Validation Accuracy after Epoch 24: 35.5000\n",
      "  Cidar10.1 Accuracy: 29.2\n",
      "  Epoch [25/99], Batch [350/352], Train Acc: 35.5000 Loss: 1.8477\n",
      "  Validation Accuracy after Epoch 25: 35.8000\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [26/99], Batch [350/352], Train Acc: 35.1250 Loss: 1.8530\n",
      "  Validation Accuracy after Epoch 26: 35.9200\n",
      "  Cidar10.1 Accuracy: 28.5\n",
      "  Epoch [27/99], Batch [350/352], Train Acc: 35.0982 Loss: 1.8955\n",
      "  Validation Accuracy after Epoch 27: 35.5000\n",
      "  Cidar10.1 Accuracy: 28.5\n",
      "  Epoch [28/99], Batch [350/352], Train Acc: 35.2121 Loss: 1.8498\n",
      "  Validation Accuracy after Epoch 28: 35.1000\n",
      "  Cidar10.1 Accuracy: 28.35\n",
      "  Epoch [29/99], Batch [350/352], Train Acc: 35.4018 Loss: 1.9194\n",
      "  Validation Accuracy after Epoch 29: 35.9800\n",
      "  Cidar10.1 Accuracy: 28.85\n",
      "  Epoch [30/99], Batch [350/352], Train Acc: 35.3036 Loss: 1.7768\n",
      "  Validation Accuracy after Epoch 30: 35.6000\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [31/99], Batch [350/352], Train Acc: 35.3906 Loss: 1.8751\n",
      "  Validation Accuracy after Epoch 31: 35.6600\n",
      "  Cidar10.1 Accuracy: 28.75\n",
      "  Epoch [32/99], Batch [350/352], Train Acc: 35.5156 Loss: 1.9423\n",
      "  Validation Accuracy after Epoch 32: 36.2600\n",
      "  Cidar10.1 Accuracy: 29.0\n",
      "  Epoch [33/99], Batch [350/352], Train Acc: 35.7321 Loss: 1.8241\n",
      "  Validation Accuracy after Epoch 33: 36.1600\n",
      "  Cidar10.1 Accuracy: 28.6\n",
      "  Epoch [34/99], Batch [350/352], Train Acc: 35.4397 Loss: 1.9303\n",
      "  Validation Accuracy after Epoch 34: 36.0200\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [35/99], Batch [350/352], Train Acc: 35.3080 Loss: 1.7461\n",
      "  Validation Accuracy after Epoch 35: 35.8200\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [36/99], Batch [350/352], Train Acc: 35.2768 Loss: 1.9443\n",
      "  Validation Accuracy after Epoch 36: 35.8200\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [37/99], Batch [350/352], Train Acc: 35.5737 Loss: 1.8304\n",
      "  Validation Accuracy after Epoch 37: 35.8600\n",
      "  Cidar10.1 Accuracy: 28.35\n",
      "  Epoch [38/99], Batch [350/352], Train Acc: 35.6228 Loss: 1.8330\n",
      "  Validation Accuracy after Epoch 38: 35.6400\n",
      "  Cidar10.1 Accuracy: 28.65\n",
      "  Epoch [39/99], Batch [350/352], Train Acc: 35.2924 Loss: 1.7809\n",
      "  Validation Accuracy after Epoch 39: 35.5800\n",
      "  Cidar10.1 Accuracy: 28.35\n",
      "  Epoch [40/99], Batch [350/352], Train Acc: 35.5312 Loss: 1.8687\n",
      "  Validation Accuracy after Epoch 40: 36.0600\n",
      "  Cidar10.1 Accuracy: 28.9\n",
      "  Epoch [41/99], Batch [350/352], Train Acc: 35.1719 Loss: 1.8648\n",
      "  Validation Accuracy after Epoch 41: 35.9600\n",
      "  Cidar10.1 Accuracy: 29.05\n",
      "  Epoch [42/99], Batch [350/352], Train Acc: 35.6830 Loss: 1.8643\n",
      "  Validation Accuracy after Epoch 42: 36.3400\n",
      "  Cidar10.1 Accuracy: 28.55\n",
      "  Epoch [43/99], Batch [350/352], Train Acc: 35.5513 Loss: 1.8590\n",
      "  Validation Accuracy after Epoch 43: 35.7000\n",
      "  Cidar10.1 Accuracy: 28.95\n",
      "  Epoch [44/99], Batch [350/352], Train Acc: 35.4844 Loss: 1.9512\n",
      "  Validation Accuracy after Epoch 44: 35.8400\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [45/99], Batch [350/352], Train Acc: 35.5022 Loss: 1.9419\n",
      "  Validation Accuracy after Epoch 45: 35.6200\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [46/99], Batch [350/352], Train Acc: 35.5112 Loss: 1.9914\n",
      "  Validation Accuracy after Epoch 46: 35.2000\n",
      "  Cidar10.1 Accuracy: 28.65\n",
      "  Epoch [47/99], Batch [350/352], Train Acc: 35.5134 Loss: 1.9475\n",
      "  Validation Accuracy after Epoch 47: 34.7000\n",
      "  Cidar10.1 Accuracy: 29.0\n",
      "  Epoch [48/99], Batch [350/352], Train Acc: 35.6987 Loss: 1.8553\n",
      "  Validation Accuracy after Epoch 48: 35.9000\n",
      "  Cidar10.1 Accuracy: 28.85\n",
      "  Epoch [49/99], Batch [350/352], Train Acc: 35.2522 Loss: 1.8707\n",
      "  Validation Accuracy after Epoch 49: 36.0200\n",
      "  Cidar10.1 Accuracy: 28.2\n",
      "  Epoch [50/99], Batch [350/352], Train Acc: 35.1629 Loss: 1.8524\n",
      "  Validation Accuracy after Epoch 50: 36.3400\n",
      "  Cidar10.1 Accuracy: 28.3\n",
      "  Epoch [51/99], Batch [350/352], Train Acc: 35.3795 Loss: 1.8159\n",
      "  Validation Accuracy after Epoch 51: 36.2800\n",
      "  Cidar10.1 Accuracy: 28.2\n",
      "  Epoch [52/99], Batch [350/352], Train Acc: 35.5737 Loss: 1.8643\n",
      "  Validation Accuracy after Epoch 52: 35.4000\n",
      "  Cidar10.1 Accuracy: 28.95\n",
      "  Epoch [53/99], Batch [350/352], Train Acc: 35.2433 Loss: 1.8366\n",
      "  Validation Accuracy after Epoch 53: 35.5000\n",
      "  Cidar10.1 Accuracy: 28.5\n",
      "  Epoch [54/99], Batch [350/352], Train Acc: 35.1696 Loss: 1.8424\n",
      "  Validation Accuracy after Epoch 54: 35.3200\n",
      "  Cidar10.1 Accuracy: 28.6\n",
      "  Epoch [55/99], Batch [350/352], Train Acc: 35.4554 Loss: 1.9532\n",
      "  Validation Accuracy after Epoch 55: 35.0800\n",
      "  Cidar10.1 Accuracy: 28.75\n",
      "  Epoch [56/99], Batch [350/352], Train Acc: 35.2835 Loss: 1.8022\n",
      "  Validation Accuracy after Epoch 56: 36.4800\n",
      "  Cidar10.1 Accuracy: 28.65\n",
      "  Epoch [57/99], Batch [350/352], Train Acc: 35.2210 Loss: 1.7516\n",
      "  Validation Accuracy after Epoch 57: 35.7600\n",
      "  Cidar10.1 Accuracy: 28.45\n",
      "  Epoch [58/99], Batch [350/352], Train Acc: 35.4375 Loss: 1.8513\n",
      "  Validation Accuracy after Epoch 58: 35.6600\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [59/99], Batch [350/352], Train Acc: 35.4598 Loss: 1.7996\n",
      "  Validation Accuracy after Epoch 59: 34.9400\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [60/99], Batch [350/352], Train Acc: 35.2924 Loss: 1.8732\n",
      "  Validation Accuracy after Epoch 60: 36.5600\n",
      "  Cidar10.1 Accuracy: 28.45\n",
      "  Epoch [61/99], Batch [350/352], Train Acc: 35.3683 Loss: 1.7034\n",
      "  Validation Accuracy after Epoch 61: 36.1600\n",
      "  Cidar10.1 Accuracy: 29.0\n",
      "  Epoch [62/99], Batch [350/352], Train Acc: 35.5179 Loss: 1.9044\n",
      "  Validation Accuracy after Epoch 62: 35.5200\n",
      "  Cidar10.1 Accuracy: 29.25\n",
      "  Epoch [63/99], Batch [350/352], Train Acc: 35.2411 Loss: 1.9326\n",
      "  Validation Accuracy after Epoch 63: 36.6400\n",
      "  Cidar10.1 Accuracy: 28.65\n",
      "  Epoch [64/99], Batch [350/352], Train Acc: 35.1183 Loss: 1.8794\n",
      "  Validation Accuracy after Epoch 64: 35.8800\n",
      "  Cidar10.1 Accuracy: 28.6\n",
      "  Epoch [65/99], Batch [350/352], Train Acc: 35.4152 Loss: 1.8476\n",
      "  Validation Accuracy after Epoch 65: 34.9600\n",
      "  Cidar10.1 Accuracy: 28.95\n",
      "  Epoch [66/99], Batch [350/352], Train Acc: 35.2344 Loss: 1.8592\n",
      "  Validation Accuracy after Epoch 66: 36.1400\n",
      "  Cidar10.1 Accuracy: 28.65\n",
      "  Epoch [67/99], Batch [350/352], Train Acc: 35.4308 Loss: 1.8460\n",
      "  Validation Accuracy after Epoch 67: 36.2800\n",
      "  Cidar10.1 Accuracy: 27.95\n",
      "  Epoch [68/99], Batch [350/352], Train Acc: 35.2210 Loss: 1.8050\n",
      "  Validation Accuracy after Epoch 68: 35.8200\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [69/99], Batch [350/352], Train Acc: 35.1763 Loss: 1.8748\n",
      "  Validation Accuracy after Epoch 69: 36.1200\n",
      "  Cidar10.1 Accuracy: 28.9\n",
      "  Epoch [70/99], Batch [350/352], Train Acc: 35.3326 Loss: 1.8417\n",
      "  Validation Accuracy after Epoch 70: 36.3400\n",
      "  Cidar10.1 Accuracy: 28.5\n",
      "  Epoch [71/99], Batch [350/352], Train Acc: 35.2723 Loss: 1.8446\n",
      "  Validation Accuracy after Epoch 71: 35.7600\n",
      "  Cidar10.1 Accuracy: 28.2\n",
      "  Epoch [72/99], Batch [350/352], Train Acc: 35.4888 Loss: 1.9998\n",
      "  Validation Accuracy after Epoch 72: 36.7600\n",
      "  Cidar10.1 Accuracy: 28.75\n",
      "  Epoch [73/99], Batch [350/352], Train Acc: 35.3259 Loss: 1.8635\n",
      "  Validation Accuracy after Epoch 73: 36.1000\n",
      "  Cidar10.1 Accuracy: 28.65\n",
      "  Epoch [74/99], Batch [350/352], Train Acc: 35.5402 Loss: 1.8478\n",
      "  Validation Accuracy after Epoch 74: 35.9200\n",
      "  Cidar10.1 Accuracy: 28.5\n",
      "  Epoch [75/99], Batch [350/352], Train Acc: 34.9844 Loss: 1.8313\n",
      "  Validation Accuracy after Epoch 75: 35.7200\n",
      "  Cidar10.1 Accuracy: 28.6\n",
      "  Epoch [76/99], Batch [350/352], Train Acc: 35.2165 Loss: 1.8793\n",
      "  Validation Accuracy after Epoch 76: 35.8000\n",
      "  Cidar10.1 Accuracy: 28.3\n",
      "  Epoch [77/99], Batch [350/352], Train Acc: 35.5112 Loss: 1.8452\n",
      "  Validation Accuracy after Epoch 77: 35.5400\n",
      "  Cidar10.1 Accuracy: 28.9\n",
      "  Epoch [78/99], Batch [350/352], Train Acc: 35.5692 Loss: 1.8260\n",
      "  Validation Accuracy after Epoch 78: 36.1000\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [79/99], Batch [350/352], Train Acc: 35.4821 Loss: 1.7942\n",
      "  Validation Accuracy after Epoch 79: 37.0000\n",
      "  Cidar10.1 Accuracy: 29.2\n",
      "  Epoch [80/99], Batch [350/352], Train Acc: 35.3884 Loss: 1.9395\n",
      "  Validation Accuracy after Epoch 80: 35.6400\n",
      "  Cidar10.1 Accuracy: 29.15\n",
      "  Epoch [81/99], Batch [350/352], Train Acc: 35.4174 Loss: 1.8726\n",
      "  Validation Accuracy after Epoch 81: 36.3400\n",
      "  Cidar10.1 Accuracy: 29.15\n",
      "  Epoch [82/99], Batch [350/352], Train Acc: 35.7344 Loss: 1.9108\n",
      "  Validation Accuracy after Epoch 82: 35.7800\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [83/99], Batch [350/352], Train Acc: 35.3415 Loss: 1.9446\n",
      "  Validation Accuracy after Epoch 83: 35.9800\n",
      "  Cidar10.1 Accuracy: 28.6\n",
      "  Epoch [84/99], Batch [350/352], Train Acc: 35.3415 Loss: 1.6310\n",
      "  Validation Accuracy after Epoch 84: 36.3400\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [85/99], Batch [350/352], Train Acc: 35.6451 Loss: 1.8686\n",
      "  Validation Accuracy after Epoch 85: 35.8400\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [86/99], Batch [350/352], Train Acc: 35.4308 Loss: 1.9281\n",
      "  Validation Accuracy after Epoch 86: 35.2000\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [87/99], Batch [350/352], Train Acc: 35.4576 Loss: 1.6716\n",
      "  Validation Accuracy after Epoch 87: 35.8800\n",
      "  Cidar10.1 Accuracy: 28.55\n",
      "  Epoch [88/99], Batch [350/352], Train Acc: 35.3996 Loss: 1.7829\n",
      "  Validation Accuracy after Epoch 88: 36.1400\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [89/99], Batch [350/352], Train Acc: 35.2165 Loss: 1.8223\n",
      "  Validation Accuracy after Epoch 89: 35.2800\n",
      "  Cidar10.1 Accuracy: 28.0\n",
      "  Epoch [90/99], Batch [350/352], Train Acc: 35.7768 Loss: 1.8993\n",
      "  Validation Accuracy after Epoch 90: 36.2800\n",
      "  Cidar10.1 Accuracy: 28.8\n",
      "  Epoch [91/99], Batch [350/352], Train Acc: 35.2723 Loss: 1.8291\n",
      "  Validation Accuracy after Epoch 91: 36.1000\n",
      "  Cidar10.1 Accuracy: 28.9\n",
      "  Epoch [92/99], Batch [350/352], Train Acc: 35.5246 Loss: 1.8611\n",
      "  Validation Accuracy after Epoch 92: 36.7800\n",
      "  Cidar10.1 Accuracy: 29.15\n",
      "  Epoch [93/99], Batch [350/352], Train Acc: 35.2790 Loss: 1.9274\n",
      "  Validation Accuracy after Epoch 93: 36.9000\n",
      "  Cidar10.1 Accuracy: 28.65\n",
      "  Epoch [94/99], Batch [350/352], Train Acc: 35.3013 Loss: 1.8590\n",
      "  Validation Accuracy after Epoch 94: 36.1400\n",
      "  Cidar10.1 Accuracy: 28.55\n",
      "  Epoch [95/99], Batch [350/352], Train Acc: 35.2768 Loss: 1.8280\n",
      "  Validation Accuracy after Epoch 95: 36.1600\n",
      "  Cidar10.1 Accuracy: 28.7\n",
      "  Epoch [96/99], Batch [350/352], Train Acc: 35.3750 Loss: 1.9402\n",
      "  Validation Accuracy after Epoch 96: 35.3000\n",
      "  Cidar10.1 Accuracy: 28.6\n",
      "  Epoch [97/99], Batch [350/352], Train Acc: 35.3929 Loss: 1.9810\n",
      "  Validation Accuracy after Epoch 97: 35.3800\n",
      "  Cidar10.1 Accuracy: 29.15\n",
      "  Epoch [98/99], Batch [350/352], Train Acc: 35.4464 Loss: 1.8415\n",
      "  Validation Accuracy after Epoch 98: 35.6200\n",
      "  Cidar10.1 Accuracy: 28.9\n",
      "  Epoch [99/99], Batch [350/352], Train Acc: 35.5446 Loss: 1.8126\n",
      "  Validation Accuracy after Epoch 99: 35.5600\n",
      "  Cidar10.1 Accuracy: 29.15\n",
      "Trial 1 complete. Best Validation Accuracy: 37.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 03:16:02,770] Trial 1 finished with value: 37.0 and parameters: {'num_epochs': 99, 'model_type': 'efficientnet', 'batch_size': 128, 'optimizer_type': 'Adam', 'scheduler_type': 'ReduceLROnPlateau', 'beta1': 0.879263309837687, 'beta2': 0.9902483573125087, 'lr': 1.0489767423709725e-05, 'weight_decay': 6.32754805913792e-06, 'factor': 0.11188403904979145, 'patience': 6, 'threshold': 0.092594865117007}. Best is trial 0 with value: 77.5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=2\n",
      "num_epochs: 78\n",
      "model_type: base\n",
      "batch_size: 256\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.8554047923562503\n",
      "beta2: 0.9900537807605059\n",
      "lr: 0.0008874696628000282\n",
      "weight_decay: 1.6390033154606387e-05\n",
      "factor: 0.10502947244187953\n",
      "patience: 20\n",
      "threshold: 0.021875882097500743\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/78], Batch [170/176], Train Acc: 41.3649 Loss: 1.5172\n",
      "  Validation Accuracy after Epoch 1: 51.7600\n",
      "  Cidar10.1 Accuracy: 41.5\n",
      "  Epoch [2/78], Batch [170/176], Train Acc: 60.7973 Loss: 1.3195\n",
      "  Validation Accuracy after Epoch 2: 64.1800\n",
      "  Cidar10.1 Accuracy: 51.2\n",
      "  Epoch [3/78], Batch [170/176], Train Acc: 68.4903 Loss: 1.1378\n",
      "  Validation Accuracy after Epoch 3: 71.2400\n",
      "  Cidar10.1 Accuracy: 59.3\n",
      "  Epoch [4/78], Batch [170/176], Train Acc: 73.5547 Loss: 1.1219\n",
      "  Validation Accuracy after Epoch 4: 72.0200\n",
      "  Cidar10.1 Accuracy: 61.2\n",
      "  Epoch [5/78], Batch [170/176], Train Acc: 76.4062 Loss: 1.0623\n",
      "  Validation Accuracy after Epoch 5: 75.3200\n",
      "  Cidar10.1 Accuracy: 64.8\n",
      "  Epoch [6/78], Batch [170/176], Train Acc: 79.1797 Loss: 0.9343\n",
      "  Validation Accuracy after Epoch 6: 69.1800\n",
      "  Cidar10.1 Accuracy: 58.95\n",
      "  Epoch [7/78], Batch [170/176], Train Acc: 80.3975 Loss: 1.0794\n",
      "  Validation Accuracy after Epoch 7: 82.2000\n",
      "  Cidar10.1 Accuracy: 68.95\n",
      "  Epoch [8/78], Batch [170/176], Train Acc: 82.0221 Loss: 0.9476\n",
      "  Validation Accuracy after Epoch 8: 80.6200\n",
      "  Cidar10.1 Accuracy: 67.8\n",
      "  Epoch [9/78], Batch [170/176], Train Acc: 83.3364 Loss: 0.9001\n",
      "  Validation Accuracy after Epoch 9: 75.1800\n",
      "  Cidar10.1 Accuracy: 65.6\n",
      "  Epoch [10/78], Batch [170/176], Train Acc: 84.3543 Loss: 0.8979\n",
      "  Validation Accuracy after Epoch 10: 82.8400\n",
      "  Cidar10.1 Accuracy: 75.45\n",
      "  Epoch [11/78], Batch [170/176], Train Acc: 85.1126 Loss: 0.8829\n",
      "  Validation Accuracy after Epoch 11: 80.9200\n",
      "  Cidar10.1 Accuracy: 69.6\n",
      "  Epoch [12/78], Batch [170/176], Train Acc: 85.9536 Loss: 0.8192\n",
      "  Validation Accuracy after Epoch 12: 84.7000\n",
      "  Cidar10.1 Accuracy: 75.45\n",
      "  Epoch [13/78], Batch [170/176], Train Acc: 86.8222 Loss: 0.8684\n",
      "  Validation Accuracy after Epoch 13: 82.9200\n",
      "  Cidar10.1 Accuracy: 73.85\n",
      "  Epoch [14/78], Batch [170/176], Train Acc: 87.3943 Loss: 0.8466\n",
      "  Validation Accuracy after Epoch 14: 84.7400\n",
      "  Cidar10.1 Accuracy: 77.4\n",
      "  Epoch [15/78], Batch [170/176], Train Acc: 87.8929 Loss: 0.8458\n",
      "  Validation Accuracy after Epoch 15: 85.6800\n",
      "  Cidar10.1 Accuracy: 76.35\n",
      "  Epoch [16/78], Batch [170/176], Train Acc: 88.4605 Loss: 0.7907\n",
      "  Validation Accuracy after Epoch 16: 87.4200\n",
      "  Cidar10.1 Accuracy: 78.2\n",
      "  Epoch [17/78], Batch [170/176], Train Acc: 89.0165 Loss: 0.7513\n",
      "  Validation Accuracy after Epoch 17: 87.6600\n",
      "  Cidar10.1 Accuracy: 76.8\n",
      "  Epoch [18/78], Batch [170/176], Train Acc: 89.3199 Loss: 0.8122\n",
      "  Validation Accuracy after Epoch 18: 86.5400\n",
      "  Cidar10.1 Accuracy: 77.3\n",
      "  Epoch [19/78], Batch [170/176], Train Acc: 89.7610 Loss: 0.7400\n",
      "  Validation Accuracy after Epoch 19: 87.6600\n",
      "  Cidar10.1 Accuracy: 78.45\n",
      "  Epoch [20/78], Batch [170/176], Train Acc: 90.3401 Loss: 0.7801\n",
      "  Validation Accuracy after Epoch 20: 86.5600\n",
      "  Cidar10.1 Accuracy: 78.15\n",
      "  Epoch [21/78], Batch [170/176], Train Acc: 90.5032 Loss: 0.7314\n",
      "  Validation Accuracy after Epoch 21: 87.4600\n",
      "  Cidar10.1 Accuracy: 79.2\n",
      "  Epoch [22/78], Batch [170/176], Train Acc: 90.8984 Loss: 0.7034\n",
      "  Validation Accuracy after Epoch 22: 85.2200\n",
      "  Cidar10.1 Accuracy: 76.65\n",
      "  Epoch [23/78], Batch [170/176], Train Acc: 91.3006 Loss: 0.7635\n",
      "  Validation Accuracy after Epoch 23: 87.1200\n",
      "  Cidar10.1 Accuracy: 76.7\n",
      "  Epoch [24/78], Batch [170/176], Train Acc: 91.5809 Loss: 0.7281\n",
      "  Validation Accuracy after Epoch 24: 88.7400\n",
      "  Cidar10.1 Accuracy: 80.85\n",
      "  Epoch [25/78], Batch [170/176], Train Acc: 91.8635 Loss: 0.7582\n",
      "  Validation Accuracy after Epoch 25: 88.5200\n",
      "  Cidar10.1 Accuracy: 79.15\n",
      "  Epoch [26/78], Batch [170/176], Train Acc: 92.2932 Loss: 0.7459\n",
      "  Validation Accuracy after Epoch 26: 87.8800\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [27/78], Batch [170/176], Train Acc: 92.4816 Loss: 0.7194\n",
      "  Validation Accuracy after Epoch 27: 88.1800\n",
      "  Cidar10.1 Accuracy: 80.4\n",
      "  Epoch [28/78], Batch [170/176], Train Acc: 92.6953 Loss: 0.7046\n",
      "  Validation Accuracy after Epoch 28: 86.5800\n",
      "  Cidar10.1 Accuracy: 79.0\n",
      "  Epoch [29/78], Batch [170/176], Train Acc: 92.8860 Loss: 0.7288\n",
      "  Validation Accuracy after Epoch 29: 88.6800\n",
      "  Cidar10.1 Accuracy: 80.05\n",
      "  Epoch [30/78], Batch [170/176], Train Acc: 93.2537 Loss: 0.6546\n",
      "  Validation Accuracy after Epoch 30: 89.4200\n",
      "  Cidar10.1 Accuracy: 80.9\n",
      "  Epoch [31/78], Batch [170/176], Train Acc: 93.4926 Loss: 0.6853\n",
      "  Validation Accuracy after Epoch 31: 88.8400\n",
      "  Cidar10.1 Accuracy: 81.45\n",
      "  Epoch [32/78], Batch [170/176], Train Acc: 93.4122 Loss: 0.6727\n",
      "  Validation Accuracy after Epoch 32: 89.5600\n",
      "  Cidar10.1 Accuracy: 82.65\n",
      "  Epoch [33/78], Batch [170/176], Train Acc: 93.7201 Loss: 0.7061\n",
      "  Validation Accuracy after Epoch 33: 89.2600\n",
      "  Cidar10.1 Accuracy: 79.65\n",
      "  Epoch [34/78], Batch [170/176], Train Acc: 94.0234 Loss: 0.6364\n",
      "  Validation Accuracy after Epoch 34: 88.7800\n",
      "  Cidar10.1 Accuracy: 79.95\n",
      "  Epoch [35/78], Batch [170/176], Train Acc: 94.1889 Loss: 0.6902\n",
      "  Validation Accuracy after Epoch 35: 90.1600\n",
      "  Cidar10.1 Accuracy: 80.2\n",
      "  Epoch [36/78], Batch [170/176], Train Acc: 94.2073 Loss: 0.6607\n",
      "  Validation Accuracy after Epoch 36: 89.3400\n",
      "  Cidar10.1 Accuracy: 81.85\n",
      "  Epoch [37/78], Batch [170/176], Train Acc: 94.4256 Loss: 0.6730\n",
      "  Validation Accuracy after Epoch 37: 89.6800\n",
      "  Cidar10.1 Accuracy: 81.8\n",
      "  Epoch [38/78], Batch [170/176], Train Acc: 94.6255 Loss: 0.6443\n",
      "  Validation Accuracy after Epoch 38: 90.2800\n",
      "  Cidar10.1 Accuracy: 81.35\n",
      "  Epoch [39/78], Batch [170/176], Train Acc: 94.8254 Loss: 0.6620\n",
      "  Validation Accuracy after Epoch 39: 89.6000\n",
      "  Cidar10.1 Accuracy: 80.1\n",
      "  Epoch [40/78], Batch [170/176], Train Acc: 94.9357 Loss: 0.6635\n",
      "  Validation Accuracy after Epoch 40: 89.5200\n",
      "  Cidar10.1 Accuracy: 82.05\n",
      "  Epoch [41/78], Batch [170/176], Train Acc: 95.0437 Loss: 0.6516\n",
      "  Validation Accuracy after Epoch 41: 89.9200\n",
      "  Cidar10.1 Accuracy: 81.5\n",
      "  Epoch [42/78], Batch [170/176], Train Acc: 95.4090 Loss: 0.6813\n",
      "  Validation Accuracy after Epoch 42: 89.4200\n",
      "  Cidar10.1 Accuracy: 79.8\n",
      "  Epoch [43/78], Batch [170/176], Train Acc: 95.4963 Loss: 0.5929\n",
      "  Validation Accuracy after Epoch 43: 90.4800\n",
      "  Cidar10.1 Accuracy: 80.4\n",
      "  Epoch [44/78], Batch [170/176], Train Acc: 95.4665 Loss: 0.6306\n",
      "  Validation Accuracy after Epoch 44: 89.7200\n",
      "  Cidar10.1 Accuracy: 80.8\n",
      "  Epoch [45/78], Batch [170/176], Train Acc: 95.5767 Loss: 0.6723\n",
      "  Validation Accuracy after Epoch 45: 89.5000\n",
      "  Cidar10.1 Accuracy: 82.6\n",
      "  Epoch [46/78], Batch [170/176], Train Acc: 95.6066 Loss: 0.6255\n",
      "  Validation Accuracy after Epoch 46: 90.5200\n",
      "  Cidar10.1 Accuracy: 83.2\n",
      "  Epoch [47/78], Batch [170/176], Train Acc: 95.7560 Loss: 0.6324\n",
      "  Validation Accuracy after Epoch 47: 90.3200\n",
      "  Cidar10.1 Accuracy: 81.15\n",
      "  Epoch [48/78], Batch [170/176], Train Acc: 95.7468 Loss: 0.6241\n",
      "  Validation Accuracy after Epoch 48: 88.1000\n",
      "  Cidar10.1 Accuracy: 80.75\n",
      "  Epoch [49/78], Batch [170/176], Train Acc: 96.0340 Loss: 0.6652\n",
      "  Validation Accuracy after Epoch 49: 89.8200\n",
      "  Cidar10.1 Accuracy: 81.35\n",
      "  Epoch [50/78], Batch [170/176], Train Acc: 96.1719 Loss: 0.6358\n",
      "  Validation Accuracy after Epoch 50: 90.2400\n",
      "  Cidar10.1 Accuracy: 81.2\n",
      "  Epoch [51/78], Batch [170/176], Train Acc: 96.1627 Loss: 0.6709\n",
      "  Validation Accuracy after Epoch 51: 90.5800\n",
      "  Cidar10.1 Accuracy: 82.75\n",
      "  Epoch [52/78], Batch [170/176], Train Acc: 96.1811 Loss: 0.6541\n",
      "  Validation Accuracy after Epoch 52: 90.9200\n",
      "  Cidar10.1 Accuracy: 81.75\n",
      "  Epoch [53/78], Batch [170/176], Train Acc: 96.1236 Loss: 0.6391\n",
      "  Validation Accuracy after Epoch 53: 90.1400\n",
      "  Cidar10.1 Accuracy: 82.2\n",
      "  Epoch [54/78], Batch [170/176], Train Acc: 96.5028 Loss: 0.6091\n",
      "  Validation Accuracy after Epoch 54: 90.3400\n",
      "  Cidar10.1 Accuracy: 81.7\n",
      "  Epoch [55/78], Batch [170/176], Train Acc: 96.3350 Loss: 0.5931\n",
      "  Validation Accuracy after Epoch 55: 90.7000\n",
      "  Cidar10.1 Accuracy: 82.4\n",
      "  Epoch [56/78], Batch [170/176], Train Acc: 96.5005 Loss: 0.5966\n",
      "  Validation Accuracy after Epoch 56: 90.5400\n",
      "  Cidar10.1 Accuracy: 83.4\n",
      "  Epoch [57/78], Batch [170/176], Train Acc: 96.5051 Loss: 0.6161\n",
      "  Validation Accuracy after Epoch 57: 90.5600\n",
      "  Cidar10.1 Accuracy: 82.15\n",
      "  Epoch [58/78], Batch [170/176], Train Acc: 96.5074 Loss: 0.6025\n",
      "  Validation Accuracy after Epoch 58: 90.7600\n",
      "  Cidar10.1 Accuracy: 81.2\n",
      "  Epoch [59/78], Batch [170/176], Train Acc: 96.7394 Loss: 0.6020\n",
      "  Validation Accuracy after Epoch 59: 90.8200\n",
      "  Cidar10.1 Accuracy: 81.95\n",
      "  Epoch [60/78], Batch [170/176], Train Acc: 96.6498 Loss: 0.6338\n",
      "  Validation Accuracy after Epoch 60: 89.6400\n",
      "  Cidar10.1 Accuracy: 80.05\n",
      "  Epoch [61/78], Batch [170/176], Train Acc: 96.8107 Loss: 0.6037\n",
      "  Validation Accuracy after Epoch 61: 90.2600\n",
      "  Cidar10.1 Accuracy: 81.8\n",
      "  Epoch [62/78], Batch [170/176], Train Acc: 96.8130 Loss: 0.6669\n",
      "  Validation Accuracy after Epoch 62: 90.3200\n",
      "  Cidar10.1 Accuracy: 82.25\n",
      "  Epoch [63/78], Batch [170/176], Train Acc: 96.7348 Loss: 0.5861\n",
      "  Validation Accuracy after Epoch 63: 89.6600\n",
      "  Cidar10.1 Accuracy: 82.4\n",
      "  Epoch [64/78], Batch [170/176], Train Acc: 96.9233 Loss: 0.6066\n",
      "  Validation Accuracy after Epoch 64: 90.7400\n",
      "  Cidar10.1 Accuracy: 82.85\n",
      "  Epoch [65/78], Batch [170/176], Train Acc: 97.1415 Loss: 0.6061\n",
      "  Validation Accuracy after Epoch 65: 90.1200\n",
      "  Cidar10.1 Accuracy: 82.65\n",
      "  Epoch [66/78], Batch [170/176], Train Acc: 97.1255 Loss: 0.6148\n",
      "  Validation Accuracy after Epoch 66: 91.1000\n",
      "  Cidar10.1 Accuracy: 82.95\n",
      "  Epoch [67/78], Batch [170/176], Train Acc: 97.1944 Loss: 0.5831\n",
      "  Validation Accuracy after Epoch 67: 90.8200\n",
      "  Cidar10.1 Accuracy: 82.95\n",
      "  Epoch [68/78], Batch [170/176], Train Acc: 97.0956 Loss: 0.5938\n",
      "  Validation Accuracy after Epoch 68: 90.9600\n",
      "  Cidar10.1 Accuracy: 82.2\n",
      "  Epoch [69/78], Batch [170/176], Train Acc: 97.1599 Loss: 0.6400\n",
      "  Validation Accuracy after Epoch 69: 90.1800\n",
      "  Cidar10.1 Accuracy: 83.15\n",
      "  Epoch [70/78], Batch [170/176], Train Acc: 97.2151 Loss: 0.6026\n",
      "  Validation Accuracy after Epoch 70: 90.8600\n",
      "  Cidar10.1 Accuracy: 82.4\n",
      "  Epoch [71/78], Batch [170/176], Train Acc: 97.2197 Loss: 0.5902\n",
      "  Validation Accuracy after Epoch 71: 90.3800\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [72/78], Batch [170/176], Train Acc: 97.1025 Loss: 0.6095\n",
      "  Validation Accuracy after Epoch 72: 90.8800\n",
      "  Cidar10.1 Accuracy: 81.35\n",
      "  Epoch [73/78], Batch [170/176], Train Acc: 97.1484 Loss: 0.5748\n",
      "  Validation Accuracy after Epoch 73: 90.5400\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [74/78], Batch [170/176], Train Acc: 98.2996 Loss: 0.5602\n",
      "  Validation Accuracy after Epoch 74: 92.2800\n",
      "  Cidar10.1 Accuracy: 84.45\n",
      "  Epoch [75/78], Batch [170/176], Train Acc: 98.6857 Loss: 0.5753\n",
      "  Validation Accuracy after Epoch 75: 91.9600\n",
      "  Cidar10.1 Accuracy: 84.65\n",
      "  Epoch [76/78], Batch [170/176], Train Acc: 98.8534 Loss: 0.5543\n",
      "  Validation Accuracy after Epoch 76: 92.3200\n",
      "  Cidar10.1 Accuracy: 84.75\n",
      "  Epoch [77/78], Batch [170/176], Train Acc: 98.9407 Loss: 0.5387\n",
      "  Validation Accuracy after Epoch 77: 92.5200\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [78/78], Batch [170/176], Train Acc: 99.0119 Loss: 0.5535\n",
      "  Validation Accuracy after Epoch 78: 92.2800\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "Trial 2 complete. Best Validation Accuracy: 92.5200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 03:28:18,313] Trial 2 finished with value: 92.52 and parameters: {'num_epochs': 78, 'model_type': 'base', 'batch_size': 256, 'optimizer_type': 'Adam', 'scheduler_type': 'ReduceLROnPlateau', 'beta1': 0.8554047923562503, 'beta2': 0.9900537807605059, 'lr': 0.0008874696628000282, 'weight_decay': 1.6390033154606387e-05, 'factor': 0.10502947244187953, 'patience': 20, 'threshold': 0.021875882097500743}. Best is trial 2 with value: 92.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=3\n",
      "num_epochs: 87\n",
      "model_type: smallresnet\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9467467502610648\n",
      "beta2: 0.9986599029303749\n",
      "lr: 0.0005757323449046855\n",
      "weight_decay: 0.008336338695006893\n",
      "max_lr: 0.0019789098923762923\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/87], Batch [80/88], Train Acc: 22.1118 Loss: 1.9481\n",
      "  Validation Accuracy after Epoch 1: 33.1800\n",
      "  Cidar10.1 Accuracy: 28.45\n",
      "  Epoch [2/87], Batch [80/88], Train Acc: 35.7568 Loss: 1.7400\n",
      "  Validation Accuracy after Epoch 2: 41.7000\n",
      "  Cidar10.1 Accuracy: 33.45\n",
      "  Epoch [3/87], Batch [80/88], Train Acc: 42.9541 Loss: 1.7105\n",
      "  Validation Accuracy after Epoch 3: 45.1200\n",
      "  Cidar10.1 Accuracy: 37.65\n",
      "  Epoch [4/87], Batch [80/88], Train Acc: 49.0894 Loss: 1.5621\n",
      "  Validation Accuracy after Epoch 4: 50.6400\n",
      "  Cidar10.1 Accuracy: 41.35\n",
      "  Epoch [5/87], Batch [80/88], Train Acc: 53.8623 Loss: 1.4621\n",
      "  Validation Accuracy after Epoch 5: 55.8400\n",
      "  Cidar10.1 Accuracy: 44.65\n",
      "  Epoch [6/87], Batch [80/88], Train Acc: 58.8525 Loss: 1.3202\n",
      "  Validation Accuracy after Epoch 6: 57.2200\n",
      "  Cidar10.1 Accuracy: 47.85\n",
      "  Epoch [7/87], Batch [80/88], Train Acc: 63.5352 Loss: 1.2290\n",
      "  Validation Accuracy after Epoch 7: 61.0800\n",
      "  Cidar10.1 Accuracy: 47.6\n",
      "  Epoch [8/87], Batch [80/88], Train Acc: 66.3501 Loss: 1.1532\n",
      "  Validation Accuracy after Epoch 8: 62.0800\n",
      "  Cidar10.1 Accuracy: 50.65\n",
      "  Epoch [9/87], Batch [80/88], Train Acc: 70.3882 Loss: 1.1704\n",
      "  Validation Accuracy after Epoch 9: 64.8000\n",
      "  Cidar10.1 Accuracy: 54.15\n",
      "  Epoch [10/87], Batch [80/88], Train Acc: 73.4912 Loss: 1.0969\n",
      "  Validation Accuracy after Epoch 10: 71.1600\n",
      "  Cidar10.1 Accuracy: 59.85\n",
      "  Epoch [11/87], Batch [80/88], Train Acc: 75.5664 Loss: 1.0325\n",
      "  Validation Accuracy after Epoch 11: 72.3800\n",
      "  Cidar10.1 Accuracy: 60.45\n",
      "  Epoch [12/87], Batch [80/88], Train Acc: 77.0679 Loss: 1.0699\n",
      "  Validation Accuracy after Epoch 12: 67.4000\n",
      "  Cidar10.1 Accuracy: 55.35\n",
      "  Epoch [13/87], Batch [80/88], Train Acc: 78.2178 Loss: 0.9734\n",
      "  Validation Accuracy after Epoch 13: 70.5200\n",
      "  Cidar10.1 Accuracy: 57.65\n",
      "  Epoch [14/87], Batch [80/88], Train Acc: 80.1099 Loss: 0.9241\n",
      "  Validation Accuracy after Epoch 14: 76.2200\n",
      "  Cidar10.1 Accuracy: 64.85\n",
      "  Epoch [15/87], Batch [80/88], Train Acc: 81.0596 Loss: 0.9124\n",
      "  Validation Accuracy after Epoch 15: 77.8200\n",
      "  Cidar10.1 Accuracy: 65.0\n",
      "  Epoch [16/87], Batch [80/88], Train Acc: 82.1533 Loss: 0.9484\n",
      "  Validation Accuracy after Epoch 16: 76.2000\n",
      "  Cidar10.1 Accuracy: 67.4\n",
      "  Epoch [17/87], Batch [80/88], Train Acc: 82.9883 Loss: 0.8981\n",
      "  Validation Accuracy after Epoch 17: 73.1200\n",
      "  Cidar10.1 Accuracy: 61.45\n",
      "  Epoch [18/87], Batch [80/88], Train Acc: 83.6890 Loss: 0.8976\n",
      "  Validation Accuracy after Epoch 18: 75.0600\n",
      "  Cidar10.1 Accuracy: 67.2\n",
      "  Epoch [19/87], Batch [80/88], Train Acc: 84.7241 Loss: 0.8701\n",
      "  Validation Accuracy after Epoch 19: 81.3400\n",
      "  Cidar10.1 Accuracy: 71.1\n",
      "  Epoch [20/87], Batch [80/88], Train Acc: 85.2148 Loss: 0.8818\n",
      "  Validation Accuracy after Epoch 20: 77.7400\n",
      "  Cidar10.1 Accuracy: 69.95\n",
      "  Epoch [21/87], Batch [80/88], Train Acc: 85.7788 Loss: 0.8384\n",
      "  Validation Accuracy after Epoch 21: 80.3000\n",
      "  Cidar10.1 Accuracy: 70.0\n",
      "  Epoch [22/87], Batch [80/88], Train Acc: 86.4331 Loss: 0.7801\n",
      "  Validation Accuracy after Epoch 22: 79.3400\n",
      "  Cidar10.1 Accuracy: 67.6\n",
      "  Epoch [23/87], Batch [80/88], Train Acc: 86.8335 Loss: 0.7878\n",
      "  Validation Accuracy after Epoch 23: 79.1400\n",
      "  Cidar10.1 Accuracy: 66.75\n",
      "  Epoch [24/87], Batch [80/88], Train Acc: 87.3828 Loss: 0.8227\n",
      "  Validation Accuracy after Epoch 24: 80.4000\n",
      "  Cidar10.1 Accuracy: 69.75\n",
      "  Epoch [25/87], Batch [80/88], Train Acc: 87.9810 Loss: 0.8171\n",
      "  Validation Accuracy after Epoch 25: 83.2000\n",
      "  Cidar10.1 Accuracy: 71.6\n",
      "  Epoch [26/87], Batch [80/88], Train Acc: 88.6230 Loss: 0.7385\n",
      "  Validation Accuracy after Epoch 26: 83.3000\n",
      "  Cidar10.1 Accuracy: 73.45\n",
      "  Epoch [27/87], Batch [80/88], Train Acc: 88.8770 Loss: 0.7435\n",
      "  Validation Accuracy after Epoch 27: 85.1400\n",
      "  Cidar10.1 Accuracy: 75.25\n",
      "  Epoch [28/87], Batch [80/88], Train Acc: 89.5557 Loss: 0.7193\n",
      "  Validation Accuracy after Epoch 28: 78.5200\n",
      "  Cidar10.1 Accuracy: 69.4\n",
      "  Epoch [29/87], Batch [80/88], Train Acc: 89.9243 Loss: 0.7824\n",
      "  Validation Accuracy after Epoch 29: 80.5800\n",
      "  Cidar10.1 Accuracy: 71.05\n",
      "  Epoch [30/87], Batch [80/88], Train Acc: 90.4077 Loss: 0.7599\n",
      "  Validation Accuracy after Epoch 30: 82.8600\n",
      "  Cidar10.1 Accuracy: 71.25\n",
      "  Epoch [31/87], Batch [80/88], Train Acc: 90.5835 Loss: 0.7114\n",
      "  Validation Accuracy after Epoch 31: 85.6400\n",
      "  Cidar10.1 Accuracy: 74.8\n",
      "  Epoch [32/87], Batch [80/88], Train Acc: 91.0059 Loss: 0.6981\n",
      "  Validation Accuracy after Epoch 32: 83.4200\n",
      "  Cidar10.1 Accuracy: 70.45\n",
      "  Epoch [33/87], Batch [80/88], Train Acc: 91.5601 Loss: 0.7482\n",
      "  Validation Accuracy after Epoch 33: 83.8400\n",
      "  Cidar10.1 Accuracy: 72.85\n",
      "  Epoch [34/87], Batch [80/88], Train Acc: 91.7236 Loss: 0.6889\n",
      "  Validation Accuracy after Epoch 34: 84.6000\n",
      "  Cidar10.1 Accuracy: 76.0\n",
      "  Epoch [35/87], Batch [80/88], Train Acc: 91.7358 Loss: 0.7045\n",
      "  Validation Accuracy after Epoch 35: 86.0000\n",
      "  Cidar10.1 Accuracy: 75.1\n",
      "  Epoch [36/87], Batch [80/88], Train Acc: 92.1289 Loss: 0.7119\n",
      "  Validation Accuracy after Epoch 36: 84.7600\n",
      "  Cidar10.1 Accuracy: 74.6\n",
      "  Epoch [37/87], Batch [80/88], Train Acc: 92.6855 Loss: 0.7033\n",
      "  Validation Accuracy after Epoch 37: 86.2400\n",
      "  Cidar10.1 Accuracy: 76.4\n",
      "  Epoch [38/87], Batch [80/88], Train Acc: 92.7930 Loss: 0.6663\n",
      "  Validation Accuracy after Epoch 38: 87.0600\n",
      "  Cidar10.1 Accuracy: 74.95\n",
      "  Epoch [39/87], Batch [80/88], Train Acc: 93.0127 Loss: 0.6936\n",
      "  Validation Accuracy after Epoch 39: 85.7400\n",
      "  Cidar10.1 Accuracy: 76.35\n",
      "  Epoch [40/87], Batch [80/88], Train Acc: 93.4668 Loss: 0.6599\n",
      "  Validation Accuracy after Epoch 40: 86.1200\n",
      "  Cidar10.1 Accuracy: 77.55\n",
      "  Epoch [41/87], Batch [80/88], Train Acc: 93.7427 Loss: 0.6129\n",
      "  Validation Accuracy after Epoch 41: 86.1600\n",
      "  Cidar10.1 Accuracy: 77.0\n",
      "  Epoch [42/87], Batch [80/88], Train Acc: 94.0283 Loss: 0.6303\n",
      "  Validation Accuracy after Epoch 42: 85.8000\n",
      "  Cidar10.1 Accuracy: 75.85\n",
      "  Epoch [43/87], Batch [80/88], Train Acc: 94.0771 Loss: 0.6369\n",
      "  Validation Accuracy after Epoch 43: 87.7400\n",
      "  Cidar10.1 Accuracy: 77.3\n",
      "  Epoch [44/87], Batch [80/88], Train Acc: 94.2749 Loss: 0.6219\n",
      "  Validation Accuracy after Epoch 44: 87.6600\n",
      "  Cidar10.1 Accuracy: 78.2\n",
      "  Epoch [45/87], Batch [80/88], Train Acc: 94.5142 Loss: 0.6522\n",
      "  Validation Accuracy after Epoch 45: 88.0200\n",
      "  Cidar10.1 Accuracy: 78.55\n",
      "  Epoch [46/87], Batch [80/88], Train Acc: 94.8486 Loss: 0.6358\n",
      "  Validation Accuracy after Epoch 46: 88.1800\n",
      "  Cidar10.1 Accuracy: 79.4\n",
      "  Epoch [47/87], Batch [80/88], Train Acc: 95.1489 Loss: 0.6225\n",
      "  Validation Accuracy after Epoch 47: 87.3200\n",
      "  Cidar10.1 Accuracy: 76.05\n",
      "  Epoch [48/87], Batch [80/88], Train Acc: 95.3735 Loss: 0.6102\n",
      "  Validation Accuracy after Epoch 48: 87.5000\n",
      "  Cidar10.1 Accuracy: 78.4\n",
      "  Epoch [49/87], Batch [80/88], Train Acc: 95.6641 Loss: 0.6109\n",
      "  Validation Accuracy after Epoch 49: 88.6400\n",
      "  Cidar10.1 Accuracy: 79.1\n",
      "  Epoch [50/87], Batch [80/88], Train Acc: 95.4028 Loss: 0.6397\n",
      "  Validation Accuracy after Epoch 50: 88.1800\n",
      "  Cidar10.1 Accuracy: 80.45\n",
      "  Epoch [51/87], Batch [80/88], Train Acc: 95.9375 Loss: 0.5878\n",
      "  Validation Accuracy after Epoch 51: 87.8600\n",
      "  Cidar10.1 Accuracy: 78.95\n",
      "  Epoch [52/87], Batch [80/88], Train Acc: 96.2012 Loss: 0.5915\n",
      "  Validation Accuracy after Epoch 52: 88.3200\n",
      "  Cidar10.1 Accuracy: 78.05\n",
      "  Epoch [53/87], Batch [80/88], Train Acc: 96.5015 Loss: 0.5681\n",
      "  Validation Accuracy after Epoch 53: 88.7600\n",
      "  Cidar10.1 Accuracy: 81.1\n",
      "  Epoch [54/87], Batch [80/88], Train Acc: 96.5283 Loss: 0.6203\n",
      "  Validation Accuracy after Epoch 54: 88.6400\n",
      "  Cidar10.1 Accuracy: 79.9\n",
      "  Epoch [55/87], Batch [80/88], Train Acc: 96.8042 Loss: 0.5809\n",
      "  Validation Accuracy after Epoch 55: 89.4600\n",
      "  Cidar10.1 Accuracy: 81.8\n",
      "  Epoch [56/87], Batch [80/88], Train Acc: 97.0044 Loss: 0.5705\n",
      "  Validation Accuracy after Epoch 56: 89.2000\n",
      "  Cidar10.1 Accuracy: 81.75\n",
      "  Epoch [57/87], Batch [80/88], Train Acc: 97.2021 Loss: 0.5509\n",
      "  Validation Accuracy after Epoch 57: 87.7800\n",
      "  Cidar10.1 Accuracy: 77.4\n",
      "  Epoch [58/87], Batch [80/88], Train Acc: 97.4585 Loss: 0.5592\n",
      "  Validation Accuracy after Epoch 58: 88.8400\n",
      "  Cidar10.1 Accuracy: 80.65\n",
      "  Epoch [59/87], Batch [80/88], Train Acc: 97.6416 Loss: 0.5660\n",
      "  Validation Accuracy after Epoch 59: 90.0800\n",
      "  Cidar10.1 Accuracy: 82.0\n",
      "  Epoch [60/87], Batch [80/88], Train Acc: 97.6782 Loss: 0.5747\n",
      "  Validation Accuracy after Epoch 60: 89.1800\n",
      "  Cidar10.1 Accuracy: 80.8\n",
      "  Epoch [61/87], Batch [80/88], Train Acc: 97.8882 Loss: 0.5582\n",
      "  Validation Accuracy after Epoch 61: 89.6000\n",
      "  Cidar10.1 Accuracy: 81.65\n",
      "  Epoch [62/87], Batch [80/88], Train Acc: 98.1055 Loss: 0.5796\n",
      "  Validation Accuracy after Epoch 62: 90.2000\n",
      "  Cidar10.1 Accuracy: 82.9\n",
      "  Epoch [63/87], Batch [80/88], Train Acc: 98.2373 Loss: 0.5615\n",
      "  Validation Accuracy after Epoch 63: 90.1200\n",
      "  Cidar10.1 Accuracy: 81.2\n",
      "  Epoch [64/87], Batch [80/88], Train Acc: 98.4302 Loss: 0.5216\n",
      "  Validation Accuracy after Epoch 64: 90.0200\n",
      "  Cidar10.1 Accuracy: 81.1\n",
      "  Epoch [65/87], Batch [80/88], Train Acc: 98.6426 Loss: 0.5329\n",
      "  Validation Accuracy after Epoch 65: 90.4000\n",
      "  Cidar10.1 Accuracy: 81.9\n",
      "  Epoch [66/87], Batch [80/88], Train Acc: 98.7451 Loss: 0.5406\n",
      "  Validation Accuracy after Epoch 66: 90.4200\n",
      "  Cidar10.1 Accuracy: 83.3\n",
      "  Epoch [67/87], Batch [80/88], Train Acc: 98.7769 Loss: 0.5381\n",
      "  Validation Accuracy after Epoch 67: 90.9200\n",
      "  Cidar10.1 Accuracy: 83.1\n",
      "  Epoch [68/87], Batch [80/88], Train Acc: 98.8867 Loss: 0.5199\n",
      "  Validation Accuracy after Epoch 68: 90.6800\n",
      "  Cidar10.1 Accuracy: 83.35\n",
      "  Epoch [69/87], Batch [80/88], Train Acc: 99.0698 Loss: 0.5361\n",
      "  Validation Accuracy after Epoch 69: 91.3000\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [70/87], Batch [80/88], Train Acc: 99.1113 Loss: 0.5230\n",
      "  Validation Accuracy after Epoch 70: 90.9400\n",
      "  Cidar10.1 Accuracy: 83.05\n",
      "  Epoch [71/87], Batch [80/88], Train Acc: 99.2505 Loss: 0.5240\n",
      "  Validation Accuracy after Epoch 71: 91.0200\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [72/87], Batch [80/88], Train Acc: 99.2896 Loss: 0.5196\n",
      "  Validation Accuracy after Epoch 72: 90.8000\n",
      "  Cidar10.1 Accuracy: 82.6\n",
      "  Epoch [73/87], Batch [80/88], Train Acc: 99.3823 Loss: 0.5171\n",
      "  Validation Accuracy after Epoch 73: 91.8000\n",
      "  Cidar10.1 Accuracy: 82.75\n",
      "  Epoch [74/87], Batch [80/88], Train Acc: 99.4507 Loss: 0.5176\n",
      "  Validation Accuracy after Epoch 74: 91.1600\n",
      "  Cidar10.1 Accuracy: 82.75\n",
      "  Epoch [75/87], Batch [80/88], Train Acc: 99.4678 Loss: 0.5227\n",
      "  Validation Accuracy after Epoch 75: 91.2800\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [76/87], Batch [80/88], Train Acc: 99.5386 Loss: 0.5202\n",
      "  Validation Accuracy after Epoch 76: 90.8800\n",
      "  Cidar10.1 Accuracy: 83.25\n",
      "  Epoch [77/87], Batch [80/88], Train Acc: 99.6680 Loss: 0.5157\n",
      "  Validation Accuracy after Epoch 77: 91.4000\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [78/87], Batch [80/88], Train Acc: 99.6558 Loss: 0.5135\n",
      "  Validation Accuracy after Epoch 78: 91.2400\n",
      "  Cidar10.1 Accuracy: 83.05\n",
      "  Epoch [79/87], Batch [80/88], Train Acc: 99.6484 Loss: 0.5131\n",
      "  Validation Accuracy after Epoch 79: 91.3200\n",
      "  Cidar10.1 Accuracy: 83.6\n",
      "  Epoch [80/87], Batch [80/88], Train Acc: 99.6875 Loss: 0.5125\n",
      "  Validation Accuracy after Epoch 80: 91.2400\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [81/87], Batch [80/88], Train Acc: 99.7046 Loss: 0.5100\n",
      "  Validation Accuracy after Epoch 81: 91.3400\n",
      "  Cidar10.1 Accuracy: 83.35\n",
      "  Epoch [82/87], Batch [80/88], Train Acc: 99.6680 Loss: 0.5075\n",
      "  Validation Accuracy after Epoch 82: 91.6200\n",
      "  Cidar10.1 Accuracy: 83.85\n",
      "  Epoch [83/87], Batch [80/88], Train Acc: 99.6851 Loss: 0.5162\n",
      "  Validation Accuracy after Epoch 83: 91.4200\n",
      "  Cidar10.1 Accuracy: 83.75\n",
      "  Epoch [84/87], Batch [80/88], Train Acc: 99.7144 Loss: 0.5105\n",
      "  Validation Accuracy after Epoch 84: 91.8400\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [85/87], Batch [80/88], Train Acc: 99.6948 Loss: 0.5153\n",
      "  Validation Accuracy after Epoch 85: 91.4600\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [86/87], Batch [80/88], Train Acc: 99.7168 Loss: 0.5185\n",
      "  Validation Accuracy after Epoch 86: 91.8400\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [87/87], Batch [80/88], Train Acc: 99.7485 Loss: 0.5161\n",
      "  Validation Accuracy after Epoch 87: 91.4000\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "Trial 3 complete. Best Validation Accuracy: 91.8400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 03:42:40,992] Trial 3 finished with value: 91.84 and parameters: {'num_epochs': 87, 'model_type': 'smallresnet', 'batch_size': 512, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.9467467502610648, 'beta2': 0.9986599029303749, 'lr': 0.0005757323449046855, 'weight_decay': 0.008336338695006893, 'max_lr': 0.0019789098923762923}. Best is trial 2 with value: 92.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=4\n",
      "num_epochs: 121\n",
      "model_type: efficientnet\n",
      "batch_size: 64\n",
      "optimizer_type: SGD\n",
      "scheduler_type: CosineAnnealingLR\n",
      "lr: 0.08528869231926088\n",
      "momentum: 0.8889096409901536\n",
      "weight_decay: 0.00016615937852276983\n",
      "eta_min: 0.00019452924876717267\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/121], Batch [700/704], Train Acc: 24.6094 Loss: 1.8851\n",
      "  Validation Accuracy after Epoch 1: 26.7800\n",
      "  Cidar10.1 Accuracy: 22.35\n",
      "  Epoch [2/121], Batch [700/704], Train Acc: 38.3326 Loss: 1.6546\n",
      "  Validation Accuracy after Epoch 2: 41.8400\n",
      "  Cidar10.1 Accuracy: 32.1\n",
      "  Epoch [3/121], Batch [700/704], Train Acc: 48.1161 Loss: 1.5427\n",
      "  Validation Accuracy after Epoch 3: 48.0200\n",
      "  Cidar10.1 Accuracy: 38.95\n",
      "  Epoch [4/121], Batch [700/704], Train Acc: 54.5647 Loss: 1.2488\n",
      "  Validation Accuracy after Epoch 4: 60.0800\n",
      "  Cidar10.1 Accuracy: 49.3\n",
      "  Epoch [5/121], Batch [700/704], Train Acc: 59.8862 Loss: 1.4566\n",
      "  Validation Accuracy after Epoch 5: 64.2000\n",
      "  Cidar10.1 Accuracy: 53.3\n",
      "  Epoch [6/121], Batch [700/704], Train Acc: 63.1786 Loss: 1.2574\n",
      "  Validation Accuracy after Epoch 6: 63.2600\n",
      "  Cidar10.1 Accuracy: 52.2\n",
      "  Epoch [7/121], Batch [700/704], Train Acc: 65.1138 Loss: 1.4590\n",
      "  Validation Accuracy after Epoch 7: 67.6400\n",
      "  Cidar10.1 Accuracy: 55.95\n",
      "  Epoch [8/121], Batch [700/704], Train Acc: 66.2679 Loss: 1.0814\n",
      "  Validation Accuracy after Epoch 8: 65.3000\n",
      "  Cidar10.1 Accuracy: 54.9\n",
      "  Epoch [9/121], Batch [700/704], Train Acc: 69.6518 Loss: 1.1867\n",
      "  Validation Accuracy after Epoch 9: 69.7200\n",
      "  Cidar10.1 Accuracy: 56.0\n",
      "  Epoch [10/121], Batch [700/704], Train Acc: 69.7701 Loss: 1.2760\n",
      "  Validation Accuracy after Epoch 10: 67.5400\n",
      "  Cidar10.1 Accuracy: 55.9\n",
      "  Epoch [11/121], Batch [700/704], Train Acc: 72.7344 Loss: 1.2830\n",
      "  Validation Accuracy after Epoch 11: 66.2000\n",
      "  Cidar10.1 Accuracy: 57.75\n",
      "  Epoch [12/121], Batch [700/704], Train Acc: 73.9844 Loss: 1.0620\n",
      "  Validation Accuracy after Epoch 12: 72.2400\n",
      "  Cidar10.1 Accuracy: 62.5\n",
      "  Epoch [13/121], Batch [700/704], Train Acc: 74.7366 Loss: 1.0204\n",
      "  Validation Accuracy after Epoch 13: 70.7400\n",
      "  Cidar10.1 Accuracy: 61.6\n",
      "  Epoch [14/121], Batch [700/704], Train Acc: 75.4509 Loss: 0.9813\n",
      "  Validation Accuracy after Epoch 14: 78.2800\n",
      "  Cidar10.1 Accuracy: 68.5\n",
      "  Epoch [15/121], Batch [700/704], Train Acc: 76.5312 Loss: 0.9367\n",
      "  Validation Accuracy after Epoch 15: 79.3000\n",
      "  Cidar10.1 Accuracy: 68.35\n",
      "  Epoch [16/121], Batch [700/704], Train Acc: 77.1897 Loss: 1.0194\n",
      "  Validation Accuracy after Epoch 16: 78.5800\n",
      "  Cidar10.1 Accuracy: 69.1\n",
      "  Epoch [17/121], Batch [700/704], Train Acc: 77.9129 Loss: 0.8819\n",
      "  Validation Accuracy after Epoch 17: 79.4400\n",
      "  Cidar10.1 Accuracy: 68.75\n",
      "  Epoch [18/121], Batch [700/704], Train Acc: 78.6004 Loss: 0.9069\n",
      "  Validation Accuracy after Epoch 18: 79.5600\n",
      "  Cidar10.1 Accuracy: 69.7\n",
      "  Epoch [19/121], Batch [700/704], Train Acc: 78.9531 Loss: 1.0449\n",
      "  Validation Accuracy after Epoch 19: 78.8200\n",
      "  Cidar10.1 Accuracy: 68.0\n",
      "  Epoch [20/121], Batch [700/704], Train Acc: 79.2054 Loss: 0.9328\n",
      "  Validation Accuracy after Epoch 20: 75.5200\n",
      "  Cidar10.1 Accuracy: 64.3\n",
      "  Epoch [21/121], Batch [700/704], Train Acc: 79.8929 Loss: 0.9942\n",
      "  Validation Accuracy after Epoch 21: 75.6800\n",
      "  Cidar10.1 Accuracy: 66.45\n",
      "  Epoch [22/121], Batch [700/704], Train Acc: 79.8862 Loss: 1.1682\n",
      "  Validation Accuracy after Epoch 22: 75.8200\n",
      "  Cidar10.1 Accuracy: 65.55\n",
      "  Epoch [23/121], Batch [700/704], Train Acc: 80.4129 Loss: 0.9137\n",
      "  Validation Accuracy after Epoch 23: 75.3200\n",
      "  Cidar10.1 Accuracy: 61.6\n",
      "  Epoch [24/121], Batch [700/704], Train Acc: 80.0268 Loss: 1.0067\n",
      "  Validation Accuracy after Epoch 24: 78.4200\n",
      "  Cidar10.1 Accuracy: 70.75\n",
      "  Epoch [25/121], Batch [700/704], Train Acc: 80.7344 Loss: 0.8646\n",
      "  Validation Accuracy after Epoch 25: 81.1800\n",
      "  Cidar10.1 Accuracy: 72.05\n",
      "  Epoch [26/121], Batch [700/704], Train Acc: 81.0558 Loss: 0.9276\n",
      "  Validation Accuracy after Epoch 26: 82.1200\n",
      "  Cidar10.1 Accuracy: 74.2\n",
      "  Epoch [27/121], Batch [700/704], Train Acc: 81.4933 Loss: 0.9738\n",
      "  Validation Accuracy after Epoch 27: 82.9800\n",
      "  Cidar10.1 Accuracy: 74.0\n",
      "  Epoch [28/121], Batch [700/704], Train Acc: 81.5000 Loss: 0.8458\n",
      "  Validation Accuracy after Epoch 28: 82.9200\n",
      "  Cidar10.1 Accuracy: 73.0\n",
      "  Epoch [29/121], Batch [700/704], Train Acc: 81.9754 Loss: 0.8328\n",
      "  Validation Accuracy after Epoch 29: 82.1400\n",
      "  Cidar10.1 Accuracy: 73.75\n",
      "  Epoch [30/121], Batch [700/704], Train Acc: 82.2991 Loss: 0.9736\n",
      "  Validation Accuracy after Epoch 30: 81.9200\n",
      "  Cidar10.1 Accuracy: 72.35\n",
      "  Epoch [31/121], Batch [700/704], Train Acc: 82.5201 Loss: 0.9282\n",
      "  Validation Accuracy after Epoch 31: 80.3200\n",
      "  Cidar10.1 Accuracy: 69.75\n",
      "  Epoch [32/121], Batch [700/704], Train Acc: 82.6897 Loss: 0.9596\n",
      "  Validation Accuracy after Epoch 32: 77.8400\n",
      "  Cidar10.1 Accuracy: 68.05\n",
      "  Epoch [33/121], Batch [700/704], Train Acc: 82.8214 Loss: 0.8779\n",
      "  Validation Accuracy after Epoch 33: 79.2000\n",
      "  Cidar10.1 Accuracy: 68.85\n",
      "  Epoch [34/121], Batch [700/704], Train Acc: 82.9888 Loss: 0.9319\n",
      "  Validation Accuracy after Epoch 34: 77.5800\n",
      "  Cidar10.1 Accuracy: 70.15\n",
      "  Epoch [35/121], Batch [700/704], Train Acc: 82.8549 Loss: 0.9294\n",
      "  Validation Accuracy after Epoch 35: 80.6000\n",
      "  Cidar10.1 Accuracy: 71.5\n",
      "  Epoch [36/121], Batch [700/704], Train Acc: 83.0201 Loss: 0.7940\n",
      "  Validation Accuracy after Epoch 36: 84.3200\n",
      "  Cidar10.1 Accuracy: 75.8\n",
      "  Epoch [37/121], Batch [700/704], Train Acc: 83.3750 Loss: 0.8010\n",
      "  Validation Accuracy after Epoch 37: 84.4400\n",
      "  Cidar10.1 Accuracy: 74.95\n",
      "  Epoch [38/121], Batch [700/704], Train Acc: 83.5826 Loss: 0.8442\n",
      "  Validation Accuracy after Epoch 38: 85.0000\n",
      "  Cidar10.1 Accuracy: 75.55\n",
      "  Epoch [39/121], Batch [700/704], Train Acc: 83.7455 Loss: 0.8705\n",
      "  Validation Accuracy after Epoch 39: 84.3600\n",
      "  Cidar10.1 Accuracy: 74.75\n",
      "  Epoch [40/121], Batch [700/704], Train Acc: 83.8460 Loss: 0.9153\n",
      "  Validation Accuracy after Epoch 40: 83.2000\n",
      "  Cidar10.1 Accuracy: 74.35\n",
      "  Epoch [41/121], Batch [700/704], Train Acc: 83.9375 Loss: 0.8110\n",
      "  Validation Accuracy after Epoch 41: 82.6200\n",
      "  Cidar10.1 Accuracy: 72.0\n",
      "  Epoch [42/121], Batch [700/704], Train Acc: 83.9174 Loss: 1.0617\n",
      "  Validation Accuracy after Epoch 42: 79.9800\n",
      "  Cidar10.1 Accuracy: 71.85\n",
      "  Epoch [43/121], Batch [700/704], Train Acc: 84.2232 Loss: 1.0896\n",
      "  Validation Accuracy after Epoch 43: 77.6800\n",
      "  Cidar10.1 Accuracy: 65.0\n",
      "  Epoch [44/121], Batch [700/704], Train Acc: 84.2254 Loss: 0.8021\n",
      "  Validation Accuracy after Epoch 44: 76.2200\n",
      "  Cidar10.1 Accuracy: 69.65\n",
      "  Epoch [45/121], Batch [700/704], Train Acc: 84.5670 Loss: 0.8141\n",
      "  Validation Accuracy after Epoch 45: 80.2200\n",
      "  Cidar10.1 Accuracy: 70.7\n",
      "  Epoch [46/121], Batch [700/704], Train Acc: 84.3884 Loss: 0.8836\n",
      "  Validation Accuracy after Epoch 46: 82.9600\n",
      "  Cidar10.1 Accuracy: 74.05\n",
      "  Epoch [47/121], Batch [700/704], Train Acc: 84.8214 Loss: 0.9836\n",
      "  Validation Accuracy after Epoch 47: 84.3600\n",
      "  Cidar10.1 Accuracy: 75.2\n",
      "  Epoch [48/121], Batch [700/704], Train Acc: 84.3616 Loss: 0.7916\n",
      "  Validation Accuracy after Epoch 48: 85.9400\n",
      "  Cidar10.1 Accuracy: 75.85\n",
      "  Epoch [49/121], Batch [700/704], Train Acc: 84.6942 Loss: 0.8098\n",
      "  Validation Accuracy after Epoch 49: 85.4200\n",
      "  Cidar10.1 Accuracy: 76.65\n",
      "  Epoch [50/121], Batch [700/704], Train Acc: 84.8326 Loss: 0.9005\n",
      "  Validation Accuracy after Epoch 50: 85.6000\n",
      "  Cidar10.1 Accuracy: 76.05\n",
      "  Epoch [51/121], Batch [700/704], Train Acc: 84.8415 Loss: 0.8404\n",
      "  Validation Accuracy after Epoch 51: 84.6200\n",
      "  Cidar10.1 Accuracy: 74.5\n",
      "  Epoch [52/121], Batch [700/704], Train Acc: 85.2344 Loss: 0.9625\n",
      "  Validation Accuracy after Epoch 52: 82.6200\n",
      "  Cidar10.1 Accuracy: 71.4\n",
      "  Epoch [53/121], Batch [700/704], Train Acc: 85.1116 Loss: 0.8745\n",
      "  Validation Accuracy after Epoch 53: 81.3600\n",
      "  Cidar10.1 Accuracy: 71.8\n",
      "  Epoch [54/121], Batch [700/704], Train Acc: 85.1473 Loss: 0.9540\n",
      "  Validation Accuracy after Epoch 54: 80.1200\n",
      "  Cidar10.1 Accuracy: 69.15\n",
      "  Epoch [55/121], Batch [700/704], Train Acc: 85.1518 Loss: 0.8315\n",
      "  Validation Accuracy after Epoch 55: 80.2400\n",
      "  Cidar10.1 Accuracy: 70.4\n",
      "  Epoch [56/121], Batch [700/704], Train Acc: 85.0759 Loss: 0.8881\n",
      "  Validation Accuracy after Epoch 56: 82.2200\n",
      "  Cidar10.1 Accuracy: 73.2\n",
      "  Epoch [57/121], Batch [700/704], Train Acc: 85.3705 Loss: 1.0212\n",
      "  Validation Accuracy after Epoch 57: 83.9200\n",
      "  Cidar10.1 Accuracy: 73.05\n",
      "  Epoch [58/121], Batch [700/704], Train Acc: 85.1987 Loss: 0.7503\n",
      "  Validation Accuracy after Epoch 58: 85.4000\n",
      "  Cidar10.1 Accuracy: 77.3\n",
      "  Epoch [59/121], Batch [700/704], Train Acc: 85.2656 Loss: 0.7926\n",
      "  Validation Accuracy after Epoch 59: 86.6000\n",
      "  Cidar10.1 Accuracy: 78.75\n",
      "  Epoch [60/121], Batch [700/704], Train Acc: 85.3661 Loss: 0.6336\n",
      "  Validation Accuracy after Epoch 60: 85.7600\n",
      "  Cidar10.1 Accuracy: 77.05\n",
      "  Epoch [61/121], Batch [700/704], Train Acc: 85.6808 Loss: 0.8484\n",
      "  Validation Accuracy after Epoch 61: 86.6000\n",
      "  Cidar10.1 Accuracy: 76.8\n",
      "  Epoch [62/121], Batch [700/704], Train Acc: 85.5223 Loss: 0.7500\n",
      "  Validation Accuracy after Epoch 62: 84.7000\n",
      "  Cidar10.1 Accuracy: 75.3\n",
      "  Epoch [63/121], Batch [700/704], Train Acc: 85.7455 Loss: 0.8515\n",
      "  Validation Accuracy after Epoch 63: 83.5400\n",
      "  Cidar10.1 Accuracy: 73.25\n",
      "  Epoch [64/121], Batch [700/704], Train Acc: 85.7812 Loss: 0.8378\n",
      "  Validation Accuracy after Epoch 64: 82.0400\n",
      "  Cidar10.1 Accuracy: 71.9\n",
      "  Epoch [65/121], Batch [700/704], Train Acc: 85.9821 Loss: 0.8097\n",
      "  Validation Accuracy after Epoch 65: 74.8800\n",
      "  Cidar10.1 Accuracy: 65.95\n",
      "  Epoch [66/121], Batch [700/704], Train Acc: 85.5670 Loss: 0.8614\n",
      "  Validation Accuracy after Epoch 66: 81.5800\n",
      "  Cidar10.1 Accuracy: 73.0\n",
      "  Epoch [67/121], Batch [700/704], Train Acc: 85.5960 Loss: 0.8994\n",
      "  Validation Accuracy after Epoch 67: 80.3200\n",
      "  Cidar10.1 Accuracy: 70.65\n",
      "  Epoch [68/121], Batch [700/704], Train Acc: 85.5000 Loss: 0.7900\n",
      "  Validation Accuracy after Epoch 68: 84.0800\n",
      "  Cidar10.1 Accuracy: 75.65\n",
      "  Epoch [69/121], Batch [700/704], Train Acc: 85.6496 Loss: 0.9548\n",
      "  Validation Accuracy after Epoch 69: 86.7400\n",
      "  Cidar10.1 Accuracy: 75.6\n",
      "  Epoch [70/121], Batch [700/704], Train Acc: 85.8772 Loss: 0.6906\n",
      "  Validation Accuracy after Epoch 70: 86.8400\n",
      "  Cidar10.1 Accuracy: 76.1\n",
      "  Epoch [71/121], Batch [700/704], Train Acc: 86.1094 Loss: 0.7905\n",
      "  Validation Accuracy after Epoch 71: 85.9600\n",
      "  Cidar10.1 Accuracy: 75.9\n",
      "  Epoch [72/121], Batch [700/704], Train Acc: 86.1585 Loss: 0.6956\n",
      "  Validation Accuracy after Epoch 72: 86.1000\n",
      "  Cidar10.1 Accuracy: 77.05\n",
      "  Epoch [73/121], Batch [700/704], Train Acc: 86.0893 Loss: 0.9870\n",
      "  Validation Accuracy after Epoch 73: 85.9000\n",
      "  Cidar10.1 Accuracy: 76.15\n",
      "  Epoch [74/121], Batch [700/704], Train Acc: 86.2121 Loss: 0.7038\n",
      "  Validation Accuracy after Epoch 74: 85.3400\n",
      "  Cidar10.1 Accuracy: 75.65\n",
      "  Epoch [75/121], Batch [700/704], Train Acc: 86.6786 Loss: 0.9811\n",
      "  Validation Accuracy after Epoch 75: 83.2000\n",
      "  Cidar10.1 Accuracy: 74.3\n",
      "  Epoch [76/121], Batch [700/704], Train Acc: 86.5290 Loss: 0.9178\n",
      "  Validation Accuracy after Epoch 76: 80.2200\n",
      "  Cidar10.1 Accuracy: 69.15\n",
      "  Epoch [77/121], Batch [700/704], Train Acc: 86.0960 Loss: 0.7165\n",
      "  Validation Accuracy after Epoch 77: 77.6800\n",
      "  Cidar10.1 Accuracy: 66.65\n",
      "  Epoch [78/121], Batch [700/704], Train Acc: 86.0781 Loss: 0.8902\n",
      "  Validation Accuracy after Epoch 78: 83.8600\n",
      "  Cidar10.1 Accuracy: 73.9\n",
      "  Epoch [79/121], Batch [700/704], Train Acc: 86.3482 Loss: 0.7926\n",
      "  Validation Accuracy after Epoch 79: 84.8200\n",
      "  Cidar10.1 Accuracy: 74.75\n",
      "  Epoch [80/121], Batch [700/704], Train Acc: 86.4241 Loss: 0.8168\n",
      "  Validation Accuracy after Epoch 80: 86.6800\n",
      "  Cidar10.1 Accuracy: 78.6\n",
      "  Epoch [81/121], Batch [700/704], Train Acc: 86.2679 Loss: 0.7481\n",
      "  Validation Accuracy after Epoch 81: 87.1200\n",
      "  Cidar10.1 Accuracy: 78.95\n",
      "  Epoch [82/121], Batch [700/704], Train Acc: 86.4799 Loss: 0.8080\n",
      "  Validation Accuracy after Epoch 82: 87.4200\n",
      "  Cidar10.1 Accuracy: 77.25\n",
      "  Epoch [83/121], Batch [700/704], Train Acc: 86.5268 Loss: 0.8772\n",
      "  Validation Accuracy after Epoch 83: 87.0200\n",
      "  Cidar10.1 Accuracy: 77.05\n",
      "  Epoch [84/121], Batch [700/704], Train Acc: 86.3772 Loss: 1.0385\n",
      "  Validation Accuracy after Epoch 84: 86.5000\n",
      "  Cidar10.1 Accuracy: 77.95\n",
      "  Epoch [85/121], Batch [700/704], Train Acc: 86.5692 Loss: 0.8471\n",
      "  Validation Accuracy after Epoch 85: 84.3600\n",
      "  Cidar10.1 Accuracy: 76.0\n",
      "  Epoch [86/121], Batch [700/704], Train Acc: 86.7143 Loss: 0.8163\n",
      "  Validation Accuracy after Epoch 86: 80.8600\n",
      "  Cidar10.1 Accuracy: 70.3\n",
      "  Epoch [87/121], Batch [700/704], Train Acc: 86.8125 Loss: 0.8626\n",
      "  Validation Accuracy after Epoch 87: 80.4800\n",
      "  Cidar10.1 Accuracy: 70.35\n",
      "  Epoch [88/121], Batch [700/704], Train Acc: 86.7969 Loss: 0.7733\n",
      "  Validation Accuracy after Epoch 88: 72.2600\n",
      "  Cidar10.1 Accuracy: 61.8\n",
      "  Epoch [89/121], Batch [700/704], Train Acc: 86.4688 Loss: 0.7753\n",
      "  Validation Accuracy after Epoch 89: 82.9000\n",
      "  Cidar10.1 Accuracy: 73.95\n",
      "  Epoch [90/121], Batch [700/704], Train Acc: 86.8862 Loss: 0.8241\n",
      "  Validation Accuracy after Epoch 90: 85.3800\n",
      "  Cidar10.1 Accuracy: 76.6\n",
      "  Epoch [91/121], Batch [700/704], Train Acc: 86.7634 Loss: 0.7526\n",
      "  Validation Accuracy after Epoch 91: 88.1600\n",
      "  Cidar10.1 Accuracy: 77.4\n",
      "  Epoch [92/121], Batch [700/704], Train Acc: 86.5647 Loss: 0.7444\n",
      "  Validation Accuracy after Epoch 92: 87.3600\n",
      "  Cidar10.1 Accuracy: 78.25\n",
      "  Epoch [93/121], Batch [700/704], Train Acc: 86.9554 Loss: 0.8308\n",
      "  Validation Accuracy after Epoch 93: 86.9200\n",
      "  Cidar10.1 Accuracy: 77.45\n",
      "  Epoch [94/121], Batch [700/704], Train Acc: 87.1116 Loss: 0.6912\n",
      "  Validation Accuracy after Epoch 94: 87.9000\n",
      "  Cidar10.1 Accuracy: 78.05\n",
      "  Epoch [95/121], Batch [700/704], Train Acc: 86.9509 Loss: 0.7028\n",
      "  Validation Accuracy after Epoch 95: 86.6200\n",
      "  Cidar10.1 Accuracy: 78.2\n",
      "  Epoch [96/121], Batch [700/704], Train Acc: 87.2188 Loss: 0.8195\n",
      "  Validation Accuracy after Epoch 96: 84.9000\n",
      "  Cidar10.1 Accuracy: 74.35\n",
      "  Epoch [97/121], Batch [700/704], Train Acc: 87.2746 Loss: 0.7479\n",
      "  Validation Accuracy after Epoch 97: 84.1000\n",
      "  Cidar10.1 Accuracy: 72.9\n",
      "  Epoch [98/121], Batch [700/704], Train Acc: 87.2098 Loss: 0.8239\n",
      "  Validation Accuracy after Epoch 98: 76.6600\n",
      "  Cidar10.1 Accuracy: 69.0\n",
      "  Epoch [99/121], Batch [700/704], Train Acc: 86.7478 Loss: 0.8475\n",
      "  Validation Accuracy after Epoch 99: 85.0200\n",
      "  Cidar10.1 Accuracy: 74.6\n",
      "  Epoch [100/121], Batch [700/704], Train Acc: 87.3237 Loss: 0.7852\n",
      "  Validation Accuracy after Epoch 100: 79.5400\n",
      "  Cidar10.1 Accuracy: 69.2\n",
      "  Epoch [101/121], Batch [700/704], Train Acc: 86.5134 Loss: 0.7155\n",
      "  Validation Accuracy after Epoch 101: 86.6000\n",
      "  Cidar10.1 Accuracy: 77.7\n",
      "  Epoch [102/121], Batch [700/704], Train Acc: 87.1987 Loss: 0.7246\n",
      "  Validation Accuracy after Epoch 102: 87.0600\n",
      "  Cidar10.1 Accuracy: 80.0\n",
      "  Epoch [103/121], Batch [700/704], Train Acc: 87.4799 Loss: 0.7365\n",
      "  Validation Accuracy after Epoch 103: 87.8600\n",
      "  Cidar10.1 Accuracy: 79.5\n",
      "  Epoch [104/121], Batch [700/704], Train Acc: 87.3125 Loss: 0.6201\n",
      "  Validation Accuracy after Epoch 104: 86.8000\n",
      "  Cidar10.1 Accuracy: 78.75\n",
      "  Epoch [105/121], Batch [700/704], Train Acc: 87.0848 Loss: 0.8470\n",
      "  Validation Accuracy after Epoch 105: 87.3400\n",
      "  Cidar10.1 Accuracy: 78.45\n",
      "  Epoch [106/121], Batch [700/704], Train Acc: 87.3906 Loss: 0.8870\n",
      "  Validation Accuracy after Epoch 106: 86.8600\n",
      "  Cidar10.1 Accuracy: 78.4\n",
      "  Epoch [107/121], Batch [700/704], Train Acc: 87.4576 Loss: 0.8570\n",
      "  Validation Accuracy after Epoch 107: 84.9000\n",
      "  Cidar10.1 Accuracy: 75.95\n",
      "  Epoch [108/121], Batch [700/704], Train Acc: 87.5357 Loss: 0.8991\n",
      "  Validation Accuracy after Epoch 108: 82.1600\n",
      "  Cidar10.1 Accuracy: 71.8\n",
      "  Epoch [109/121], Batch [700/704], Train Acc: 87.3750 Loss: 0.9356\n",
      "  Validation Accuracy after Epoch 109: 80.5400\n",
      "  Cidar10.1 Accuracy: 71.0\n",
      "  Epoch [110/121], Batch [700/704], Train Acc: 87.4844 Loss: 0.8364\n",
      "  Validation Accuracy after Epoch 110: 80.7400\n",
      "  Cidar10.1 Accuracy: 71.4\n",
      "  Epoch [111/121], Batch [700/704], Train Acc: 86.6897 Loss: 0.7987\n",
      "  Validation Accuracy after Epoch 111: 83.5400\n",
      "  Cidar10.1 Accuracy: 71.05\n",
      "  Epoch [112/121], Batch [700/704], Train Acc: 87.6272 Loss: 0.7862\n",
      "  Validation Accuracy after Epoch 112: 86.7600\n",
      "  Cidar10.1 Accuracy: 77.3\n",
      "  Epoch [113/121], Batch [700/704], Train Acc: 87.5156 Loss: 0.7804\n",
      "  Validation Accuracy after Epoch 113: 87.6000\n",
      "  Cidar10.1 Accuracy: 79.3\n",
      "  Epoch [114/121], Batch [700/704], Train Acc: 87.4732 Loss: 0.9273\n",
      "  Validation Accuracy after Epoch 114: 88.1000\n",
      "  Cidar10.1 Accuracy: 77.35\n",
      "  Epoch [115/121], Batch [700/704], Train Acc: 87.4531 Loss: 0.7593\n",
      "  Validation Accuracy after Epoch 115: 87.6800\n",
      "  Cidar10.1 Accuracy: 78.1\n",
      "  Epoch [116/121], Batch [700/704], Train Acc: 87.4263 Loss: 0.7031\n",
      "  Validation Accuracy after Epoch 116: 87.8400\n",
      "  Cidar10.1 Accuracy: 78.05\n",
      "  Epoch [117/121], Batch [700/704], Train Acc: 87.5469 Loss: 0.9012\n",
      "  Validation Accuracy after Epoch 117: 87.2200\n",
      "  Cidar10.1 Accuracy: 78.3\n",
      "  Epoch [118/121], Batch [700/704], Train Acc: 87.5312 Loss: 0.7251\n",
      "  Validation Accuracy after Epoch 118: 86.3600\n",
      "  Cidar10.1 Accuracy: 75.4\n",
      "  Epoch [119/121], Batch [700/704], Train Acc: 87.8482 Loss: 0.8048\n",
      "  Validation Accuracy after Epoch 119: 80.4400\n",
      "  Cidar10.1 Accuracy: 67.85\n",
      "  Epoch [120/121], Batch [700/704], Train Acc: 87.9196 Loss: 0.8212\n",
      "  Validation Accuracy after Epoch 120: 83.6200\n",
      "  Cidar10.1 Accuracy: 75.35\n",
      "  Epoch [121/121], Batch [700/704], Train Acc: 87.6942 Loss: 1.1283\n",
      "  Validation Accuracy after Epoch 121: 76.2800\n",
      "  Cidar10.1 Accuracy: 68.2\n",
      "Trial 4 complete. Best Validation Accuracy: 88.1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 04:38:19,025] Trial 4 finished with value: 88.16 and parameters: {'num_epochs': 121, 'model_type': 'efficientnet', 'batch_size': 64, 'optimizer_type': 'SGD', 'scheduler_type': 'CosineAnnealingLR', 'lr': 0.08528869231926088, 'momentum': 0.8889096409901536, 'weight_decay': 0.00016615937852276983, 'eta_min': 0.00019452924876717267}. Best is trial 2 with value: 92.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=5\n",
      "num_epochs: 108\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8971607284559575\n",
      "beta2: 0.9963589435517188\n",
      "lr: 0.0004240424765580441\n",
      "weight_decay: 0.001461400798408547\n",
      "max_lr: 0.00941063463217609\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/108], Batch [80/88], Train Acc: 36.2036 Loss: 1.6910\n",
      "  Validation Accuracy after Epoch 1: 45.6200\n",
      "  Cidar10.1 Accuracy: 38.45\n",
      "  Epoch [2/108], Batch [80/88], Train Acc: 52.0239 Loss: 1.3593\n",
      "  Validation Accuracy after Epoch 2: 54.1800\n",
      "  Cidar10.1 Accuracy: 42.95\n",
      "  Epoch [3/108], Batch [80/88], Train Acc: 60.8398 Loss: 1.3085\n",
      "  Validation Accuracy after Epoch 3: 61.8200\n",
      "  Cidar10.1 Accuracy: 49.65\n",
      "  Epoch [4/108], Batch [80/88], Train Acc: 66.4868 Loss: 1.3033\n",
      "  Validation Accuracy after Epoch 4: 69.7400\n",
      "  Cidar10.1 Accuracy: 58.4\n",
      "  Epoch [5/108], Batch [80/88], Train Acc: 69.9438 Loss: 1.1213\n",
      "  Validation Accuracy after Epoch 5: 68.4600\n",
      "  Cidar10.1 Accuracy: 54.3\n",
      "  Epoch [6/108], Batch [80/88], Train Acc: 73.4912 Loss: 1.1051\n",
      "  Validation Accuracy after Epoch 6: 71.1600\n",
      "  Cidar10.1 Accuracy: 57.35\n",
      "  Epoch [7/108], Batch [80/88], Train Acc: 75.1294 Loss: 1.0381\n",
      "  Validation Accuracy after Epoch 7: 67.0800\n",
      "  Cidar10.1 Accuracy: 53.6\n",
      "  Epoch [8/108], Batch [80/88], Train Acc: 77.0435 Loss: 1.0557\n",
      "  Validation Accuracy after Epoch 8: 76.2000\n",
      "  Cidar10.1 Accuracy: 65.25\n",
      "  Epoch [9/108], Batch [80/88], Train Acc: 78.7183 Loss: 1.0399\n",
      "  Validation Accuracy after Epoch 9: 75.2200\n",
      "  Cidar10.1 Accuracy: 64.45\n",
      "  Epoch [10/108], Batch [80/88], Train Acc: 79.9951 Loss: 0.9772\n",
      "  Validation Accuracy after Epoch 10: 77.9400\n",
      "  Cidar10.1 Accuracy: 66.1\n",
      "  Epoch [11/108], Batch [80/88], Train Acc: 80.7153 Loss: 1.0229\n",
      "  Validation Accuracy after Epoch 11: 73.0400\n",
      "  Cidar10.1 Accuracy: 61.55\n",
      "  Epoch [12/108], Batch [80/88], Train Acc: 81.9580 Loss: 0.8869\n",
      "  Validation Accuracy after Epoch 12: 78.4800\n",
      "  Cidar10.1 Accuracy: 69.3\n",
      "  Epoch [13/108], Batch [80/88], Train Acc: 83.0884 Loss: 0.9335\n",
      "  Validation Accuracy after Epoch 13: 72.9600\n",
      "  Cidar10.1 Accuracy: 60.85\n",
      "  Epoch [14/108], Batch [80/88], Train Acc: 83.9771 Loss: 0.9017\n",
      "  Validation Accuracy after Epoch 14: 81.8400\n",
      "  Cidar10.1 Accuracy: 69.05\n",
      "  Epoch [15/108], Batch [80/88], Train Acc: 84.5410 Loss: 0.9023\n",
      "  Validation Accuracy after Epoch 15: 78.0000\n",
      "  Cidar10.1 Accuracy: 65.25\n",
      "  Epoch [16/108], Batch [80/88], Train Acc: 85.1978 Loss: 0.8937\n",
      "  Validation Accuracy after Epoch 16: 82.7200\n",
      "  Cidar10.1 Accuracy: 73.2\n",
      "  Epoch [17/108], Batch [80/88], Train Acc: 85.8398 Loss: 0.8613\n",
      "  Validation Accuracy after Epoch 17: 80.5200\n",
      "  Cidar10.1 Accuracy: 69.8\n",
      "  Epoch [18/108], Batch [80/88], Train Acc: 86.3843 Loss: 0.8060\n",
      "  Validation Accuracy after Epoch 18: 83.5200\n",
      "  Cidar10.1 Accuracy: 70.55\n",
      "  Epoch [19/108], Batch [80/88], Train Acc: 87.0215 Loss: 0.7924\n",
      "  Validation Accuracy after Epoch 19: 77.8600\n",
      "  Cidar10.1 Accuracy: 67.45\n",
      "  Epoch [20/108], Batch [80/88], Train Acc: 87.2070 Loss: 0.8057\n",
      "  Validation Accuracy after Epoch 20: 84.0000\n",
      "  Cidar10.1 Accuracy: 73.3\n",
      "  Epoch [21/108], Batch [80/88], Train Acc: 87.9663 Loss: 0.8345\n",
      "  Validation Accuracy after Epoch 21: 84.9000\n",
      "  Cidar10.1 Accuracy: 72.95\n",
      "  Epoch [22/108], Batch [80/88], Train Acc: 88.0640 Loss: 0.8315\n",
      "  Validation Accuracy after Epoch 22: 84.4200\n",
      "  Cidar10.1 Accuracy: 73.85\n",
      "  Epoch [23/108], Batch [80/88], Train Acc: 88.5815 Loss: 0.8050\n",
      "  Validation Accuracy after Epoch 23: 85.3800\n",
      "  Cidar10.1 Accuracy: 76.05\n",
      "  Epoch [24/108], Batch [80/88], Train Acc: 88.9160 Loss: 0.7871\n",
      "  Validation Accuracy after Epoch 24: 86.0000\n",
      "  Cidar10.1 Accuracy: 74.45\n",
      "  Epoch [25/108], Batch [80/88], Train Acc: 89.3921 Loss: 0.7735\n",
      "  Validation Accuracy after Epoch 25: 83.3000\n",
      "  Cidar10.1 Accuracy: 73.15\n",
      "  Epoch [26/108], Batch [80/88], Train Acc: 89.6240 Loss: 0.8079\n",
      "  Validation Accuracy after Epoch 26: 86.1000\n",
      "  Cidar10.1 Accuracy: 77.2\n",
      "  Epoch [27/108], Batch [80/88], Train Acc: 89.8096 Loss: 0.7583\n",
      "  Validation Accuracy after Epoch 27: 86.6200\n",
      "  Cidar10.1 Accuracy: 76.45\n",
      "  Epoch [28/108], Batch [80/88], Train Acc: 90.2075 Loss: 0.7273\n",
      "  Validation Accuracy after Epoch 28: 86.5400\n",
      "  Cidar10.1 Accuracy: 78.5\n",
      "  Epoch [29/108], Batch [80/88], Train Acc: 90.8032 Loss: 0.7657\n",
      "  Validation Accuracy after Epoch 29: 86.3600\n",
      "  Cidar10.1 Accuracy: 75.75\n",
      "  Epoch [30/108], Batch [80/88], Train Acc: 90.8936 Loss: 0.7379\n",
      "  Validation Accuracy after Epoch 30: 85.8000\n",
      "  Cidar10.1 Accuracy: 76.2\n",
      "  Epoch [31/108], Batch [80/88], Train Acc: 91.5552 Loss: 0.7406\n",
      "  Validation Accuracy after Epoch 31: 85.6600\n",
      "  Cidar10.1 Accuracy: 73.75\n",
      "  Epoch [32/108], Batch [80/88], Train Acc: 91.4819 Loss: 0.7042\n",
      "  Validation Accuracy after Epoch 32: 84.9000\n",
      "  Cidar10.1 Accuracy: 76.55\n",
      "  Epoch [33/108], Batch [80/88], Train Acc: 92.0337 Loss: 0.6945\n",
      "  Validation Accuracy after Epoch 33: 87.1200\n",
      "  Cidar10.1 Accuracy: 77.15\n",
      "  Epoch [34/108], Batch [80/88], Train Acc: 92.2070 Loss: 0.7408\n",
      "  Validation Accuracy after Epoch 34: 87.5000\n",
      "  Cidar10.1 Accuracy: 77.85\n",
      "  Epoch [35/108], Batch [80/88], Train Acc: 92.6807 Loss: 0.7443\n",
      "  Validation Accuracy after Epoch 35: 88.0400\n",
      "  Cidar10.1 Accuracy: 79.25\n",
      "  Epoch [36/108], Batch [80/88], Train Acc: 92.9907 Loss: 0.7171\n",
      "  Validation Accuracy after Epoch 36: 87.9800\n",
      "  Cidar10.1 Accuracy: 76.55\n",
      "  Epoch [37/108], Batch [80/88], Train Acc: 92.9883 Loss: 0.7380\n",
      "  Validation Accuracy after Epoch 37: 88.5000\n",
      "  Cidar10.1 Accuracy: 80.1\n",
      "  Epoch [38/108], Batch [80/88], Train Acc: 93.2129 Loss: 0.6891\n",
      "  Validation Accuracy after Epoch 38: 89.7000\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [39/108], Batch [80/88], Train Acc: 93.6963 Loss: 0.7018\n",
      "  Validation Accuracy after Epoch 39: 88.5000\n",
      "  Cidar10.1 Accuracy: 79.65\n",
      "  Epoch [40/108], Batch [80/88], Train Acc: 93.7012 Loss: 0.6688\n",
      "  Validation Accuracy after Epoch 40: 89.0600\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [41/108], Batch [80/88], Train Acc: 94.1235 Loss: 0.6376\n",
      "  Validation Accuracy after Epoch 41: 89.2000\n",
      "  Cidar10.1 Accuracy: 80.3\n",
      "  Epoch [42/108], Batch [80/88], Train Acc: 94.3384 Loss: 0.6928\n",
      "  Validation Accuracy after Epoch 42: 89.3200\n",
      "  Cidar10.1 Accuracy: 82.45\n",
      "  Epoch [43/108], Batch [80/88], Train Acc: 94.6826 Loss: 0.6369\n",
      "  Validation Accuracy after Epoch 43: 88.4800\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [44/108], Batch [80/88], Train Acc: 94.8242 Loss: 0.6809\n",
      "  Validation Accuracy after Epoch 44: 88.9800\n",
      "  Cidar10.1 Accuracy: 78.45\n",
      "  Epoch [45/108], Batch [80/88], Train Acc: 94.9829 Loss: 0.6663\n",
      "  Validation Accuracy after Epoch 45: 88.4200\n",
      "  Cidar10.1 Accuracy: 79.9\n",
      "  Epoch [46/108], Batch [80/88], Train Acc: 95.2979 Loss: 0.6258\n",
      "  Validation Accuracy after Epoch 46: 89.3400\n",
      "  Cidar10.1 Accuracy: 79.4\n",
      "  Epoch [47/108], Batch [80/88], Train Acc: 95.3882 Loss: 0.6290\n",
      "  Validation Accuracy after Epoch 47: 90.4000\n",
      "  Cidar10.1 Accuracy: 80.7\n",
      "  Epoch [48/108], Batch [80/88], Train Acc: 95.6006 Loss: 0.6348\n",
      "  Validation Accuracy after Epoch 48: 90.2600\n",
      "  Cidar10.1 Accuracy: 82.05\n",
      "  Epoch [49/108], Batch [80/88], Train Acc: 95.9521 Loss: 0.6297\n",
      "  Validation Accuracy after Epoch 49: 90.7000\n",
      "  Cidar10.1 Accuracy: 81.0\n",
      "  Epoch [50/108], Batch [80/88], Train Acc: 95.9302 Loss: 0.6405\n",
      "  Validation Accuracy after Epoch 50: 90.1600\n",
      "  Cidar10.1 Accuracy: 83.3\n",
      "  Epoch [51/108], Batch [80/88], Train Acc: 96.0352 Loss: 0.6450\n",
      "  Validation Accuracy after Epoch 51: 90.7600\n",
      "  Cidar10.1 Accuracy: 82.35\n",
      "  Epoch [52/108], Batch [80/88], Train Acc: 96.1230 Loss: 0.6308\n",
      "  Validation Accuracy after Epoch 52: 90.7800\n",
      "  Cidar10.1 Accuracy: 82.25\n",
      "  Epoch [53/108], Batch [80/88], Train Acc: 96.3794 Loss: 0.5949\n",
      "  Validation Accuracy after Epoch 53: 90.8400\n",
      "  Cidar10.1 Accuracy: 82.85\n",
      "  Epoch [54/108], Batch [80/88], Train Acc: 96.6626 Loss: 0.6097\n",
      "  Validation Accuracy after Epoch 54: 90.3800\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [55/108], Batch [80/88], Train Acc: 96.6235 Loss: 0.6146\n",
      "  Validation Accuracy after Epoch 55: 90.8800\n",
      "  Cidar10.1 Accuracy: 82.7\n",
      "  Epoch [56/108], Batch [80/88], Train Acc: 96.9238 Loss: 0.6015\n",
      "  Validation Accuracy after Epoch 56: 90.3200\n",
      "  Cidar10.1 Accuracy: 82.3\n",
      "  Epoch [57/108], Batch [80/88], Train Acc: 97.0850 Loss: 0.6030\n",
      "  Validation Accuracy after Epoch 57: 90.3200\n",
      "  Cidar10.1 Accuracy: 83.15\n",
      "  Epoch [58/108], Batch [80/88], Train Acc: 97.2852 Loss: 0.6124\n",
      "  Validation Accuracy after Epoch 58: 91.2000\n",
      "  Cidar10.1 Accuracy: 84.4\n",
      "  Epoch [59/108], Batch [80/88], Train Acc: 97.3584 Loss: 0.5929\n",
      "  Validation Accuracy after Epoch 59: 89.9400\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [60/108], Batch [80/88], Train Acc: 97.4756 Loss: 0.6041\n",
      "  Validation Accuracy after Epoch 60: 91.6200\n",
      "  Cidar10.1 Accuracy: 83.0\n",
      "  Epoch [61/108], Batch [80/88], Train Acc: 97.6392 Loss: 0.5984\n",
      "  Validation Accuracy after Epoch 61: 90.7200\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [62/108], Batch [80/88], Train Acc: 97.6904 Loss: 0.5901\n",
      "  Validation Accuracy after Epoch 62: 90.9000\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [63/108], Batch [80/88], Train Acc: 97.8149 Loss: 0.5786\n",
      "  Validation Accuracy after Epoch 63: 90.9800\n",
      "  Cidar10.1 Accuracy: 83.95\n",
      "  Epoch [64/108], Batch [80/88], Train Acc: 97.8931 Loss: 0.5882\n",
      "  Validation Accuracy after Epoch 64: 91.3400\n",
      "  Cidar10.1 Accuracy: 83.6\n",
      "  Epoch [65/108], Batch [80/88], Train Acc: 98.1152 Loss: 0.5694\n",
      "  Validation Accuracy after Epoch 65: 91.7400\n",
      "  Cidar10.1 Accuracy: 83.55\n",
      "  Epoch [66/108], Batch [80/88], Train Acc: 98.3301 Loss: 0.5663\n",
      "  Validation Accuracy after Epoch 66: 91.3000\n",
      "  Cidar10.1 Accuracy: 83.05\n",
      "  Epoch [67/108], Batch [80/88], Train Acc: 98.3105 Loss: 0.5782\n",
      "  Validation Accuracy after Epoch 67: 91.4400\n",
      "  Cidar10.1 Accuracy: 83.8\n",
      "  Epoch [68/108], Batch [80/88], Train Acc: 98.3057 Loss: 0.5904\n",
      "  Validation Accuracy after Epoch 68: 92.2000\n",
      "  Cidar10.1 Accuracy: 83.9\n",
      "  Epoch [69/108], Batch [80/88], Train Acc: 98.4668 Loss: 0.5638\n",
      "  Validation Accuracy after Epoch 69: 91.9800\n",
      "  Cidar10.1 Accuracy: 83.85\n",
      "  Epoch [70/108], Batch [80/88], Train Acc: 98.5938 Loss: 0.5922\n",
      "  Validation Accuracy after Epoch 70: 91.5200\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [71/108], Batch [80/88], Train Acc: 98.4570 Loss: 0.5826\n",
      "  Validation Accuracy after Epoch 71: 91.8800\n",
      "  Cidar10.1 Accuracy: 84.0\n",
      "  Epoch [72/108], Batch [80/88], Train Acc: 98.7476 Loss: 0.5466\n",
      "  Validation Accuracy after Epoch 72: 92.1600\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [73/108], Batch [80/88], Train Acc: 98.8843 Loss: 0.5482\n",
      "  Validation Accuracy after Epoch 73: 91.7200\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [74/108], Batch [80/88], Train Acc: 98.8550 Loss: 0.5572\n",
      "  Validation Accuracy after Epoch 74: 91.7000\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [75/108], Batch [80/88], Train Acc: 98.8916 Loss: 0.5578\n",
      "  Validation Accuracy after Epoch 75: 92.2800\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [76/108], Batch [80/88], Train Acc: 99.0381 Loss: 0.5590\n",
      "  Validation Accuracy after Epoch 76: 92.4200\n",
      "  Cidar10.1 Accuracy: 83.9\n",
      "  Epoch [77/108], Batch [80/88], Train Acc: 99.1772 Loss: 0.5590\n",
      "  Validation Accuracy after Epoch 77: 92.3400\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [78/108], Batch [80/88], Train Acc: 99.1235 Loss: 0.5448\n",
      "  Validation Accuracy after Epoch 78: 92.2000\n",
      "  Cidar10.1 Accuracy: 84.05\n",
      "  Epoch [79/108], Batch [80/88], Train Acc: 99.2041 Loss: 0.5518\n",
      "  Validation Accuracy after Epoch 79: 92.5400\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [80/108], Batch [80/88], Train Acc: 99.1870 Loss: 0.5556\n",
      "  Validation Accuracy after Epoch 80: 92.7200\n",
      "  Cidar10.1 Accuracy: 83.75\n",
      "  Epoch [81/108], Batch [80/88], Train Acc: 99.2993 Loss: 0.5433\n",
      "  Validation Accuracy after Epoch 81: 92.2400\n",
      "  Cidar10.1 Accuracy: 84.25\n",
      "  Epoch [82/108], Batch [80/88], Train Acc: 99.3311 Loss: 0.5406\n",
      "  Validation Accuracy after Epoch 82: 92.5000\n",
      "  Cidar10.1 Accuracy: 83.8\n",
      "  Epoch [83/108], Batch [80/88], Train Acc: 99.4043 Loss: 0.5419\n",
      "  Validation Accuracy after Epoch 83: 92.5600\n",
      "  Cidar10.1 Accuracy: 83.95\n",
      "  Epoch [84/108], Batch [80/88], Train Acc: 99.4434 Loss: 0.5387\n",
      "  Validation Accuracy after Epoch 84: 92.5800\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [85/108], Batch [80/88], Train Acc: 99.4287 Loss: 0.5420\n",
      "  Validation Accuracy after Epoch 85: 92.7600\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [86/108], Batch [80/88], Train Acc: 99.4971 Loss: 0.5381\n",
      "  Validation Accuracy after Epoch 86: 92.6800\n",
      "  Cidar10.1 Accuracy: 84.75\n",
      "  Epoch [87/108], Batch [80/88], Train Acc: 99.5776 Loss: 0.5405\n",
      "  Validation Accuracy after Epoch 87: 93.0800\n",
      "  Cidar10.1 Accuracy: 85.15\n",
      "  Epoch [88/108], Batch [80/88], Train Acc: 99.5312 Loss: 0.5392\n",
      "  Validation Accuracy after Epoch 88: 92.6200\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [89/108], Batch [80/88], Train Acc: 99.5532 Loss: 0.5338\n",
      "  Validation Accuracy after Epoch 89: 92.7200\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [90/108], Batch [80/88], Train Acc: 99.5996 Loss: 0.5295\n",
      "  Validation Accuracy after Epoch 90: 92.7000\n",
      "  Cidar10.1 Accuracy: 85.0\n",
      "  Epoch [91/108], Batch [80/88], Train Acc: 99.6094 Loss: 0.5283\n",
      "  Validation Accuracy after Epoch 91: 92.7000\n",
      "  Cidar10.1 Accuracy: 84.6\n",
      "  Epoch [92/108], Batch [80/88], Train Acc: 99.6948 Loss: 0.5320\n",
      "  Validation Accuracy after Epoch 92: 92.7400\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [93/108], Batch [80/88], Train Acc: 99.6851 Loss: 0.5344\n",
      "  Validation Accuracy after Epoch 93: 92.9400\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [94/108], Batch [80/88], Train Acc: 99.6704 Loss: 0.5405\n",
      "  Validation Accuracy after Epoch 94: 92.6600\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [95/108], Batch [80/88], Train Acc: 99.7510 Loss: 0.5368\n",
      "  Validation Accuracy after Epoch 95: 92.9000\n",
      "  Cidar10.1 Accuracy: 84.6\n",
      "  Epoch [96/108], Batch [80/88], Train Acc: 99.7534 Loss: 0.5343\n",
      "  Validation Accuracy after Epoch 96: 92.8600\n",
      "  Cidar10.1 Accuracy: 85.65\n",
      "  Epoch [97/108], Batch [80/88], Train Acc: 99.7290 Loss: 0.5359\n",
      "  Validation Accuracy after Epoch 97: 93.2800\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [98/108], Batch [80/88], Train Acc: 99.7778 Loss: 0.5274\n",
      "  Validation Accuracy after Epoch 98: 93.0000\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [99/108], Batch [80/88], Train Acc: 99.7363 Loss: 0.5273\n",
      "  Validation Accuracy after Epoch 99: 93.1600\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [100/108], Batch [80/88], Train Acc: 99.7559 Loss: 0.5365\n",
      "  Validation Accuracy after Epoch 100: 93.2400\n",
      "  Cidar10.1 Accuracy: 85.5\n",
      "  Epoch [101/108], Batch [80/88], Train Acc: 99.7852 Loss: 0.5334\n",
      "  Validation Accuracy after Epoch 101: 92.9200\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [102/108], Batch [80/88], Train Acc: 99.7534 Loss: 0.5266\n",
      "  Validation Accuracy after Epoch 102: 93.1800\n",
      "  Cidar10.1 Accuracy: 85.15\n",
      "  Epoch [103/108], Batch [80/88], Train Acc: 99.7559 Loss: 0.5276\n",
      "  Validation Accuracy after Epoch 103: 93.2200\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [104/108], Batch [80/88], Train Acc: 99.7681 Loss: 0.5276\n",
      "  Validation Accuracy after Epoch 104: 92.7800\n",
      "  Cidar10.1 Accuracy: 85.65\n",
      "  Epoch [105/108], Batch [80/88], Train Acc: 99.7778 Loss: 0.5281\n",
      "  Validation Accuracy after Epoch 105: 93.2000\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [106/108], Batch [80/88], Train Acc: 99.7876 Loss: 0.5265\n",
      "  Validation Accuracy after Epoch 106: 92.6200\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [107/108], Batch [80/88], Train Acc: 99.8047 Loss: 0.5280\n",
      "  Validation Accuracy after Epoch 107: 93.1200\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [108/108], Batch [80/88], Train Acc: 99.7534 Loss: 0.5266\n",
      "  Validation Accuracy after Epoch 108: 93.0800\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "Trial 5 complete. Best Validation Accuracy: 93.2800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 04:55:42,942] Trial 5 finished with value: 93.28 and parameters: {'num_epochs': 108, 'model_type': 'base', 'batch_size': 512, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8971607284559575, 'beta2': 0.9963589435517188, 'lr': 0.0004240424765580441, 'weight_decay': 0.001461400798408547, 'max_lr': 0.00941063463217609}. Best is trial 5 with value: 93.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=6\n",
      "num_epochs: 81\n",
      "model_type: largeresnet\n",
      "batch_size: 256\n",
      "optimizer_type: Adam\n",
      "scheduler_type: CosineAnnealingLR\n",
      "beta1: 0.863700704711385\n",
      "beta2: 0.9948206675016444\n",
      "lr: 2.2989649318469157e-05\n",
      "weight_decay: 3.9733422288800845e-05\n",
      "eta_min: 0.00010769406377503403\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/81], Batch [170/176], Train Acc: 37.4494 Loss: 1.6510\n",
      "  Validation Accuracy after Epoch 1: 48.2800\n",
      "  Cidar10.1 Accuracy: 37.7\n",
      "  Epoch [2/81], Batch [170/176], Train Acc: 51.3419 Loss: 1.4049\n",
      "  Validation Accuracy after Epoch 2: 55.8200\n",
      "  Cidar10.1 Accuracy: 44.25\n",
      "  Epoch [3/81], Batch [170/176], Train Acc: 58.0905 Loss: 1.3460\n",
      "  Validation Accuracy after Epoch 3: 60.2200\n",
      "  Cidar10.1 Accuracy: 47.85\n",
      "  Epoch [4/81], Batch [170/176], Train Acc: 62.2013 Loss: 1.2643\n",
      "  Validation Accuracy after Epoch 4: 61.8000\n",
      "  Cidar10.1 Accuracy: 51.5\n",
      "  Epoch [5/81], Batch [170/176], Train Acc: 65.6664 Loss: 1.3634\n",
      "  Validation Accuracy after Epoch 5: 63.9000\n",
      "  Cidar10.1 Accuracy: 53.15\n",
      "  Epoch [6/81], Batch [170/176], Train Acc: 67.8447 Loss: 1.2385\n",
      "  Validation Accuracy after Epoch 6: 61.9800\n",
      "  Cidar10.1 Accuracy: 48.55\n",
      "  Epoch [7/81], Batch [170/176], Train Acc: 69.8966 Loss: 1.1671\n",
      "  Validation Accuracy after Epoch 7: 67.0800\n",
      "  Cidar10.1 Accuracy: 55.0\n",
      "  Epoch [8/81], Batch [170/176], Train Acc: 71.6774 Loss: 1.1944\n",
      "  Validation Accuracy after Epoch 8: 69.3800\n",
      "  Cidar10.1 Accuracy: 56.3\n",
      "  Epoch [9/81], Batch [170/176], Train Acc: 73.5501 Loss: 1.0902\n",
      "  Validation Accuracy after Epoch 9: 71.3600\n",
      "  Cidar10.1 Accuracy: 57.55\n",
      "  Epoch [10/81], Batch [170/176], Train Acc: 74.8736 Loss: 1.1248\n",
      "  Validation Accuracy after Epoch 10: 73.8800\n",
      "  Cidar10.1 Accuracy: 61.3\n",
      "  Epoch [11/81], Batch [170/176], Train Acc: 76.1512 Loss: 1.0703\n",
      "  Validation Accuracy after Epoch 11: 76.1800\n",
      "  Cidar10.1 Accuracy: 63.5\n",
      "  Epoch [12/81], Batch [170/176], Train Acc: 77.2748 Loss: 0.9683\n",
      "  Validation Accuracy after Epoch 12: 76.6600\n",
      "  Cidar10.1 Accuracy: 65.4\n",
      "  Epoch [13/81], Batch [170/176], Train Acc: 77.9481 Loss: 0.9334\n",
      "  Validation Accuracy after Epoch 13: 77.8800\n",
      "  Cidar10.1 Accuracy: 65.1\n",
      "  Epoch [14/81], Batch [170/176], Train Acc: 78.9591 Loss: 1.0149\n",
      "  Validation Accuracy after Epoch 14: 78.5600\n",
      "  Cidar10.1 Accuracy: 66.3\n",
      "  Epoch [15/81], Batch [170/176], Train Acc: 79.8943 Loss: 0.9728\n",
      "  Validation Accuracy after Epoch 15: 77.7000\n",
      "  Cidar10.1 Accuracy: 67.05\n",
      "  Epoch [16/81], Batch [170/176], Train Acc: 80.3424 Loss: 0.9516\n",
      "  Validation Accuracy after Epoch 16: 73.5400\n",
      "  Cidar10.1 Accuracy: 59.3\n",
      "  Epoch [17/81], Batch [170/176], Train Acc: 81.1374 Loss: 0.9818\n",
      "  Validation Accuracy after Epoch 17: 77.1800\n",
      "  Cidar10.1 Accuracy: 65.25\n",
      "  Epoch [18/81], Batch [170/176], Train Acc: 81.7394 Loss: 0.9220\n",
      "  Validation Accuracy after Epoch 18: 77.2800\n",
      "  Cidar10.1 Accuracy: 63.1\n",
      "  Epoch [19/81], Batch [170/176], Train Acc: 82.5689 Loss: 0.9224\n",
      "  Validation Accuracy after Epoch 19: 76.4400\n",
      "  Cidar10.1 Accuracy: 64.35\n",
      "  Epoch [20/81], Batch [170/176], Train Acc: 82.7597 Loss: 1.0234\n",
      "  Validation Accuracy after Epoch 20: 79.1200\n",
      "  Cidar10.1 Accuracy: 64.9\n",
      "  Epoch [21/81], Batch [170/176], Train Acc: 83.4099 Loss: 0.9263\n",
      "  Validation Accuracy after Epoch 21: 80.1400\n",
      "  Cidar10.1 Accuracy: 69.15\n",
      "  Epoch [22/81], Batch [170/176], Train Acc: 84.1475 Loss: 0.8738\n",
      "  Validation Accuracy after Epoch 22: 82.1800\n",
      "  Cidar10.1 Accuracy: 70.2\n",
      "  Epoch [23/81], Batch [170/176], Train Acc: 84.4141 Loss: 0.8880\n",
      "  Validation Accuracy after Epoch 23: 82.0600\n",
      "  Cidar10.1 Accuracy: 70.35\n",
      "  Epoch [24/81], Batch [170/176], Train Acc: 85.0483 Loss: 0.9353\n",
      "  Validation Accuracy after Epoch 24: 84.1400\n",
      "  Cidar10.1 Accuracy: 73.1\n",
      "  Epoch [25/81], Batch [170/176], Train Acc: 85.5492 Loss: 0.8390\n",
      "  Validation Accuracy after Epoch 25: 84.1400\n",
      "  Cidar10.1 Accuracy: 72.15\n",
      "  Epoch [26/81], Batch [170/176], Train Acc: 85.7008 Loss: 0.8839\n",
      "  Validation Accuracy after Epoch 26: 81.7400\n",
      "  Cidar10.1 Accuracy: 70.1\n",
      "  Epoch [27/81], Batch [170/176], Train Acc: 86.0202 Loss: 0.8458\n",
      "  Validation Accuracy after Epoch 27: 83.2800\n",
      "  Cidar10.1 Accuracy: 72.25\n",
      "  Epoch [28/81], Batch [170/176], Train Acc: 86.6475 Loss: 0.9068\n",
      "  Validation Accuracy after Epoch 28: 81.0600\n",
      "  Cidar10.1 Accuracy: 68.6\n",
      "  Epoch [29/81], Batch [170/176], Train Acc: 86.7693 Loss: 0.8473\n",
      "  Validation Accuracy after Epoch 29: 80.2800\n",
      "  Cidar10.1 Accuracy: 68.8\n",
      "  Epoch [30/81], Batch [170/176], Train Acc: 87.3759 Loss: 0.8928\n",
      "  Validation Accuracy after Epoch 30: 78.6400\n",
      "  Cidar10.1 Accuracy: 67.7\n",
      "  Epoch [31/81], Batch [170/176], Train Acc: 87.3782 Loss: 0.8504\n",
      "  Validation Accuracy after Epoch 31: 79.1800\n",
      "  Cidar10.1 Accuracy: 68.0\n",
      "  Epoch [32/81], Batch [170/176], Train Acc: 87.7390 Loss: 0.8583\n",
      "  Validation Accuracy after Epoch 32: 81.7600\n",
      "  Cidar10.1 Accuracy: 68.9\n",
      "  Epoch [33/81], Batch [170/176], Train Acc: 88.3456 Loss: 0.7727\n",
      "  Validation Accuracy after Epoch 33: 85.0000\n",
      "  Cidar10.1 Accuracy: 73.9\n",
      "  Epoch [34/81], Batch [170/176], Train Acc: 88.5754 Loss: 0.8071\n",
      "  Validation Accuracy after Epoch 34: 85.5800\n",
      "  Cidar10.1 Accuracy: 74.5\n",
      "  Epoch [35/81], Batch [170/176], Train Acc: 88.5317 Loss: 0.7860\n",
      "  Validation Accuracy after Epoch 35: 85.8600\n",
      "  Cidar10.1 Accuracy: 73.8\n",
      "  Epoch [36/81], Batch [170/176], Train Acc: 89.3222 Loss: 0.7128\n",
      "  Validation Accuracy after Epoch 36: 86.3800\n",
      "  Cidar10.1 Accuracy: 74.3\n",
      "  Epoch [37/81], Batch [170/176], Train Acc: 89.3015 Loss: 0.8318\n",
      "  Validation Accuracy after Epoch 37: 85.0000\n",
      "  Cidar10.1 Accuracy: 72.45\n",
      "  Epoch [38/81], Batch [170/176], Train Acc: 89.3704 Loss: 0.7338\n",
      "  Validation Accuracy after Epoch 38: 84.7800\n",
      "  Cidar10.1 Accuracy: 73.45\n",
      "  Epoch [39/81], Batch [170/176], Train Acc: 89.7449 Loss: 0.7791\n",
      "  Validation Accuracy after Epoch 39: 82.6600\n",
      "  Cidar10.1 Accuracy: 69.6\n",
      "  Epoch [40/81], Batch [170/176], Train Acc: 90.1241 Loss: 0.8059\n",
      "  Validation Accuracy after Epoch 40: 84.3000\n",
      "  Cidar10.1 Accuracy: 73.55\n",
      "  Epoch [41/81], Batch [170/176], Train Acc: 90.0850 Loss: 0.8295\n",
      "  Validation Accuracy after Epoch 41: 84.3000\n",
      "  Cidar10.1 Accuracy: 73.4\n",
      "  Epoch [42/81], Batch [170/176], Train Acc: 90.5813 Loss: 0.7960\n",
      "  Validation Accuracy after Epoch 42: 84.4400\n",
      "  Cidar10.1 Accuracy: 73.65\n",
      "  Epoch [43/81], Batch [170/176], Train Acc: 90.9789 Loss: 0.7627\n",
      "  Validation Accuracy after Epoch 43: 83.2800\n",
      "  Cidar10.1 Accuracy: 72.25\n",
      "  Epoch [44/81], Batch [170/176], Train Acc: 91.0294 Loss: 0.8150\n",
      "  Validation Accuracy after Epoch 44: 85.9400\n",
      "  Cidar10.1 Accuracy: 75.0\n",
      "  Epoch [45/81], Batch [170/176], Train Acc: 91.4384 Loss: 0.7331\n",
      "  Validation Accuracy after Epoch 45: 86.7000\n",
      "  Cidar10.1 Accuracy: 75.85\n",
      "  Epoch [46/81], Batch [170/176], Train Acc: 91.6131 Loss: 0.7285\n",
      "  Validation Accuracy after Epoch 46: 86.6800\n",
      "  Cidar10.1 Accuracy: 75.35\n",
      "  Epoch [47/81], Batch [170/176], Train Acc: 91.8911 Loss: 0.7056\n",
      "  Validation Accuracy after Epoch 47: 87.4200\n",
      "  Cidar10.1 Accuracy: 77.6\n",
      "  Epoch [48/81], Batch [170/176], Train Acc: 91.8566 Loss: 0.6595\n",
      "  Validation Accuracy after Epoch 48: 88.0400\n",
      "  Cidar10.1 Accuracy: 77.55\n",
      "  Epoch [49/81], Batch [170/176], Train Acc: 92.0565 Loss: 0.6960\n",
      "  Validation Accuracy after Epoch 49: 86.9600\n",
      "  Cidar10.1 Accuracy: 75.1\n",
      "  Epoch [50/81], Batch [170/176], Train Acc: 92.2472 Loss: 0.6972\n",
      "  Validation Accuracy after Epoch 50: 86.4800\n",
      "  Cidar10.1 Accuracy: 74.25\n",
      "  Epoch [51/81], Batch [170/176], Train Acc: 92.2886 Loss: 0.7481\n",
      "  Validation Accuracy after Epoch 51: 83.7000\n",
      "  Cidar10.1 Accuracy: 69.35\n",
      "  Epoch [52/81], Batch [170/176], Train Acc: 92.4242 Loss: 0.7258\n",
      "  Validation Accuracy after Epoch 52: 84.6800\n",
      "  Cidar10.1 Accuracy: 73.8\n",
      "  Epoch [53/81], Batch [170/176], Train Acc: 92.8079 Loss: 0.7034\n",
      "  Validation Accuracy after Epoch 53: 87.5000\n",
      "  Cidar10.1 Accuracy: 76.75\n",
      "  Epoch [54/81], Batch [170/176], Train Acc: 92.8608 Loss: 0.6726\n",
      "  Validation Accuracy after Epoch 54: 85.1400\n",
      "  Cidar10.1 Accuracy: 73.35\n",
      "  Epoch [55/81], Batch [170/176], Train Acc: 93.2146 Loss: 0.7286\n",
      "  Validation Accuracy after Epoch 55: 86.2600\n",
      "  Cidar10.1 Accuracy: 74.95\n",
      "  Epoch [56/81], Batch [170/176], Train Acc: 93.1824 Loss: 0.6829\n",
      "  Validation Accuracy after Epoch 56: 86.7600\n",
      "  Cidar10.1 Accuracy: 76.75\n",
      "  Epoch [57/81], Batch [170/176], Train Acc: 93.4720 Loss: 0.7112\n",
      "  Validation Accuracy after Epoch 57: 88.2200\n",
      "  Cidar10.1 Accuracy: 78.3\n",
      "  Epoch [58/81], Batch [170/176], Train Acc: 93.5087 Loss: 0.6867\n",
      "  Validation Accuracy after Epoch 58: 88.2000\n",
      "  Cidar10.1 Accuracy: 77.6\n",
      "  Epoch [59/81], Batch [170/176], Train Acc: 93.8626 Loss: 0.6890\n",
      "  Validation Accuracy after Epoch 59: 88.0400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:04:58,595] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=7\n",
      "num_epochs: 89\n",
      "model_type: smallresnet\n",
      "batch_size: 256\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.8859498453506164\n",
      "beta2: 0.9967813605196271\n",
      "lr: 1.0059573326543053e-05\n",
      "weight_decay: 0.04875703995157717\n",
      "factor: 0.12647946217796507\n",
      "patience: 19\n",
      "threshold: 0.06502352547749993\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/89], Batch [170/176], Train Acc: 13.9614 Loss: 2.2219\n",
      "  Validation Accuracy after Epoch 1: 19.6000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:05:10,136] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=8\n",
      "num_epochs: 92\n",
      "model_type: base\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8597063166954072\n",
      "beta2: 0.9963855278011335\n",
      "lr: 0.008386110732810157\n",
      "weight_decay: 0.0006982151077958207\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/92], Batch [350/352], Train Acc: 30.1473 Loss: 1.8962\n",
      "  Validation Accuracy after Epoch 1: 32.2600\n",
      "  Cidar10.1 Accuracy: 29.9\n",
      "  Epoch [2/92], Batch [350/352], Train Acc: 44.7366 Loss: 1.5528\n",
      "  Validation Accuracy after Epoch 2: 49.9600\n",
      "  Cidar10.1 Accuracy: 41.45\n",
      "  Epoch [3/92], Batch [350/352], Train Acc: 51.6808 Loss: 1.4989\n",
      "  Validation Accuracy after Epoch 3: 53.7200\n",
      "  Cidar10.1 Accuracy: 42.15\n",
      "  Epoch [4/92], Batch [350/352], Train Acc: 54.7879 Loss: 1.4957\n",
      "  Validation Accuracy after Epoch 4: 56.0000\n",
      "  Cidar10.1 Accuracy: 44.0\n",
      "  Epoch [5/92], Batch [350/352], Train Acc: 56.1384 Loss: 1.4127\n",
      "  Validation Accuracy after Epoch 5: 53.3400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:05:59,909] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=9\n",
      "num_epochs: 114\n",
      "model_type: efficientnet\n",
      "batch_size: 256\n",
      "optimizer_type: SGD\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "lr: 0.0052294740757562914\n",
      "momentum: 0.80681824073355\n",
      "weight_decay: 0.00011864881536734163\n",
      "factor: 0.1520927056129971\n",
      "patience: 18\n",
      "threshold: 0.07781767567531292\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/114], Batch [170/176], Train Acc: 19.3796 Loss: 2.0004\n",
      "  Validation Accuracy after Epoch 1: 28.4200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:06:12,235] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=10\n",
      "num_epochs: 57\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9128690632714375\n",
      "beta2: 0.9930747172712939\n",
      "lr: 0.00014377927960525607\n",
      "weight_decay: 0.0045845774091663625\n",
      "max_lr: 0.009086002505118474\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/57], Batch [80/88], Train Acc: 36.2842 Loss: 1.7012\n",
      "  Validation Accuracy after Epoch 1: 45.1200\n",
      "  Cidar10.1 Accuracy: 38.35\n",
      "  Epoch [2/57], Batch [80/88], Train Acc: 51.9385 Loss: 1.4978\n",
      "  Validation Accuracy after Epoch 2: 50.7800\n",
      "  Cidar10.1 Accuracy: 46.05\n",
      "  Epoch [3/57], Batch [80/88], Train Acc: 61.5894 Loss: 1.3164\n",
      "  Validation Accuracy after Epoch 3: 63.5200\n",
      "  Cidar10.1 Accuracy: 52.1\n",
      "  Epoch [4/57], Batch [80/88], Train Acc: 66.5186 Loss: 1.2203\n",
      "  Validation Accuracy after Epoch 4: 67.5800\n",
      "  Cidar10.1 Accuracy: 55.55\n",
      "  Epoch [5/57], Batch [80/88], Train Acc: 70.8447 Loss: 1.0925\n",
      "  Validation Accuracy after Epoch 5: 70.5000\n",
      "  Cidar10.1 Accuracy: 60.25\n",
      "  Epoch [6/57], Batch [80/88], Train Acc: 73.0396 Loss: 1.1677\n",
      "  Validation Accuracy after Epoch 6: 65.5600\n",
      "  Cidar10.1 Accuracy: 52.8\n",
      "  Epoch [7/57], Batch [80/88], Train Acc: 75.8691 Loss: 1.0539\n",
      "  Validation Accuracy after Epoch 7: 65.4400\n",
      "  Cidar10.1 Accuracy: 53.6\n",
      "  Epoch [8/57], Batch [80/88], Train Acc: 77.6978 Loss: 1.0322\n",
      "  Validation Accuracy after Epoch 8: 72.0400\n",
      "  Cidar10.1 Accuracy: 60.15\n",
      "  Epoch [9/57], Batch [80/88], Train Acc: 79.1089 Loss: 0.9879\n",
      "  Validation Accuracy after Epoch 9: 69.3200\n",
      "  Cidar10.1 Accuracy: 55.7\n",
      "  Epoch [10/57], Batch [80/88], Train Acc: 80.6299 Loss: 1.0236\n",
      "  Validation Accuracy after Epoch 10: 76.2200\n",
      "  Cidar10.1 Accuracy: 62.7\n",
      "  Epoch [11/57], Batch [80/88], Train Acc: 81.7407 Loss: 0.9495\n",
      "  Validation Accuracy after Epoch 11: 73.5000\n",
      "  Cidar10.1 Accuracy: 60.2\n",
      "  Epoch [12/57], Batch [80/88], Train Acc: 82.9858 Loss: 0.8592\n",
      "  Validation Accuracy after Epoch 12: 77.2200\n",
      "  Cidar10.1 Accuracy: 61.35\n",
      "  Epoch [13/57], Batch [80/88], Train Acc: 83.7305 Loss: 0.9397\n",
      "  Validation Accuracy after Epoch 13: 80.2200\n",
      "  Cidar10.1 Accuracy: 69.95\n",
      "  Epoch [14/57], Batch [80/88], Train Acc: 84.6631 Loss: 0.8808\n",
      "  Validation Accuracy after Epoch 14: 81.5200\n",
      "  Cidar10.1 Accuracy: 72.8\n",
      "  Epoch [15/57], Batch [80/88], Train Acc: 85.4199 Loss: 0.9083\n",
      "  Validation Accuracy after Epoch 15: 79.5800\n",
      "  Cidar10.1 Accuracy: 68.6\n",
      "  Epoch [16/57], Batch [80/88], Train Acc: 86.2427 Loss: 0.8705\n",
      "  Validation Accuracy after Epoch 16: 83.1000\n",
      "  Cidar10.1 Accuracy: 73.55\n",
      "  Epoch [17/57], Batch [80/88], Train Acc: 87.1875 Loss: 0.7912\n",
      "  Validation Accuracy after Epoch 17: 79.7600\n",
      "  Cidar10.1 Accuracy: 69.65\n",
      "  Epoch [18/57], Batch [80/88], Train Acc: 87.5708 Loss: 0.8145\n",
      "  Validation Accuracy after Epoch 18: 85.3400\n",
      "  Cidar10.1 Accuracy: 76.25\n",
      "  Epoch [19/57], Batch [80/88], Train Acc: 88.5059 Loss: 0.8148\n",
      "  Validation Accuracy after Epoch 19: 83.7000\n",
      "  Cidar10.1 Accuracy: 70.95\n",
      "  Epoch [20/57], Batch [80/88], Train Acc: 88.8232 Loss: 0.7893\n",
      "  Validation Accuracy after Epoch 20: 84.2000\n",
      "  Cidar10.1 Accuracy: 73.7\n",
      "  Epoch [21/57], Batch [80/88], Train Acc: 89.3823 Loss: 0.7456\n",
      "  Validation Accuracy after Epoch 21: 86.9000\n",
      "  Cidar10.1 Accuracy: 76.6\n",
      "  Epoch [22/57], Batch [80/88], Train Acc: 90.3296 Loss: 0.7455\n",
      "  Validation Accuracy after Epoch 22: 87.2800\n",
      "  Cidar10.1 Accuracy: 78.1\n",
      "  Epoch [23/57], Batch [80/88], Train Acc: 90.7812 Loss: 0.7529\n",
      "  Validation Accuracy after Epoch 23: 87.8200\n",
      "  Cidar10.1 Accuracy: 79.8\n",
      "  Epoch [24/57], Batch [80/88], Train Acc: 91.1035 Loss: 0.7773\n",
      "  Validation Accuracy after Epoch 24: 87.8200\n",
      "  Cidar10.1 Accuracy: 79.0\n",
      "  Epoch [25/57], Batch [80/88], Train Acc: 91.7725 Loss: 0.7247\n",
      "  Validation Accuracy after Epoch 25: 89.1000\n",
      "  Cidar10.1 Accuracy: 78.55\n",
      "  Epoch [26/57], Batch [80/88], Train Acc: 92.0996 Loss: 0.6874\n",
      "  Validation Accuracy after Epoch 26: 87.8400\n",
      "  Cidar10.1 Accuracy: 78.55\n",
      "  Epoch [27/57], Batch [80/88], Train Acc: 92.5586 Loss: 0.7170\n",
      "  Validation Accuracy after Epoch 27: 88.7200\n",
      "  Cidar10.1 Accuracy: 80.7\n",
      "  Epoch [28/57], Batch [80/88], Train Acc: 92.9419 Loss: 0.6979\n",
      "  Validation Accuracy after Epoch 28: 89.5600\n",
      "  Cidar10.1 Accuracy: 80.15\n",
      "  Epoch [29/57], Batch [80/88], Train Acc: 93.4155 Loss: 0.6847\n",
      "  Validation Accuracy after Epoch 29: 88.4400\n",
      "  Cidar10.1 Accuracy: 79.35\n",
      "  Epoch [30/57], Batch [80/88], Train Acc: 93.7622 Loss: 0.6490\n",
      "  Validation Accuracy after Epoch 30: 89.4400\n",
      "  Cidar10.1 Accuracy: 82.25\n",
      "  Epoch [31/57], Batch [80/88], Train Acc: 94.1064 Loss: 0.6615\n",
      "  Validation Accuracy after Epoch 31: 90.1400\n",
      "  Cidar10.1 Accuracy: 82.35\n",
      "  Epoch [32/57], Batch [80/88], Train Acc: 94.5972 Loss: 0.6701\n",
      "  Validation Accuracy after Epoch 32: 89.5800\n",
      "  Cidar10.1 Accuracy: 80.7\n",
      "  Epoch [33/57], Batch [80/88], Train Acc: 94.8218 Loss: 0.6442\n",
      "  Validation Accuracy after Epoch 33: 90.4400\n",
      "  Cidar10.1 Accuracy: 82.75\n",
      "  Epoch [34/57], Batch [80/88], Train Acc: 95.1904 Loss: 0.6539\n",
      "  Validation Accuracy after Epoch 34: 90.6400\n",
      "  Cidar10.1 Accuracy: 82.05\n",
      "  Epoch [35/57], Batch [80/88], Train Acc: 95.4907 Loss: 0.6419\n",
      "  Validation Accuracy after Epoch 35: 91.0200\n",
      "  Cidar10.1 Accuracy: 82.7\n",
      "  Epoch [36/57], Batch [80/88], Train Acc: 95.8472 Loss: 0.6114\n",
      "  Validation Accuracy after Epoch 36: 91.0200\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [37/57], Batch [80/88], Train Acc: 96.1768 Loss: 0.6041\n",
      "  Validation Accuracy after Epoch 37: 91.4600\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [38/57], Batch [80/88], Train Acc: 96.4746 Loss: 0.6178\n",
      "  Validation Accuracy after Epoch 38: 91.3600\n",
      "  Cidar10.1 Accuracy: 83.4\n",
      "  Epoch [39/57], Batch [80/88], Train Acc: 96.8433 Loss: 0.6189\n",
      "  Validation Accuracy after Epoch 39: 91.4800\n",
      "  Cidar10.1 Accuracy: 84.05\n",
      "  Epoch [40/57], Batch [80/88], Train Acc: 97.1680 Loss: 0.6006\n",
      "  Validation Accuracy after Epoch 40: 91.7000\n",
      "  Cidar10.1 Accuracy: 84.3\n",
      "  Epoch [41/57], Batch [80/88], Train Acc: 97.1313 Loss: 0.5935\n",
      "  Validation Accuracy after Epoch 41: 91.4000\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [42/57], Batch [80/88], Train Acc: 97.6050 Loss: 0.5948\n",
      "  Validation Accuracy after Epoch 42: 91.8800\n",
      "  Cidar10.1 Accuracy: 84.5\n",
      "  Epoch [43/57], Batch [80/88], Train Acc: 97.7588 Loss: 0.5954\n",
      "  Validation Accuracy after Epoch 43: 92.0600\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [44/57], Batch [80/88], Train Acc: 97.9980 Loss: 0.5888\n",
      "  Validation Accuracy after Epoch 44: 92.4200\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [45/57], Batch [80/88], Train Acc: 98.0981 Loss: 0.5766\n",
      "  Validation Accuracy after Epoch 45: 92.2000\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [46/57], Batch [80/88], Train Acc: 98.3179 Loss: 0.5571\n",
      "  Validation Accuracy after Epoch 46: 92.3800\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [47/57], Batch [80/88], Train Acc: 98.5083 Loss: 0.5761\n",
      "  Validation Accuracy after Epoch 47: 92.3600\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [48/57], Batch [80/88], Train Acc: 98.5889 Loss: 0.5834\n",
      "  Validation Accuracy after Epoch 48: 92.6400\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [49/57], Batch [80/88], Train Acc: 98.6646 Loss: 0.5659\n",
      "  Validation Accuracy after Epoch 49: 92.3200\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [50/57], Batch [80/88], Train Acc: 98.7524 Loss: 0.5750\n",
      "  Validation Accuracy after Epoch 50: 92.9200\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [51/57], Batch [80/88], Train Acc: 98.8306 Loss: 0.5622\n",
      "  Validation Accuracy after Epoch 51: 92.5200\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [52/57], Batch [80/88], Train Acc: 98.8574 Loss: 0.5531\n",
      "  Validation Accuracy after Epoch 52: 93.1800\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [53/57], Batch [80/88], Train Acc: 98.8281 Loss: 0.5663\n",
      "  Validation Accuracy after Epoch 53: 93.2400\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [54/57], Batch [80/88], Train Acc: 98.9258 Loss: 0.5490\n",
      "  Validation Accuracy after Epoch 54: 92.9000\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [55/57], Batch [80/88], Train Acc: 99.0210 Loss: 0.5571\n",
      "  Validation Accuracy after Epoch 55: 92.4800\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [56/57], Batch [80/88], Train Acc: 98.9844 Loss: 0.5528\n",
      "  Validation Accuracy after Epoch 56: 92.7000\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [57/57], Batch [80/88], Train Acc: 99.0503 Loss: 0.5561\n",
      "  Validation Accuracy after Epoch 57: 92.8000\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "Trial 10 complete. Best Validation Accuracy: 93.2400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:15:23,487] Trial 10 finished with value: 93.24 and parameters: {'num_epochs': 57, 'model_type': 'base', 'batch_size': 512, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.9128690632714375, 'beta2': 0.9930747172712939, 'lr': 0.00014377927960525607, 'weight_decay': 0.0045845774091663625, 'max_lr': 0.009086002505118474}. Best is trial 5 with value: 93.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=11\n",
      "num_epochs: 51\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.912756498839181\n",
      "beta2: 0.9928518894897843\n",
      "lr: 0.00012490446662229772\n",
      "weight_decay: 0.004260164450297314\n",
      "max_lr: 0.009923399724315335\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/51], Batch [80/88], Train Acc: 36.4868 Loss: 1.6885\n",
      "  Validation Accuracy after Epoch 1: 42.2000\n",
      "  Cidar10.1 Accuracy: 35.65\n",
      "  Epoch [2/51], Batch [80/88], Train Acc: 52.7905 Loss: 1.4218\n",
      "  Validation Accuracy after Epoch 2: 55.7600\n",
      "  Cidar10.1 Accuracy: 43.35\n",
      "  Epoch [3/51], Batch [80/88], Train Acc: 61.3965 Loss: 1.2951\n",
      "  Validation Accuracy after Epoch 3: 64.1800\n",
      "  Cidar10.1 Accuracy: 52.3\n",
      "  Epoch [4/51], Batch [80/88], Train Acc: 66.8823 Loss: 1.2550\n",
      "  Validation Accuracy after Epoch 4: 61.7400\n",
      "  Cidar10.1 Accuracy: 51.35\n",
      "  Epoch [5/51], Batch [80/88], Train Acc: 70.5615 Loss: 1.1575\n",
      "  Validation Accuracy after Epoch 5: 74.1400\n",
      "  Cidar10.1 Accuracy: 62.0\n",
      "  Epoch [6/51], Batch [80/88], Train Acc: 73.8965 Loss: 1.0270\n",
      "  Validation Accuracy after Epoch 6: 75.4200\n",
      "  Cidar10.1 Accuracy: 63.2\n",
      "  Epoch [7/51], Batch [80/88], Train Acc: 76.4209 Loss: 1.0535\n",
      "  Validation Accuracy after Epoch 7: 69.6200\n",
      "  Cidar10.1 Accuracy: 54.95\n",
      "  Epoch [8/51], Batch [80/88], Train Acc: 77.9150 Loss: 1.0248\n",
      "  Validation Accuracy after Epoch 8: 75.6400\n",
      "  Cidar10.1 Accuracy: 61.5\n",
      "  Epoch [9/51], Batch [80/88], Train Acc: 79.7925 Loss: 1.0137\n",
      "  Validation Accuracy after Epoch 9: 77.7400\n",
      "  Cidar10.1 Accuracy: 66.15\n",
      "  Epoch [10/51], Batch [80/88], Train Acc: 81.2646 Loss: 0.8955\n",
      "  Validation Accuracy after Epoch 10: 72.2800\n",
      "  Cidar10.1 Accuracy: 57.7\n",
      "  Epoch [11/51], Batch [80/88], Train Acc: 81.8652 Loss: 0.9248\n",
      "  Validation Accuracy after Epoch 11: 80.9400\n",
      "  Cidar10.1 Accuracy: 69.5\n",
      "  Epoch [12/51], Batch [80/88], Train Acc: 83.6768 Loss: 0.9158\n",
      "  Validation Accuracy after Epoch 12: 80.2200\n",
      "  Cidar10.1 Accuracy: 68.4\n",
      "  Epoch [13/51], Batch [80/88], Train Acc: 84.2261 Loss: 0.8960\n",
      "  Validation Accuracy after Epoch 13: 82.4400\n",
      "  Cidar10.1 Accuracy: 74.3\n",
      "  Epoch [14/51], Batch [80/88], Train Acc: 85.4810 Loss: 0.8516\n",
      "  Validation Accuracy after Epoch 14: 81.7600\n",
      "  Cidar10.1 Accuracy: 74.0\n",
      "  Epoch [15/51], Batch [80/88], Train Acc: 85.9229 Loss: 0.8363\n",
      "  Validation Accuracy after Epoch 15: 82.5200\n",
      "  Cidar10.1 Accuracy: 72.2\n",
      "  Epoch [16/51], Batch [80/88], Train Acc: 86.5625 Loss: 0.8475\n",
      "  Validation Accuracy after Epoch 16: 83.2200\n",
      "  Cidar10.1 Accuracy: 75.6\n",
      "  Epoch [17/51], Batch [80/88], Train Acc: 87.7734 Loss: 0.8127\n",
      "  Validation Accuracy after Epoch 17: 83.9800\n",
      "  Cidar10.1 Accuracy: 76.3\n",
      "  Epoch [18/51], Batch [80/88], Train Acc: 88.2422 Loss: 0.7965\n",
      "  Validation Accuracy after Epoch 18: 83.0000\n",
      "  Cidar10.1 Accuracy: 73.15\n",
      "  Epoch [19/51], Batch [80/88], Train Acc: 88.7793 Loss: 0.7930\n",
      "  Validation Accuracy after Epoch 19: 87.2800\n",
      "  Cidar10.1 Accuracy: 77.75\n",
      "  Epoch [20/51], Batch [80/88], Train Acc: 89.2163 Loss: 0.7834\n",
      "  Validation Accuracy after Epoch 20: 87.1000\n",
      "  Cidar10.1 Accuracy: 78.95\n",
      "  Epoch [21/51], Batch [80/88], Train Acc: 90.3809 Loss: 0.7580\n",
      "  Validation Accuracy after Epoch 21: 85.0200\n",
      "  Cidar10.1 Accuracy: 74.7\n",
      "  Epoch [22/51], Batch [80/88], Train Acc: 90.6396 Loss: 0.7881\n",
      "  Validation Accuracy after Epoch 22: 86.3000\n",
      "  Cidar10.1 Accuracy: 77.1\n",
      "  Epoch [23/51], Batch [80/88], Train Acc: 90.9570 Loss: 0.7411\n",
      "  Validation Accuracy after Epoch 23: 87.0200\n",
      "  Cidar10.1 Accuracy: 80.6\n",
      "  Epoch [24/51], Batch [80/88], Train Acc: 91.6992 Loss: 0.7120\n",
      "  Validation Accuracy after Epoch 24: 87.7200\n",
      "  Cidar10.1 Accuracy: 80.6\n",
      "  Epoch [25/51], Batch [80/88], Train Acc: 92.2607 Loss: 0.7778\n",
      "  Validation Accuracy after Epoch 25: 88.8800\n",
      "  Cidar10.1 Accuracy: 79.95\n",
      "  Epoch [26/51], Batch [80/88], Train Acc: 92.6685 Loss: 0.7264\n",
      "  Validation Accuracy after Epoch 26: 89.1000\n",
      "  Cidar10.1 Accuracy: 80.05\n",
      "  Epoch [27/51], Batch [80/88], Train Acc: 93.1104 Loss: 0.6986\n",
      "  Validation Accuracy after Epoch 27: 89.1800\n",
      "  Cidar10.1 Accuracy: 82.9\n",
      "  Epoch [28/51], Batch [80/88], Train Acc: 93.8281 Loss: 0.6896\n",
      "  Validation Accuracy after Epoch 28: 89.0600\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [29/51], Batch [80/88], Train Acc: 94.0381 Loss: 0.7114\n",
      "  Validation Accuracy after Epoch 29: 90.3200\n",
      "  Cidar10.1 Accuracy: 83.1\n",
      "  Epoch [30/51], Batch [80/88], Train Acc: 94.5361 Loss: 0.6632\n",
      "  Validation Accuracy after Epoch 30: 90.3800\n",
      "  Cidar10.1 Accuracy: 82.9\n",
      "  Epoch [31/51], Batch [80/88], Train Acc: 94.8535 Loss: 0.6592\n",
      "  Validation Accuracy after Epoch 31: 89.6600\n",
      "  Cidar10.1 Accuracy: 81.3\n",
      "  Epoch [32/51], Batch [80/88], Train Acc: 95.3442 Loss: 0.6602\n",
      "  Validation Accuracy after Epoch 32: 90.8200\n",
      "  Cidar10.1 Accuracy: 82.9\n",
      "  Epoch [33/51], Batch [80/88], Train Acc: 95.4004 Loss: 0.6618\n",
      "  Validation Accuracy after Epoch 33: 90.8200\n",
      "  Cidar10.1 Accuracy: 82.15\n",
      "  Epoch [34/51], Batch [80/88], Train Acc: 95.8789 Loss: 0.6139\n",
      "  Validation Accuracy after Epoch 34: 91.3400\n",
      "  Cidar10.1 Accuracy: 84.9\n",
      "  Epoch [35/51], Batch [80/88], Train Acc: 96.3501 Loss: 0.5865\n",
      "  Validation Accuracy after Epoch 35: 91.6400\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [36/51], Batch [80/88], Train Acc: 96.6528 Loss: 0.6039\n",
      "  Validation Accuracy after Epoch 36: 91.3000\n",
      "  Cidar10.1 Accuracy: 84.6\n",
      "  Epoch [37/51], Batch [80/88], Train Acc: 96.7261 Loss: 0.6024\n",
      "  Validation Accuracy after Epoch 37: 91.5600\n",
      "  Cidar10.1 Accuracy: 84.95\n",
      "  Epoch [38/51], Batch [80/88], Train Acc: 97.1704 Loss: 0.6085\n",
      "  Validation Accuracy after Epoch 38: 91.6200\n",
      "  Cidar10.1 Accuracy: 83.95\n",
      "  Epoch [39/51], Batch [80/88], Train Acc: 97.4780 Loss: 0.6000\n",
      "  Validation Accuracy after Epoch 39: 92.0200\n",
      "  Cidar10.1 Accuracy: 84.3\n",
      "  Epoch [40/51], Batch [80/88], Train Acc: 97.5977 Loss: 0.5865\n",
      "  Validation Accuracy after Epoch 40: 91.6600\n",
      "  Cidar10.1 Accuracy: 84.9\n",
      "  Epoch [41/51], Batch [80/88], Train Acc: 97.9248 Loss: 0.6061\n",
      "  Validation Accuracy after Epoch 41: 92.2400\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [42/51], Batch [80/88], Train Acc: 98.1006 Loss: 0.5867\n",
      "  Validation Accuracy after Epoch 42: 91.8600\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [43/51], Batch [80/88], Train Acc: 98.1934 Loss: 0.5695\n",
      "  Validation Accuracy after Epoch 43: 92.3000\n",
      "  Cidar10.1 Accuracy: 84.95\n",
      "  Epoch [44/51], Batch [80/88], Train Acc: 98.3325 Loss: 0.5690\n",
      "  Validation Accuracy after Epoch 44: 92.4600\n",
      "  Cidar10.1 Accuracy: 85.5\n",
      "  Epoch [45/51], Batch [80/88], Train Acc: 98.4448 Loss: 0.5641\n",
      "  Validation Accuracy after Epoch 45: 92.1400\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [46/51], Batch [80/88], Train Acc: 98.4448 Loss: 0.5748\n",
      "  Validation Accuracy after Epoch 46: 92.3400\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [47/51], Batch [80/88], Train Acc: 98.6499 Loss: 0.5800\n",
      "  Validation Accuracy after Epoch 47: 92.3200\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [48/51], Batch [80/88], Train Acc: 98.6963 Loss: 0.5541\n",
      "  Validation Accuracy after Epoch 48: 92.3600\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [49/51], Batch [80/88], Train Acc: 98.7207 Loss: 0.5639\n",
      "  Validation Accuracy after Epoch 49: 92.4800\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "  Epoch [50/51], Batch [80/88], Train Acc: 98.6987 Loss: 0.5685\n",
      "  Validation Accuracy after Epoch 50: 92.0600\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [51/51], Batch [80/88], Train Acc: 98.7842 Loss: 0.5650\n",
      "  Validation Accuracy after Epoch 51: 92.6400\n",
      "  Cidar10.1 Accuracy: 85.5\n",
      "Trial 11 complete. Best Validation Accuracy: 92.6400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:23:36,742] Trial 11 finished with value: 92.64 and parameters: {'num_epochs': 51, 'model_type': 'base', 'batch_size': 512, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.912756498839181, 'beta2': 0.9928518894897843, 'lr': 0.00012490446662229772, 'weight_decay': 0.004260164450297314, 'max_lr': 0.009923399724315335}. Best is trial 5 with value: 93.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=12\n",
      "num_epochs: 59\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9030418653359881\n",
      "beta2: 0.9931820503572736\n",
      "lr: 0.00014374931533466727\n",
      "weight_decay: 0.0033257058352376477\n",
      "max_lr: 0.00962143667834775\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/59], Batch [80/88], Train Acc: 36.3232 Loss: 1.6782\n",
      "  Validation Accuracy after Epoch 1: 44.0600\n",
      "  Cidar10.1 Accuracy: 36.5\n",
      "  Epoch [2/59], Batch [80/88], Train Acc: 52.3633 Loss: 1.4337\n",
      "  Validation Accuracy after Epoch 2: 57.7200\n",
      "  Cidar10.1 Accuracy: 46.7\n",
      "  Epoch [3/59], Batch [80/88], Train Acc: 61.3428 Loss: 1.3655\n",
      "  Validation Accuracy after Epoch 3: 51.0000\n",
      "  Cidar10.1 Accuracy: 43.4\n",
      "  Epoch [4/59], Batch [80/88], Train Acc: 66.4478 Loss: 1.1959\n",
      "  Validation Accuracy after Epoch 4: 60.0200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:24:17,062] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=13\n",
      "num_epochs: 69\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9329524789313232\n",
      "beta2: 0.9946991943427499\n",
      "lr: 0.0003926871765026719\n",
      "weight_decay: 0.0034737743539454947\n",
      "max_lr: 0.007444671068341157\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/69], Batch [80/88], Train Acc: 35.8521 Loss: 1.7002\n",
      "  Validation Accuracy after Epoch 1: 46.7400\n",
      "  Cidar10.1 Accuracy: 37.6\n",
      "  Epoch [2/69], Batch [80/88], Train Acc: 50.8984 Loss: 1.4651\n",
      "  Validation Accuracy after Epoch 2: 51.7800\n",
      "  Cidar10.1 Accuracy: 40.9\n",
      "  Epoch [3/69], Batch [80/88], Train Acc: 60.2246 Loss: 1.3522\n",
      "  Validation Accuracy after Epoch 3: 61.0200\n",
      "  Cidar10.1 Accuracy: 51.15\n",
      "  Epoch [4/69], Batch [80/88], Train Acc: 65.5469 Loss: 1.2422\n",
      "  Validation Accuracy after Epoch 4: 67.4200\n",
      "  Cidar10.1 Accuracy: 53.7\n",
      "  Epoch [5/69], Batch [80/88], Train Acc: 68.8452 Loss: 1.1366\n",
      "  Validation Accuracy after Epoch 5: 68.9600\n",
      "  Cidar10.1 Accuracy: 59.7\n",
      "  Epoch [6/69], Batch [80/88], Train Acc: 72.5391 Loss: 1.1504\n",
      "  Validation Accuracy after Epoch 6: 67.1000\n",
      "  Cidar10.1 Accuracy: 54.6\n",
      "  Epoch [7/69], Batch [80/88], Train Acc: 74.9902 Loss: 1.0869\n",
      "  Validation Accuracy after Epoch 7: 70.0400\n",
      "  Cidar10.1 Accuracy: 57.8\n",
      "  Epoch [8/69], Batch [80/88], Train Acc: 77.0557 Loss: 1.0113\n",
      "  Validation Accuracy after Epoch 8: 75.8200\n",
      "  Cidar10.1 Accuracy: 64.05\n",
      "  Epoch [9/69], Batch [80/88], Train Acc: 78.5864 Loss: 1.0427\n",
      "  Validation Accuracy after Epoch 9: 79.0400\n",
      "  Cidar10.1 Accuracy: 67.55\n",
      "  Epoch [10/69], Batch [80/88], Train Acc: 79.6118 Loss: 1.0423\n",
      "  Validation Accuracy after Epoch 10: 76.2200\n",
      "  Cidar10.1 Accuracy: 63.6\n",
      "  Epoch [11/69], Batch [80/88], Train Acc: 80.8569 Loss: 0.8863\n",
      "  Validation Accuracy after Epoch 11: 77.2200\n",
      "  Cidar10.1 Accuracy: 67.25\n",
      "  Epoch [12/69], Batch [80/88], Train Acc: 82.2314 Loss: 0.8815\n",
      "  Validation Accuracy after Epoch 12: 77.3600\n",
      "  Cidar10.1 Accuracy: 66.7\n",
      "  Epoch [13/69], Batch [80/88], Train Acc: 83.3276 Loss: 0.9128\n",
      "  Validation Accuracy after Epoch 13: 81.9600\n",
      "  Cidar10.1 Accuracy: 70.25\n",
      "  Epoch [14/69], Batch [80/88], Train Acc: 83.8623 Loss: 0.9312\n",
      "  Validation Accuracy after Epoch 14: 81.2000\n",
      "  Cidar10.1 Accuracy: 71.15\n",
      "  Epoch [15/69], Batch [80/88], Train Acc: 84.7217 Loss: 0.8839\n",
      "  Validation Accuracy after Epoch 15: 81.0600\n",
      "  Cidar10.1 Accuracy: 71.0\n",
      "  Epoch [16/69], Batch [80/88], Train Acc: 85.8057 Loss: 0.8636\n",
      "  Validation Accuracy after Epoch 16: 82.6800\n",
      "  Cidar10.1 Accuracy: 71.45\n",
      "  Epoch [17/69], Batch [80/88], Train Acc: 86.0449 Loss: 0.8869\n",
      "  Validation Accuracy after Epoch 17: 83.6200\n",
      "  Cidar10.1 Accuracy: 73.85\n",
      "  Epoch [18/69], Batch [80/88], Train Acc: 87.1191 Loss: 0.8204\n",
      "  Validation Accuracy after Epoch 18: 82.5000\n",
      "  Cidar10.1 Accuracy: 68.7\n",
      "  Epoch [19/69], Batch [80/88], Train Acc: 87.3364 Loss: 0.8498\n",
      "  Validation Accuracy after Epoch 19: 84.8000\n",
      "  Cidar10.1 Accuracy: 72.85\n",
      "  Epoch [20/69], Batch [80/88], Train Acc: 87.9492 Loss: 0.7995\n",
      "  Validation Accuracy after Epoch 20: 83.1600\n",
      "  Cidar10.1 Accuracy: 70.45\n",
      "  Epoch [21/69], Batch [80/88], Train Acc: 88.5718 Loss: 0.7606\n",
      "  Validation Accuracy after Epoch 21: 85.6000\n",
      "  Cidar10.1 Accuracy: 78.2\n",
      "  Epoch [22/69], Batch [80/88], Train Acc: 89.4775 Loss: 0.7432\n",
      "  Validation Accuracy after Epoch 22: 86.2800\n",
      "  Cidar10.1 Accuracy: 78.0\n",
      "  Epoch [23/69], Batch [80/88], Train Acc: 89.9170 Loss: 0.7307\n",
      "  Validation Accuracy after Epoch 23: 86.8000\n",
      "  Cidar10.1 Accuracy: 78.5\n",
      "  Epoch [24/69], Batch [80/88], Train Acc: 90.2197 Loss: 0.7914\n",
      "  Validation Accuracy after Epoch 24: 86.8000\n",
      "  Cidar10.1 Accuracy: 77.45\n",
      "  Epoch [25/69], Batch [80/88], Train Acc: 90.5566 Loss: 0.7266\n",
      "  Validation Accuracy after Epoch 25: 87.8000\n",
      "  Cidar10.1 Accuracy: 78.75\n",
      "  Epoch [26/69], Batch [80/88], Train Acc: 91.2012 Loss: 0.7120\n",
      "  Validation Accuracy after Epoch 26: 88.2000\n",
      "  Cidar10.1 Accuracy: 79.55\n",
      "  Epoch [27/69], Batch [80/88], Train Acc: 91.5771 Loss: 0.7593\n",
      "  Validation Accuracy after Epoch 27: 86.9000\n",
      "  Cidar10.1 Accuracy: 74.5\n",
      "  Epoch [28/69], Batch [80/88], Train Acc: 92.0410 Loss: 0.7459\n",
      "  Validation Accuracy after Epoch 28: 88.2400\n",
      "  Cidar10.1 Accuracy: 79.95\n",
      "  Epoch [29/69], Batch [80/88], Train Acc: 92.1460 Loss: 0.7014\n",
      "  Validation Accuracy after Epoch 29: 88.4400\n",
      "  Cidar10.1 Accuracy: 80.25\n",
      "  Epoch [30/69], Batch [80/88], Train Acc: 92.8589 Loss: 0.7201\n",
      "  Validation Accuracy after Epoch 30: 88.0200\n",
      "  Cidar10.1 Accuracy: 76.6\n",
      "  Epoch [31/69], Batch [80/88], Train Acc: 93.2495 Loss: 0.7025\n",
      "  Validation Accuracy after Epoch 31: 89.0400\n",
      "  Cidar10.1 Accuracy: 81.45\n",
      "  Epoch [32/69], Batch [80/88], Train Acc: 93.4448 Loss: 0.6819\n",
      "  Validation Accuracy after Epoch 32: 89.7000\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [33/69], Batch [80/88], Train Acc: 93.7476 Loss: 0.6749\n",
      "  Validation Accuracy after Epoch 33: 89.2400\n",
      "  Cidar10.1 Accuracy: 80.3\n",
      "  Epoch [34/69], Batch [80/88], Train Acc: 94.2065 Loss: 0.6556\n",
      "  Validation Accuracy after Epoch 34: 88.3600\n",
      "  Cidar10.1 Accuracy: 80.6\n",
      "  Epoch [35/69], Batch [80/88], Train Acc: 94.3237 Loss: 0.6526\n",
      "  Validation Accuracy after Epoch 35: 90.1000\n",
      "  Cidar10.1 Accuracy: 82.45\n",
      "  Epoch [36/69], Batch [80/88], Train Acc: 94.8486 Loss: 0.6578\n",
      "  Validation Accuracy after Epoch 36: 90.3000\n",
      "  Cidar10.1 Accuracy: 82.05\n",
      "  Epoch [37/69], Batch [80/88], Train Acc: 95.2173 Loss: 0.6461\n",
      "  Validation Accuracy after Epoch 37: 90.6400\n",
      "  Cidar10.1 Accuracy: 82.55\n",
      "  Epoch [38/69], Batch [80/88], Train Acc: 95.2222 Loss: 0.6611\n",
      "  Validation Accuracy after Epoch 38: 90.4800\n",
      "  Cidar10.1 Accuracy: 82.3\n",
      "  Epoch [39/69], Batch [80/88], Train Acc: 95.7471 Loss: 0.6320\n",
      "  Validation Accuracy after Epoch 39: 90.9400\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [40/69], Batch [80/88], Train Acc: 96.0425 Loss: 0.6498\n",
      "  Validation Accuracy after Epoch 40: 90.6600\n",
      "  Cidar10.1 Accuracy: 82.75\n",
      "  Epoch [41/69], Batch [80/88], Train Acc: 96.1328 Loss: 0.6071\n",
      "  Validation Accuracy after Epoch 41: 91.1400\n",
      "  Cidar10.1 Accuracy: 83.0\n",
      "  Epoch [42/69], Batch [80/88], Train Acc: 96.3672 Loss: 0.6481\n",
      "  Validation Accuracy after Epoch 42: 91.1400\n",
      "  Cidar10.1 Accuracy: 82.0\n",
      "  Epoch [43/69], Batch [80/88], Train Acc: 96.7017 Loss: 0.5971\n",
      "  Validation Accuracy after Epoch 43: 91.1400\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [44/69], Batch [80/88], Train Acc: 96.8140 Loss: 0.6216\n",
      "  Validation Accuracy after Epoch 44: 91.5000\n",
      "  Cidar10.1 Accuracy: 82.8\n",
      "  Epoch [45/69], Batch [80/88], Train Acc: 97.0850 Loss: 0.5997\n",
      "  Validation Accuracy after Epoch 45: 91.5000\n",
      "  Cidar10.1 Accuracy: 82.65\n",
      "  Epoch [46/69], Batch [80/88], Train Acc: 97.3315 Loss: 0.5961\n",
      "  Validation Accuracy after Epoch 46: 91.3800\n",
      "  Cidar10.1 Accuracy: 83.55\n",
      "  Epoch [47/69], Batch [80/88], Train Acc: 97.5488 Loss: 0.6096\n",
      "  Validation Accuracy after Epoch 47: 90.9400\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [48/69], Batch [80/88], Train Acc: 97.5952 Loss: 0.5891\n",
      "  Validation Accuracy after Epoch 48: 92.1200\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [49/69], Batch [80/88], Train Acc: 97.7222 Loss: 0.5854\n",
      "  Validation Accuracy after Epoch 49: 92.0800\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [50/69], Batch [80/88], Train Acc: 98.0957 Loss: 0.5915\n",
      "  Validation Accuracy after Epoch 50: 92.3400\n",
      "  Cidar10.1 Accuracy: 84.45\n",
      "  Epoch [51/69], Batch [80/88], Train Acc: 98.2983 Loss: 0.5698\n",
      "  Validation Accuracy after Epoch 51: 92.2400\n",
      "  Cidar10.1 Accuracy: 84.45\n",
      "  Epoch [52/69], Batch [80/88], Train Acc: 98.3740 Loss: 0.5822\n",
      "  Validation Accuracy after Epoch 52: 92.0800\n",
      "  Cidar10.1 Accuracy: 83.9\n",
      "  Epoch [53/69], Batch [80/88], Train Acc: 98.5352 Loss: 0.5649\n",
      "  Validation Accuracy after Epoch 53: 92.4600\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [54/69], Batch [80/88], Train Acc: 98.6182 Loss: 0.5571\n",
      "  Validation Accuracy after Epoch 54: 92.2800\n",
      "  Cidar10.1 Accuracy: 85.0\n",
      "  Epoch [55/69], Batch [80/88], Train Acc: 98.8110 Loss: 0.5488\n",
      "  Validation Accuracy after Epoch 55: 92.3800\n",
      "  Cidar10.1 Accuracy: 85.55\n",
      "  Epoch [56/69], Batch [80/88], Train Acc: 98.7671 Loss: 0.5603\n",
      "  Validation Accuracy after Epoch 56: 92.6600\n",
      "  Cidar10.1 Accuracy: 84.95\n",
      "  Epoch [57/69], Batch [80/88], Train Acc: 99.0063 Loss: 0.5657\n",
      "  Validation Accuracy after Epoch 57: 92.8400\n",
      "  Cidar10.1 Accuracy: 85.65\n",
      "  Epoch [58/69], Batch [80/88], Train Acc: 99.0430 Loss: 0.5633\n",
      "  Validation Accuracy after Epoch 58: 92.5600\n",
      "  Cidar10.1 Accuracy: 85.55\n",
      "  Epoch [59/69], Batch [80/88], Train Acc: 99.1724 Loss: 0.5492\n",
      "  Validation Accuracy after Epoch 59: 92.6800\n",
      "  Cidar10.1 Accuracy: 85.85\n",
      "  Epoch [60/69], Batch [80/88], Train Acc: 99.1577 Loss: 0.5479\n",
      "  Validation Accuracy after Epoch 60: 92.4600\n",
      "  Cidar10.1 Accuracy: 86.15\n",
      "  Epoch [61/69], Batch [80/88], Train Acc: 99.2334 Loss: 0.5493\n",
      "  Validation Accuracy after Epoch 61: 92.9000\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [62/69], Batch [80/88], Train Acc: 99.1577 Loss: 0.5533\n",
      "  Validation Accuracy after Epoch 62: 92.9400\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "  Epoch [63/69], Batch [80/88], Train Acc: 99.2554 Loss: 0.5539\n",
      "  Validation Accuracy after Epoch 63: 93.1800\n",
      "  Cidar10.1 Accuracy: 86.3\n",
      "  Epoch [64/69], Batch [80/88], Train Acc: 99.3823 Loss: 0.5469\n",
      "  Validation Accuracy after Epoch 64: 92.9400\n",
      "  Cidar10.1 Accuracy: 86.45\n",
      "  Epoch [65/69], Batch [80/88], Train Acc: 99.3066 Loss: 0.5446\n",
      "  Validation Accuracy after Epoch 65: 92.7800\n",
      "  Cidar10.1 Accuracy: 86.25\n",
      "  Epoch [66/69], Batch [80/88], Train Acc: 99.2920 Loss: 0.5534\n",
      "  Validation Accuracy after Epoch 66: 93.0000\n",
      "  Cidar10.1 Accuracy: 86.5\n",
      "  Epoch [67/69], Batch [80/88], Train Acc: 99.2969 Loss: 0.5372\n",
      "  Validation Accuracy after Epoch 67: 92.7200\n",
      "  Cidar10.1 Accuracy: 86.25\n",
      "  Epoch [68/69], Batch [80/88], Train Acc: 99.3018 Loss: 0.5399\n",
      "  Validation Accuracy after Epoch 68: 92.7800\n",
      "  Cidar10.1 Accuracy: 86.25\n",
      "  Epoch [69/69], Batch [80/88], Train Acc: 99.3213 Loss: 0.5340\n",
      "  Validation Accuracy after Epoch 69: 93.1600\n",
      "  Cidar10.1 Accuracy: 86.35\n",
      "Trial 13 complete. Best Validation Accuracy: 93.1800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:35:23,347] Trial 13 finished with value: 93.18 and parameters: {'num_epochs': 69, 'model_type': 'base', 'batch_size': 512, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.9329524789313232, 'beta2': 0.9946991943427499, 'lr': 0.0003926871765026719, 'weight_decay': 0.0034737743539454947, 'max_lr': 0.007444671068341157}. Best is trial 5 with value: 93.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=14\n",
      "num_epochs: 104\n",
      "model_type: largeresnet\n",
      "batch_size: 64\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8954429170116952\n",
      "beta2: 0.9925876389184227\n",
      "lr: 7.144800659348217e-05\n",
      "weight_decay: 0.006984521915656169\n",
      "max_lr: 0.006740961536442372\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/104], Batch [700/704], Train Acc: 47.6295 Loss: 1.3209\n",
      "  Validation Accuracy after Epoch 1: 57.7000\n",
      "  Cidar10.1 Accuracy: 44.55\n",
      "  Epoch [2/104], Batch [700/704], Train Acc: 65.3304 Loss: 1.2309\n",
      "  Validation Accuracy after Epoch 2: 68.0000\n",
      "  Cidar10.1 Accuracy: 58.25\n",
      "  Epoch [3/104], Batch [700/704], Train Acc: 72.3438 Loss: 1.2083\n",
      "  Validation Accuracy after Epoch 3: 70.9800\n",
      "  Cidar10.1 Accuracy: 59.95\n",
      "  Epoch [4/104], Batch [700/704], Train Acc: 75.5603 Loss: 1.0982\n",
      "  Validation Accuracy after Epoch 4: 75.5800\n",
      "  Cidar10.1 Accuracy: 63.25\n",
      "  Epoch [5/104], Batch [700/704], Train Acc: 77.6964 Loss: 0.9327\n",
      "  Validation Accuracy after Epoch 5: 76.0600\n",
      "  Cidar10.1 Accuracy: 63.65\n",
      "  Epoch [6/104], Batch [700/704], Train Acc: 79.4509 Loss: 0.8569\n",
      "  Validation Accuracy after Epoch 6: 76.8800\n",
      "  Cidar10.1 Accuracy: 64.15\n",
      "  Epoch [7/104], Batch [700/704], Train Acc: 80.4554 Loss: 0.9312\n",
      "  Validation Accuracy after Epoch 7: 78.7200\n",
      "  Cidar10.1 Accuracy: 67.8\n",
      "  Epoch [8/104], Batch [700/704], Train Acc: 81.7210 Loss: 0.8891\n",
      "  Validation Accuracy after Epoch 8: 80.8600\n",
      "  Cidar10.1 Accuracy: 69.65\n",
      "  Epoch [9/104], Batch [700/704], Train Acc: 83.2500 Loss: 0.8835\n",
      "  Validation Accuracy after Epoch 9: 82.2000\n",
      "  Cidar10.1 Accuracy: 69.75\n",
      "  Epoch [10/104], Batch [700/704], Train Acc: 84.1161 Loss: 1.0624\n",
      "  Validation Accuracy after Epoch 10: 81.1200\n",
      "  Cidar10.1 Accuracy: 70.25\n",
      "  Epoch [11/104], Batch [700/704], Train Acc: 84.7701 Loss: 0.8206\n",
      "  Validation Accuracy after Epoch 11: 82.7800\n",
      "  Cidar10.1 Accuracy: 71.55\n",
      "  Epoch [12/104], Batch [700/704], Train Acc: 85.4888 Loss: 0.7685\n",
      "  Validation Accuracy after Epoch 12: 83.5600\n",
      "  Cidar10.1 Accuracy: 73.5\n",
      "  Epoch [13/104], Batch [700/704], Train Acc: 86.3527 Loss: 0.8006\n",
      "  Validation Accuracy after Epoch 13: 84.1200\n",
      "  Cidar10.1 Accuracy: 73.75\n",
      "  Epoch [14/104], Batch [700/704], Train Acc: 86.8929 Loss: 0.9194\n",
      "  Validation Accuracy after Epoch 14: 85.4000\n",
      "  Cidar10.1 Accuracy: 73.75\n",
      "  Epoch [15/104], Batch [700/704], Train Acc: 87.4554 Loss: 0.8553\n",
      "  Validation Accuracy after Epoch 15: 84.7800\n",
      "  Cidar10.1 Accuracy: 76.6\n",
      "  Epoch [16/104], Batch [700/704], Train Acc: 88.1049 Loss: 0.7255\n",
      "  Validation Accuracy after Epoch 16: 84.4800\n",
      "  Cidar10.1 Accuracy: 72.9\n",
      "  Epoch [17/104], Batch [700/704], Train Acc: 88.7455 Loss: 0.6828\n",
      "  Validation Accuracy after Epoch 17: 84.5600\n",
      "  Cidar10.1 Accuracy: 69.35\n",
      "  Epoch [18/104], Batch [700/704], Train Acc: 89.0491 Loss: 0.7706\n",
      "  Validation Accuracy after Epoch 18: 86.7200\n",
      "  Cidar10.1 Accuracy: 76.45\n",
      "  Epoch [19/104], Batch [700/704], Train Acc: 89.5670 Loss: 0.7071\n",
      "  Validation Accuracy after Epoch 19: 87.7000\n",
      "  Cidar10.1 Accuracy: 77.7\n",
      "  Epoch [20/104], Batch [700/704], Train Acc: 89.7567 Loss: 0.7638\n",
      "  Validation Accuracy after Epoch 20: 86.4800\n",
      "  Cidar10.1 Accuracy: 76.55\n",
      "  Epoch [21/104], Batch [700/704], Train Acc: 90.2924 Loss: 0.7974\n",
      "  Validation Accuracy after Epoch 21: 86.9200\n",
      "  Cidar10.1 Accuracy: 79.05\n",
      "  Epoch [22/104], Batch [700/704], Train Acc: 90.5223 Loss: 0.6969\n",
      "  Validation Accuracy after Epoch 22: 86.7800\n",
      "  Cidar10.1 Accuracy: 78.55\n",
      "  Epoch [23/104], Batch [700/704], Train Acc: 90.9062 Loss: 0.6744\n",
      "  Validation Accuracy after Epoch 23: 88.0200\n",
      "  Cidar10.1 Accuracy: 79.2\n",
      "  Epoch [24/104], Batch [700/704], Train Acc: 91.1451 Loss: 0.7809\n",
      "  Validation Accuracy after Epoch 24: 86.7400\n",
      "  Cidar10.1 Accuracy: 77.35\n",
      "  Epoch [25/104], Batch [700/704], Train Acc: 91.4353 Loss: 0.7223\n",
      "  Validation Accuracy after Epoch 25: 85.1200\n",
      "  Cidar10.1 Accuracy: 75.55\n",
      "  Epoch [26/104], Batch [700/704], Train Acc: 91.7812 Loss: 0.7276\n",
      "  Validation Accuracy after Epoch 26: 87.9400\n",
      "  Cidar10.1 Accuracy: 79.45\n",
      "  Epoch [27/104], Batch [700/704], Train Acc: 92.0045 Loss: 0.6898\n",
      "  Validation Accuracy after Epoch 27: 86.6800\n",
      "  Cidar10.1 Accuracy: 77.9\n",
      "  Epoch [28/104], Batch [700/704], Train Acc: 92.3661 Loss: 0.7505\n",
      "  Validation Accuracy after Epoch 28: 87.5800\n",
      "  Cidar10.1 Accuracy: 79.25\n",
      "  Epoch [29/104], Batch [700/704], Train Acc: 92.8192 Loss: 0.6842\n",
      "  Validation Accuracy after Epoch 29: 88.9000\n",
      "  Cidar10.1 Accuracy: 78.45\n",
      "  Epoch [30/104], Batch [700/704], Train Acc: 92.8817 Loss: 0.7221\n",
      "  Validation Accuracy after Epoch 30: 88.6800\n",
      "  Cidar10.1 Accuracy: 79.45\n",
      "  Epoch [31/104], Batch [700/704], Train Acc: 92.9241 Loss: 0.7490\n",
      "  Validation Accuracy after Epoch 31: 88.4200\n",
      "  Cidar10.1 Accuracy: 79.15\n",
      "  Epoch [32/104], Batch [700/704], Train Acc: 93.4308 Loss: 0.6966\n",
      "  Validation Accuracy after Epoch 32: 88.6200\n",
      "  Cidar10.1 Accuracy: 79.1\n",
      "  Epoch [33/104], Batch [700/704], Train Acc: 93.8504 Loss: 0.6774\n",
      "  Validation Accuracy after Epoch 33: 88.6800\n",
      "  Cidar10.1 Accuracy: 79.6\n",
      "  Epoch [34/104], Batch [700/704], Train Acc: 93.8482 Loss: 0.7718\n",
      "  Validation Accuracy after Epoch 34: 89.8200\n",
      "  Cidar10.1 Accuracy: 80.15\n",
      "  Epoch [35/104], Batch [700/704], Train Acc: 94.2344 Loss: 0.6998\n",
      "  Validation Accuracy after Epoch 35: 89.1000\n",
      "  Cidar10.1 Accuracy: 78.7\n",
      "  Epoch [36/104], Batch [700/704], Train Acc: 94.4442 Loss: 0.5837\n",
      "  Validation Accuracy after Epoch 36: 89.0200\n",
      "  Cidar10.1 Accuracy: 80.2\n",
      "  Epoch [37/104], Batch [700/704], Train Acc: 94.6317 Loss: 0.7017\n",
      "  Validation Accuracy after Epoch 37: 89.5400\n",
      "  Cidar10.1 Accuracy: 80.25\n",
      "  Epoch [38/104], Batch [700/704], Train Acc: 94.8571 Loss: 0.7190\n",
      "  Validation Accuracy after Epoch 38: 89.8200\n",
      "  Cidar10.1 Accuracy: 79.65\n",
      "  Epoch [39/104], Batch [700/704], Train Acc: 94.8549 Loss: 0.6062\n",
      "  Validation Accuracy after Epoch 39: 89.0400\n",
      "  Cidar10.1 Accuracy: 80.0\n",
      "  Epoch [40/104], Batch [700/704], Train Acc: 95.1027 Loss: 0.7142\n",
      "  Validation Accuracy after Epoch 40: 89.7800\n",
      "  Cidar10.1 Accuracy: 80.0\n",
      "  Epoch [41/104], Batch [700/704], Train Acc: 95.3862 Loss: 0.6575\n",
      "  Validation Accuracy after Epoch 41: 90.2400\n",
      "  Cidar10.1 Accuracy: 79.9\n",
      "  Epoch [42/104], Batch [700/704], Train Acc: 95.6161 Loss: 0.6013\n",
      "  Validation Accuracy after Epoch 42: 88.8000\n",
      "  Cidar10.1 Accuracy: 79.5\n",
      "  Epoch [43/104], Batch [700/704], Train Acc: 95.6875 Loss: 0.6352\n",
      "  Validation Accuracy after Epoch 43: 89.7000\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [44/104], Batch [700/704], Train Acc: 95.9241 Loss: 0.6067\n",
      "  Validation Accuracy after Epoch 44: 89.6600\n",
      "  Cidar10.1 Accuracy: 81.9\n",
      "  Epoch [45/104], Batch [700/704], Train Acc: 96.0670 Loss: 0.6121\n",
      "  Validation Accuracy after Epoch 45: 89.4400\n",
      "  Cidar10.1 Accuracy: 80.65\n",
      "  Epoch [46/104], Batch [700/704], Train Acc: 96.1161 Loss: 0.5831\n",
      "  Validation Accuracy after Epoch 46: 89.3200\n",
      "  Cidar10.1 Accuracy: 80.2\n",
      "  Epoch [47/104], Batch [700/704], Train Acc: 96.3549 Loss: 0.6334\n",
      "  Validation Accuracy after Epoch 47: 90.1200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:43:48,472] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=15\n",
      "num_epochs: 70\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9169275626977532\n",
      "beta2: 0.995929131948824\n",
      "lr: 0.00027823650102328873\n",
      "weight_decay: 0.0022394883480038293\n",
      "max_lr: 0.008180380869424356\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/70], Batch [80/88], Train Acc: 36.0913 Loss: 1.6928\n",
      "  Validation Accuracy after Epoch 1: 45.4800\n",
      "  Cidar10.1 Accuracy: 37.4\n",
      "  Epoch [2/70], Batch [80/88], Train Acc: 51.8945 Loss: 1.4526\n",
      "  Validation Accuracy after Epoch 2: 53.2800\n",
      "  Cidar10.1 Accuracy: 42.0\n",
      "  Epoch [3/70], Batch [80/88], Train Acc: 60.0684 Loss: 1.3156\n",
      "  Validation Accuracy after Epoch 3: 63.7200\n",
      "  Cidar10.1 Accuracy: 51.0\n",
      "  Epoch [4/70], Batch [80/88], Train Acc: 65.2979 Loss: 1.2572\n",
      "  Validation Accuracy after Epoch 4: 63.3400\n",
      "  Cidar10.1 Accuracy: 52.55\n",
      "  Epoch [5/70], Batch [80/88], Train Acc: 69.4507 Loss: 1.1640\n",
      "  Validation Accuracy after Epoch 5: 66.6000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:44:38,253] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=16\n",
      "num_epochs: 105\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "lr: 0.0024165960179776754\n",
      "momentum: 0.9876208747698934\n",
      "weight_decay: 0.00025215382997647565\n",
      "max_lr: 0.15886158536574177\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/105], Batch [80/88], Train Acc: 29.4849 Loss: 1.7922\n",
      "  Validation Accuracy after Epoch 1: 41.0800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:44:49,390] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=17\n",
      "num_epochs: 125\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8776815504096155\n",
      "beta2: 0.9918481155052591\n",
      "lr: 6.989331356093778e-05\n",
      "weight_decay: 0.01892142649855459\n",
      "max_lr: 0.004318334586906785\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/125], Batch [80/88], Train Acc: 33.9014 Loss: 1.7378\n",
      "  Validation Accuracy after Epoch 1: 43.0400\n",
      "  Cidar10.1 Accuracy: 36.1\n",
      "  Epoch [2/125], Batch [80/88], Train Acc: 46.9360 Loss: 1.5142\n",
      "  Validation Accuracy after Epoch 2: 52.4800\n",
      "  Cidar10.1 Accuracy: 44.4\n",
      "  Epoch [3/125], Batch [80/88], Train Acc: 55.5688 Loss: 1.3599\n",
      "  Validation Accuracy after Epoch 3: 60.6000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:45:19,876] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=18\n",
      "num_epochs: 62\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9034976339196583\n",
      "beta2: 0.9939339592034316\n",
      "lr: 0.0007950305001671975\n",
      "weight_decay: 0.0020546792129433615\n",
      "max_lr: 0.008925590026308522\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/62], Batch [350/352], Train Acc: 45.7009 Loss: 1.5209\n",
      "  Validation Accuracy after Epoch 1: 54.7000\n",
      "  Cidar10.1 Accuracy: 43.2\n",
      "  Epoch [2/62], Batch [350/352], Train Acc: 63.4442 Loss: 1.3998\n",
      "  Validation Accuracy after Epoch 2: 59.4400\n",
      "  Cidar10.1 Accuracy: 45.0\n",
      "  Epoch [3/62], Batch [350/352], Train Acc: 69.7857 Loss: 1.1611\n",
      "  Validation Accuracy after Epoch 3: 71.0600\n",
      "  Cidar10.1 Accuracy: 58.4\n",
      "  Epoch [4/62], Batch [350/352], Train Acc: 73.8616 Loss: 1.2149\n",
      "  Validation Accuracy after Epoch 4: 74.1800\n",
      "  Cidar10.1 Accuracy: 62.5\n",
      "  Epoch [5/62], Batch [350/352], Train Acc: 76.5871 Loss: 1.0084\n",
      "  Validation Accuracy after Epoch 5: 75.2600\n",
      "  Cidar10.1 Accuracy: 63.15\n",
      "  Epoch [6/62], Batch [350/352], Train Acc: 78.6094 Loss: 0.9593\n",
      "  Validation Accuracy after Epoch 6: 76.9200\n",
      "  Cidar10.1 Accuracy: 66.0\n",
      "  Epoch [7/62], Batch [350/352], Train Acc: 80.1875 Loss: 0.9639\n",
      "  Validation Accuracy after Epoch 7: 79.3200\n",
      "  Cidar10.1 Accuracy: 68.85\n",
      "  Epoch [8/62], Batch [350/352], Train Acc: 81.7768 Loss: 0.8678\n",
      "  Validation Accuracy after Epoch 8: 76.3000\n",
      "  Cidar10.1 Accuracy: 61.45\n",
      "  Epoch [9/62], Batch [350/352], Train Acc: 83.0670 Loss: 0.9239\n",
      "  Validation Accuracy after Epoch 9: 77.5000\n",
      "  Cidar10.1 Accuracy: 66.4\n",
      "  Epoch [10/62], Batch [350/352], Train Acc: 83.8795 Loss: 0.8865\n",
      "  Validation Accuracy after Epoch 10: 81.3200\n",
      "  Cidar10.1 Accuracy: 71.5\n",
      "  Epoch [11/62], Batch [350/352], Train Acc: 85.7009 Loss: 0.8015\n",
      "  Validation Accuracy after Epoch 11: 84.0200\n",
      "  Cidar10.1 Accuracy: 74.2\n",
      "  Epoch [12/62], Batch [350/352], Train Acc: 86.1629 Loss: 0.8149\n",
      "  Validation Accuracy after Epoch 12: 82.8400\n",
      "  Cidar10.1 Accuracy: 73.6\n",
      "  Epoch [13/62], Batch [350/352], Train Acc: 87.0915 Loss: 0.8570\n",
      "  Validation Accuracy after Epoch 13: 84.8600\n",
      "  Cidar10.1 Accuracy: 76.6\n",
      "  Epoch [14/62], Batch [350/352], Train Acc: 87.9174 Loss: 0.8022\n",
      "  Validation Accuracy after Epoch 14: 84.1800\n",
      "  Cidar10.1 Accuracy: 74.05\n",
      "  Epoch [15/62], Batch [350/352], Train Acc: 88.6897 Loss: 0.7257\n",
      "  Validation Accuracy after Epoch 15: 83.2400\n",
      "  Cidar10.1 Accuracy: 72.05\n",
      "  Epoch [16/62], Batch [350/352], Train Acc: 89.0402 Loss: 0.8036\n",
      "  Validation Accuracy after Epoch 16: 85.7800\n",
      "  Cidar10.1 Accuracy: 77.5\n",
      "  Epoch [17/62], Batch [350/352], Train Acc: 89.8884 Loss: 0.6993\n",
      "  Validation Accuracy after Epoch 17: 86.1000\n",
      "  Cidar10.1 Accuracy: 74.8\n",
      "  Epoch [18/62], Batch [350/352], Train Acc: 90.3348 Loss: 0.6959\n",
      "  Validation Accuracy after Epoch 18: 85.8800\n",
      "  Cidar10.1 Accuracy: 75.65\n",
      "  Epoch [19/62], Batch [350/352], Train Acc: 91.0714 Loss: 0.7750\n",
      "  Validation Accuracy after Epoch 19: 86.2200\n",
      "  Cidar10.1 Accuracy: 77.35\n",
      "  Epoch [20/62], Batch [350/352], Train Acc: 91.6138 Loss: 0.7209\n",
      "  Validation Accuracy after Epoch 20: 86.4600\n",
      "  Cidar10.1 Accuracy: 77.5\n",
      "  Epoch [21/62], Batch [350/352], Train Acc: 92.5179 Loss: 0.6378\n",
      "  Validation Accuracy after Epoch 21: 88.5600\n",
      "  Cidar10.1 Accuracy: 79.65\n",
      "  Epoch [22/62], Batch [350/352], Train Acc: 93.0201 Loss: 0.6787\n",
      "  Validation Accuracy after Epoch 22: 87.5800\n",
      "  Cidar10.1 Accuracy: 77.4\n",
      "  Epoch [23/62], Batch [350/352], Train Acc: 93.4241 Loss: 0.7453\n",
      "  Validation Accuracy after Epoch 23: 87.9000\n",
      "  Cidar10.1 Accuracy: 77.35\n",
      "  Epoch [24/62], Batch [350/352], Train Acc: 93.6875 Loss: 0.6487\n",
      "  Validation Accuracy after Epoch 24: 87.7400\n",
      "  Cidar10.1 Accuracy: 79.55\n",
      "  Epoch [25/62], Batch [350/352], Train Acc: 94.4241 Loss: 0.6355\n",
      "  Validation Accuracy after Epoch 25: 88.3200\n",
      "  Cidar10.1 Accuracy: 80.35\n",
      "  Epoch [26/62], Batch [350/352], Train Acc: 94.8549 Loss: 0.6655\n",
      "  Validation Accuracy after Epoch 26: 88.8000\n",
      "  Cidar10.1 Accuracy: 82.0\n",
      "  Epoch [27/62], Batch [350/352], Train Acc: 95.0491 Loss: 0.6337\n",
      "  Validation Accuracy after Epoch 27: 90.3800\n",
      "  Cidar10.1 Accuracy: 82.55\n",
      "  Epoch [28/62], Batch [350/352], Train Acc: 95.5781 Loss: 0.6389\n",
      "  Validation Accuracy after Epoch 28: 89.5800\n",
      "  Cidar10.1 Accuracy: 81.75\n",
      "  Epoch [29/62], Batch [350/352], Train Acc: 95.7679 Loss: 0.6348\n",
      "  Validation Accuracy after Epoch 29: 89.9000\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [30/62], Batch [350/352], Train Acc: 96.0580 Loss: 0.6555\n",
      "  Validation Accuracy after Epoch 30: 90.5800\n",
      "  Cidar10.1 Accuracy: 82.75\n",
      "  Epoch [31/62], Batch [350/352], Train Acc: 96.4576 Loss: 0.6244\n",
      "  Validation Accuracy after Epoch 31: 91.1400\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [32/62], Batch [350/352], Train Acc: 96.9397 Loss: 0.6503\n",
      "  Validation Accuracy after Epoch 32: 90.7800\n",
      "  Cidar10.1 Accuracy: 82.55\n",
      "  Epoch [33/62], Batch [350/352], Train Acc: 97.2232 Loss: 0.5837\n",
      "  Validation Accuracy after Epoch 33: 90.8000\n",
      "  Cidar10.1 Accuracy: 82.35\n",
      "  Epoch [34/62], Batch [350/352], Train Acc: 97.4732 Loss: 0.6159\n",
      "  Validation Accuracy after Epoch 34: 91.0000\n",
      "  Cidar10.1 Accuracy: 82.15\n",
      "  Epoch [35/62], Batch [350/352], Train Acc: 97.6295 Loss: 0.5511\n",
      "  Validation Accuracy after Epoch 35: 91.3200\n",
      "  Cidar10.1 Accuracy: 83.05\n",
      "  Epoch [36/62], Batch [350/352], Train Acc: 97.9196 Loss: 0.5917\n",
      "  Validation Accuracy after Epoch 36: 90.9200\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [37/62], Batch [350/352], Train Acc: 98.3058 Loss: 0.5482\n",
      "  Validation Accuracy after Epoch 37: 91.2400\n",
      "  Cidar10.1 Accuracy: 82.85\n",
      "  Epoch [38/62], Batch [350/352], Train Acc: 98.4330 Loss: 0.5661\n",
      "  Validation Accuracy after Epoch 38: 92.1400\n",
      "  Cidar10.1 Accuracy: 83.75\n",
      "  Epoch [39/62], Batch [350/352], Train Acc: 98.5603 Loss: 0.5397\n",
      "  Validation Accuracy after Epoch 39: 91.4000\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [40/62], Batch [350/352], Train Acc: 98.7812 Loss: 0.5617\n",
      "  Validation Accuracy after Epoch 40: 91.9200\n",
      "  Cidar10.1 Accuracy: 83.85\n",
      "  Epoch [41/62], Batch [350/352], Train Acc: 98.8973 Loss: 0.5524\n",
      "  Validation Accuracy after Epoch 41: 91.3800\n",
      "  Cidar10.1 Accuracy: 83.9\n",
      "  Epoch [42/62], Batch [350/352], Train Acc: 99.0536 Loss: 0.5347\n",
      "  Validation Accuracy after Epoch 42: 92.0800\n",
      "  Cidar10.1 Accuracy: 84.05\n",
      "  Epoch [43/62], Batch [350/352], Train Acc: 99.1317 Loss: 0.5367\n",
      "  Validation Accuracy after Epoch 43: 92.1200\n",
      "  Cidar10.1 Accuracy: 84.55\n",
      "  Epoch [44/62], Batch [350/352], Train Acc: 99.2991 Loss: 0.5377\n",
      "  Validation Accuracy after Epoch 44: 92.1600\n",
      "  Cidar10.1 Accuracy: 84.05\n",
      "  Epoch [45/62], Batch [350/352], Train Acc: 99.4375 Loss: 0.5370\n",
      "  Validation Accuracy after Epoch 45: 92.3200\n",
      "  Cidar10.1 Accuracy: 84.55\n",
      "  Epoch [46/62], Batch [350/352], Train Acc: 99.4174 Loss: 0.5254\n",
      "  Validation Accuracy after Epoch 46: 92.3600\n",
      "  Cidar10.1 Accuracy: 84.35\n",
      "  Epoch [47/62], Batch [350/352], Train Acc: 99.5871 Loss: 0.5270\n",
      "  Validation Accuracy after Epoch 47: 92.7800\n",
      "  Cidar10.1 Accuracy: 84.9\n",
      "  Epoch [48/62], Batch [350/352], Train Acc: 99.6607 Loss: 0.5158\n",
      "  Validation Accuracy after Epoch 48: 92.3200\n",
      "  Cidar10.1 Accuracy: 84.55\n",
      "  Epoch [49/62], Batch [350/352], Train Acc: 99.7165 Loss: 0.5162\n",
      "  Validation Accuracy after Epoch 49: 92.6600\n",
      "  Cidar10.1 Accuracy: 84.95\n",
      "  Epoch [50/62], Batch [350/352], Train Acc: 99.7121 Loss: 0.5280\n",
      "  Validation Accuracy after Epoch 50: 92.7600\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "  Epoch [51/62], Batch [350/352], Train Acc: 99.7946 Loss: 0.5120\n",
      "  Validation Accuracy after Epoch 51: 92.9200\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [52/62], Batch [350/352], Train Acc: 99.8147 Loss: 0.5235\n",
      "  Validation Accuracy after Epoch 52: 92.9400\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [53/62], Batch [350/352], Train Acc: 99.8259 Loss: 0.5132\n",
      "  Validation Accuracy after Epoch 53: 92.9800\n",
      "  Cidar10.1 Accuracy: 85.0\n",
      "  Epoch [54/62], Batch [350/352], Train Acc: 99.8683 Loss: 0.5327\n",
      "  Validation Accuracy after Epoch 54: 92.8200\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [55/62], Batch [350/352], Train Acc: 99.8661 Loss: 0.5173\n",
      "  Validation Accuracy after Epoch 55: 93.0000\n",
      "  Cidar10.1 Accuracy: 85.5\n",
      "  Epoch [56/62], Batch [350/352], Train Acc: 99.8817 Loss: 0.5214\n",
      "  Validation Accuracy after Epoch 56: 92.8800\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [57/62], Batch [350/352], Train Acc: 99.9263 Loss: 0.5101\n",
      "  Validation Accuracy after Epoch 57: 93.1600\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "  Epoch [58/62], Batch [350/352], Train Acc: 99.9219 Loss: 0.5173\n",
      "  Validation Accuracy after Epoch 58: 93.6600\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [59/62], Batch [350/352], Train Acc: 99.9174 Loss: 0.5199\n",
      "  Validation Accuracy after Epoch 59: 92.8800\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [60/62], Batch [350/352], Train Acc: 99.8973 Loss: 0.5136\n",
      "  Validation Accuracy after Epoch 60: 93.5000\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [61/62], Batch [350/352], Train Acc: 99.9375 Loss: 0.5112\n",
      "  Validation Accuracy after Epoch 61: 93.0800\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [62/62], Batch [350/352], Train Acc: 99.9420 Loss: 0.5098\n",
      "  Validation Accuracy after Epoch 62: 93.0800\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "Trial 18 complete. Best Validation Accuracy: 93.6600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:55:17,999] Trial 18 finished with value: 93.66 and parameters: {'num_epochs': 62, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.9034976339196583, 'beta2': 0.9939339592034316, 'lr': 0.0007950305001671975, 'weight_decay': 0.0020546792129433615, 'max_lr': 0.008925590026308522}. Best is trial 18 with value: 93.66.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=19\n",
      "num_epochs: 67\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: SGD\n",
      "scheduler_type: CosineAnnealingLR\n",
      "lr: 0.044514508068941326\n",
      "momentum: 0.9856837213372819\n",
      "weight_decay: 0.00028048928502502624\n",
      "eta_min: 1.3617921042441039e-06\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/67], Batch [350/352], Train Acc: 39.7277 Loss: 1.6286\n",
      "  Validation Accuracy after Epoch 1: 48.0800\n",
      "  Cidar10.1 Accuracy: 38.9\n",
      "  Epoch [2/67], Batch [350/352], Train Acc: 53.8170 Loss: 1.3418\n",
      "  Validation Accuracy after Epoch 2: 57.5600\n",
      "  Cidar10.1 Accuracy: 44.75\n",
      "  Epoch [3/67], Batch [350/352], Train Acc: 62.6272 Loss: 1.3476\n",
      "  Validation Accuracy after Epoch 3: 60.0400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 05:55:47,885] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=20\n",
      "num_epochs: 79\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8966741749809605\n",
      "beta2: 0.9953296889087532\n",
      "lr: 0.0009949003229868505\n",
      "weight_decay: 0.002220705473846143\n",
      "max_lr: 0.005605644909963183\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/79], Batch [350/352], Train Acc: 45.2031 Loss: 1.5746\n",
      "  Validation Accuracy after Epoch 1: 53.5200\n",
      "  Cidar10.1 Accuracy: 44.55\n",
      "  Epoch [2/79], Batch [350/352], Train Acc: 62.1406 Loss: 1.2866\n",
      "  Validation Accuracy after Epoch 2: 65.4200\n",
      "  Cidar10.1 Accuracy: 53.9\n",
      "  Epoch [3/79], Batch [350/352], Train Acc: 69.5134 Loss: 1.1916\n",
      "  Validation Accuracy after Epoch 3: 67.0800\n",
      "  Cidar10.1 Accuracy: 54.7\n",
      "  Epoch [4/79], Batch [350/352], Train Acc: 74.0692 Loss: 0.9409\n",
      "  Validation Accuracy after Epoch 4: 70.8600\n",
      "  Cidar10.1 Accuracy: 55.4\n",
      "  Epoch [5/79], Batch [350/352], Train Acc: 76.2545 Loss: 1.1184\n",
      "  Validation Accuracy after Epoch 5: 74.8000\n",
      "  Cidar10.1 Accuracy: 63.4\n",
      "  Epoch [6/79], Batch [350/352], Train Acc: 77.8281 Loss: 0.9598\n",
      "  Validation Accuracy after Epoch 6: 76.4000\n",
      "  Cidar10.1 Accuracy: 63.85\n",
      "  Epoch [7/79], Batch [350/352], Train Acc: 79.8125 Loss: 1.0078\n",
      "  Validation Accuracy after Epoch 7: 78.0600\n",
      "  Cidar10.1 Accuracy: 66.5\n",
      "  Epoch [8/79], Batch [350/352], Train Acc: 80.9554 Loss: 0.9933\n",
      "  Validation Accuracy after Epoch 8: 76.6600\n",
      "  Cidar10.1 Accuracy: 63.9\n",
      "  Epoch [9/79], Batch [350/352], Train Acc: 82.1763 Loss: 0.8792\n",
      "  Validation Accuracy after Epoch 9: 79.3600\n",
      "  Cidar10.1 Accuracy: 67.5\n",
      "  Epoch [10/79], Batch [350/352], Train Acc: 83.7121 Loss: 0.8327\n",
      "  Validation Accuracy after Epoch 10: 81.5000\n",
      "  Cidar10.1 Accuracy: 70.3\n",
      "  Epoch [11/79], Batch [350/352], Train Acc: 84.3884 Loss: 0.8231\n",
      "  Validation Accuracy after Epoch 11: 83.5400\n",
      "  Cidar10.1 Accuracy: 73.35\n",
      "  Epoch [12/79], Batch [350/352], Train Acc: 85.5045 Loss: 0.9386\n",
      "  Validation Accuracy after Epoch 12: 80.5200\n",
      "  Cidar10.1 Accuracy: 68.2\n",
      "  Epoch [13/79], Batch [350/352], Train Acc: 86.3705 Loss: 0.8219\n",
      "  Validation Accuracy after Epoch 13: 82.3200\n",
      "  Cidar10.1 Accuracy: 71.15\n",
      "  Epoch [14/79], Batch [350/352], Train Acc: 87.2679 Loss: 0.7393\n",
      "  Validation Accuracy after Epoch 14: 81.1200\n",
      "  Cidar10.1 Accuracy: 68.25\n",
      "  Epoch [15/79], Batch [350/352], Train Acc: 87.7812 Loss: 0.8269\n",
      "  Validation Accuracy after Epoch 15: 82.2400\n",
      "  Cidar10.1 Accuracy: 72.3\n",
      "  Epoch [16/79], Batch [350/352], Train Acc: 88.5268 Loss: 0.8384\n",
      "  Validation Accuracy after Epoch 16: 85.0200\n",
      "  Cidar10.1 Accuracy: 73.55\n",
      "  Epoch [17/79], Batch [350/352], Train Acc: 89.1406 Loss: 0.6712\n",
      "  Validation Accuracy after Epoch 17: 86.6000\n",
      "  Cidar10.1 Accuracy: 77.4\n",
      "  Epoch [18/79], Batch [350/352], Train Acc: 89.8415 Loss: 0.7261\n",
      "  Validation Accuracy after Epoch 18: 88.0600\n",
      "  Cidar10.1 Accuracy: 80.3\n",
      "  Epoch [19/79], Batch [350/352], Train Acc: 90.6071 Loss: 0.7811\n",
      "  Validation Accuracy after Epoch 19: 86.7400\n",
      "  Cidar10.1 Accuracy: 76.7\n",
      "  Epoch [20/79], Batch [350/352], Train Acc: 90.9442 Loss: 0.7161\n",
      "  Validation Accuracy after Epoch 20: 88.1000\n",
      "  Cidar10.1 Accuracy: 78.95\n",
      "  Epoch [21/79], Batch [350/352], Train Acc: 91.6607 Loss: 0.6667\n",
      "  Validation Accuracy after Epoch 21: 86.9400\n",
      "  Cidar10.1 Accuracy: 79.45\n",
      "  Epoch [22/79], Batch [350/352], Train Acc: 91.9353 Loss: 0.6786\n",
      "  Validation Accuracy after Epoch 22: 88.4800\n",
      "  Cidar10.1 Accuracy: 80.7\n",
      "  Epoch [23/79], Batch [350/352], Train Acc: 92.4531 Loss: 0.6278\n",
      "  Validation Accuracy after Epoch 23: 85.7400\n",
      "  Cidar10.1 Accuracy: 76.85\n",
      "  Epoch [24/79], Batch [350/352], Train Acc: 92.9286 Loss: 0.6987\n",
      "  Validation Accuracy after Epoch 24: 87.9800\n",
      "  Cidar10.1 Accuracy: 79.4\n",
      "  Epoch [25/79], Batch [350/352], Train Acc: 93.4911 Loss: 0.6935\n",
      "  Validation Accuracy after Epoch 25: 88.7600\n",
      "  Cidar10.1 Accuracy: 79.5\n",
      "  Epoch [26/79], Batch [350/352], Train Acc: 93.9799 Loss: 0.6619\n",
      "  Validation Accuracy after Epoch 26: 88.7800\n",
      "  Cidar10.1 Accuracy: 80.35\n",
      "  Epoch [27/79], Batch [350/352], Train Acc: 94.5670 Loss: 0.6591\n",
      "  Validation Accuracy after Epoch 27: 89.2400\n",
      "  Cidar10.1 Accuracy: 79.5\n",
      "  Epoch [28/79], Batch [350/352], Train Acc: 94.8103 Loss: 0.6459\n",
      "  Validation Accuracy after Epoch 28: 89.6600\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [29/79], Batch [350/352], Train Acc: 95.1384 Loss: 0.6456\n",
      "  Validation Accuracy after Epoch 29: 89.3000\n",
      "  Cidar10.1 Accuracy: 79.7\n",
      "  Epoch [30/79], Batch [350/352], Train Acc: 95.4420 Loss: 0.5775\n",
      "  Validation Accuracy after Epoch 30: 89.6800\n",
      "  Cidar10.1 Accuracy: 81.0\n",
      "  Epoch [31/79], Batch [350/352], Train Acc: 95.6518 Loss: 0.6471\n",
      "  Validation Accuracy after Epoch 31: 90.6200\n",
      "  Cidar10.1 Accuracy: 81.65\n",
      "  Epoch [32/79], Batch [350/352], Train Acc: 96.0000 Loss: 0.6135\n",
      "  Validation Accuracy after Epoch 32: 89.5200\n",
      "  Cidar10.1 Accuracy: 79.8\n",
      "  Epoch [33/79], Batch [350/352], Train Acc: 96.4643 Loss: 0.6111\n",
      "  Validation Accuracy after Epoch 33: 90.0800\n",
      "  Cidar10.1 Accuracy: 81.65\n",
      "  Epoch [34/79], Batch [350/352], Train Acc: 96.7009 Loss: 0.6214\n",
      "  Validation Accuracy after Epoch 34: 89.8800\n",
      "  Cidar10.1 Accuracy: 82.8\n",
      "  Epoch [35/79], Batch [350/352], Train Acc: 96.8549 Loss: 0.5813\n",
      "  Validation Accuracy after Epoch 35: 89.5200\n",
      "  Cidar10.1 Accuracy: 82.95\n",
      "  Epoch [36/79], Batch [350/352], Train Acc: 97.1339 Loss: 0.6405\n",
      "  Validation Accuracy after Epoch 36: 90.4600\n",
      "  Cidar10.1 Accuracy: 81.85\n",
      "  Epoch [37/79], Batch [350/352], Train Acc: 97.1987 Loss: 0.5796\n",
      "  Validation Accuracy after Epoch 37: 91.0000\n",
      "  Cidar10.1 Accuracy: 82.6\n",
      "  Epoch [38/79], Batch [350/352], Train Acc: 97.6384 Loss: 0.5777\n",
      "  Validation Accuracy after Epoch 38: 91.0400\n",
      "  Cidar10.1 Accuracy: 83.25\n",
      "  Epoch [39/79], Batch [350/352], Train Acc: 97.6696 Loss: 0.5755\n",
      "  Validation Accuracy after Epoch 39: 90.8400\n",
      "  Cidar10.1 Accuracy: 83.25\n",
      "  Epoch [40/79], Batch [350/352], Train Acc: 97.8951 Loss: 0.5574\n",
      "  Validation Accuracy after Epoch 40: 91.4000\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [41/79], Batch [350/352], Train Acc: 98.1362 Loss: 0.5628\n",
      "  Validation Accuracy after Epoch 41: 91.3200\n",
      "  Cidar10.1 Accuracy: 83.6\n",
      "  Epoch [42/79], Batch [350/352], Train Acc: 98.3527 Loss: 0.5703\n",
      "  Validation Accuracy after Epoch 42: 91.3800\n",
      "  Cidar10.1 Accuracy: 84.15\n",
      "  Epoch [43/79], Batch [350/352], Train Acc: 98.2433 Loss: 0.5589\n",
      "  Validation Accuracy after Epoch 43: 91.2000\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [44/79], Batch [350/352], Train Acc: 98.4732 Loss: 0.5426\n",
      "  Validation Accuracy after Epoch 44: 91.3000\n",
      "  Cidar10.1 Accuracy: 84.0\n",
      "  Epoch [45/79], Batch [350/352], Train Acc: 98.7321 Loss: 0.5912\n",
      "  Validation Accuracy after Epoch 45: 91.1000\n",
      "  Cidar10.1 Accuracy: 83.85\n",
      "  Epoch [46/79], Batch [350/352], Train Acc: 98.7991 Loss: 0.5289\n",
      "  Validation Accuracy after Epoch 46: 91.3400\n",
      "  Cidar10.1 Accuracy: 83.15\n",
      "  Epoch [47/79], Batch [350/352], Train Acc: 98.9710 Loss: 0.5313\n",
      "  Validation Accuracy after Epoch 47: 91.7200\n",
      "  Cidar10.1 Accuracy: 83.35\n",
      "  Epoch [48/79], Batch [350/352], Train Acc: 99.0290 Loss: 0.5471\n",
      "  Validation Accuracy after Epoch 48: 91.2600\n",
      "  Cidar10.1 Accuracy: 83.15\n",
      "  Epoch [49/79], Batch [350/352], Train Acc: 99.1071 Loss: 0.5504\n",
      "  Validation Accuracy after Epoch 49: 91.9800\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [50/79], Batch [350/352], Train Acc: 99.1987 Loss: 0.5404\n",
      "  Validation Accuracy after Epoch 50: 91.8400\n",
      "  Cidar10.1 Accuracy: 83.35\n",
      "  Epoch [51/79], Batch [350/352], Train Acc: 99.2991 Loss: 0.5304\n",
      "  Validation Accuracy after Epoch 51: 92.0000\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [52/79], Batch [350/352], Train Acc: 99.3549 Loss: 0.5172\n",
      "  Validation Accuracy after Epoch 52: 92.1000\n",
      "  Cidar10.1 Accuracy: 84.15\n",
      "  Epoch [53/79], Batch [350/352], Train Acc: 99.4442 Loss: 0.5161\n",
      "  Validation Accuracy after Epoch 53: 91.4000\n",
      "  Cidar10.1 Accuracy: 84.6\n",
      "  Epoch [54/79], Batch [350/352], Train Acc: 99.4598 Loss: 0.5485\n",
      "  Validation Accuracy after Epoch 54: 92.5400\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [55/79], Batch [350/352], Train Acc: 99.5759 Loss: 0.5267\n",
      "  Validation Accuracy after Epoch 55: 92.4600\n",
      "  Cidar10.1 Accuracy: 84.65\n",
      "  Epoch [56/79], Batch [350/352], Train Acc: 99.6027 Loss: 0.5159\n",
      "  Validation Accuracy after Epoch 56: 92.4400\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "  Epoch [57/79], Batch [350/352], Train Acc: 99.6629 Loss: 0.5227\n",
      "  Validation Accuracy after Epoch 57: 92.7600\n",
      "  Cidar10.1 Accuracy: 84.85\n",
      "  Epoch [58/79], Batch [350/352], Train Acc: 99.7098 Loss: 0.5234\n",
      "  Validation Accuracy after Epoch 58: 92.3200\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [59/79], Batch [350/352], Train Acc: 99.6964 Loss: 0.5165\n",
      "  Validation Accuracy after Epoch 59: 92.7000\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [60/79], Batch [350/352], Train Acc: 99.7679 Loss: 0.5210\n",
      "  Validation Accuracy after Epoch 60: 93.1000\n",
      "  Cidar10.1 Accuracy: 84.9\n",
      "  Epoch [61/79], Batch [350/352], Train Acc: 99.8281 Loss: 0.5099\n",
      "  Validation Accuracy after Epoch 61: 92.5800\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [62/79], Batch [350/352], Train Acc: 99.8571 Loss: 0.5130\n",
      "  Validation Accuracy after Epoch 62: 92.7600\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [63/79], Batch [350/352], Train Acc: 99.8705 Loss: 0.5107\n",
      "  Validation Accuracy after Epoch 63: 93.1600\n",
      "  Cidar10.1 Accuracy: 85.55\n",
      "  Epoch [64/79], Batch [350/352], Train Acc: 99.8705 Loss: 0.5121\n",
      "  Validation Accuracy after Epoch 64: 92.3400\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [65/79], Batch [350/352], Train Acc: 99.8862 Loss: 0.5109\n",
      "  Validation Accuracy after Epoch 65: 92.9200\n",
      "  Cidar10.1 Accuracy: 85.65\n",
      "  Epoch [66/79], Batch [350/352], Train Acc: 99.9196 Loss: 0.5181\n",
      "  Validation Accuracy after Epoch 66: 93.2000\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [67/79], Batch [350/352], Train Acc: 99.9219 Loss: 0.5125\n",
      "  Validation Accuracy after Epoch 67: 93.3400\n",
      "  Cidar10.1 Accuracy: 85.15\n",
      "  Epoch [68/79], Batch [350/352], Train Acc: 99.9085 Loss: 0.5110\n",
      "  Validation Accuracy after Epoch 68: 93.0400\n",
      "  Cidar10.1 Accuracy: 85.9\n",
      "  Epoch [69/79], Batch [350/352], Train Acc: 99.9219 Loss: 0.5084\n",
      "  Validation Accuracy after Epoch 69: 93.4000\n",
      "  Cidar10.1 Accuracy: 86.15\n",
      "  Epoch [70/79], Batch [350/352], Train Acc: 99.9598 Loss: 0.5138\n",
      "  Validation Accuracy after Epoch 70: 93.1200\n",
      "  Cidar10.1 Accuracy: 85.95\n",
      "  Epoch [71/79], Batch [350/352], Train Acc: 99.9554 Loss: 0.5079\n",
      "  Validation Accuracy after Epoch 71: 93.6000\n",
      "  Cidar10.1 Accuracy: 85.65\n",
      "  Epoch [72/79], Batch [350/352], Train Acc: 99.9487 Loss: 0.5070\n",
      "  Validation Accuracy after Epoch 72: 93.3200\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "  Epoch [73/79], Batch [350/352], Train Acc: 99.9598 Loss: 0.5102\n",
      "  Validation Accuracy after Epoch 73: 93.0000\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "  Epoch [74/79], Batch [350/352], Train Acc: 99.9621 Loss: 0.5083\n",
      "  Validation Accuracy after Epoch 74: 93.9200\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [75/79], Batch [350/352], Train Acc: 99.9688 Loss: 0.5092\n",
      "  Validation Accuracy after Epoch 75: 93.1400\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [76/79], Batch [350/352], Train Acc: 99.9554 Loss: 0.5059\n",
      "  Validation Accuracy after Epoch 76: 93.4600\n",
      "  Cidar10.1 Accuracy: 85.65\n",
      "  Epoch [77/79], Batch [350/352], Train Acc: 99.9442 Loss: 0.5057\n",
      "  Validation Accuracy after Epoch 77: 93.2000\n",
      "  Cidar10.1 Accuracy: 85.9\n",
      "  Epoch [78/79], Batch [350/352], Train Acc: 99.9688 Loss: 0.5074\n",
      "  Validation Accuracy after Epoch 78: 93.8200\n",
      "  Cidar10.1 Accuracy: 85.85\n",
      "  Epoch [79/79], Batch [350/352], Train Acc: 99.9598 Loss: 0.5065\n",
      "  Validation Accuracy after Epoch 79: 93.2600\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "Trial 20 complete. Best Validation Accuracy: 93.9200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 06:08:29,591] Trial 20 finished with value: 93.92 and parameters: {'num_epochs': 79, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8966741749809605, 'beta2': 0.9953296889087532, 'lr': 0.0009949003229868505, 'weight_decay': 0.002220705473846143, 'max_lr': 0.005605644909963183}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=21\n",
      "num_epochs: 76\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8989450645955427\n",
      "beta2: 0.9958117445521014\n",
      "lr: 0.0010497858203851631\n",
      "weight_decay: 0.0021788986817215493\n",
      "max_lr: 0.005119536702611704\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/76], Batch [350/352], Train Acc: 45.1473 Loss: 1.5743\n",
      "  Validation Accuracy after Epoch 1: 51.9600\n",
      "  Cidar10.1 Accuracy: 43.2\n",
      "  Epoch [2/76], Batch [350/352], Train Acc: 61.7522 Loss: 1.3614\n",
      "  Validation Accuracy after Epoch 2: 64.5600\n",
      "  Cidar10.1 Accuracy: 51.2\n",
      "  Epoch [3/76], Batch [350/352], Train Acc: 69.1027 Loss: 1.1643\n",
      "  Validation Accuracy after Epoch 3: 61.0400\n",
      "  Cidar10.1 Accuracy: 46.05\n",
      "  Epoch [4/76], Batch [350/352], Train Acc: 73.3103 Loss: 1.1182\n",
      "  Validation Accuracy after Epoch 4: 71.6800\n",
      "  Cidar10.1 Accuracy: 58.6\n",
      "  Epoch [5/76], Batch [350/352], Train Acc: 75.6451 Loss: 1.0241\n",
      "  Validation Accuracy after Epoch 5: 73.8400\n",
      "  Cidar10.1 Accuracy: 60.25\n",
      "  Epoch [6/76], Batch [350/352], Train Acc: 77.9821 Loss: 0.9740\n",
      "  Validation Accuracy after Epoch 6: 76.0000\n",
      "  Cidar10.1 Accuracy: 64.9\n",
      "  Epoch [7/76], Batch [350/352], Train Acc: 79.3951 Loss: 0.9765\n",
      "  Validation Accuracy after Epoch 7: 78.2400\n",
      "  Cidar10.1 Accuracy: 66.85\n",
      "  Epoch [8/76], Batch [350/352], Train Acc: 81.0156 Loss: 0.9839\n",
      "  Validation Accuracy after Epoch 8: 71.8200\n",
      "  Cidar10.1 Accuracy: 55.15\n",
      "  Epoch [9/76], Batch [350/352], Train Acc: 82.3281 Loss: 0.8816\n",
      "  Validation Accuracy after Epoch 9: 78.1200\n",
      "  Cidar10.1 Accuracy: 65.95\n",
      "  Epoch [10/76], Batch [350/352], Train Acc: 82.9531 Loss: 0.9041\n",
      "  Validation Accuracy after Epoch 10: 80.7600\n",
      "  Cidar10.1 Accuracy: 68.5\n",
      "  Epoch [11/76], Batch [350/352], Train Acc: 84.2054 Loss: 0.8867\n",
      "  Validation Accuracy after Epoch 11: 81.9200\n",
      "  Cidar10.1 Accuracy: 69.8\n",
      "  Epoch [12/76], Batch [350/352], Train Acc: 85.3259 Loss: 0.8495\n",
      "  Validation Accuracy after Epoch 12: 80.5600\n",
      "  Cidar10.1 Accuracy: 69.5\n",
      "  Epoch [13/76], Batch [350/352], Train Acc: 86.1942 Loss: 0.8530\n",
      "  Validation Accuracy after Epoch 13: 83.4400\n",
      "  Cidar10.1 Accuracy: 73.25\n",
      "  Epoch [14/76], Batch [350/352], Train Acc: 87.1116 Loss: 0.8048\n",
      "  Validation Accuracy after Epoch 14: 80.3200\n",
      "  Cidar10.1 Accuracy: 70.15\n",
      "  Epoch [15/76], Batch [350/352], Train Acc: 87.5446 Loss: 0.7597\n",
      "  Validation Accuracy after Epoch 15: 81.6000\n",
      "  Cidar10.1 Accuracy: 72.4\n",
      "  Epoch [16/76], Batch [350/352], Train Acc: 88.5402 Loss: 0.7399\n",
      "  Validation Accuracy after Epoch 16: 87.0600\n",
      "  Cidar10.1 Accuracy: 77.75\n",
      "  Epoch [17/76], Batch [350/352], Train Acc: 89.2009 Loss: 0.7214\n",
      "  Validation Accuracy after Epoch 17: 84.9800\n",
      "  Cidar10.1 Accuracy: 75.45\n",
      "  Epoch [18/76], Batch [350/352], Train Acc: 89.7478 Loss: 0.8309\n",
      "  Validation Accuracy after Epoch 18: 84.8000\n",
      "  Cidar10.1 Accuracy: 73.8\n",
      "  Epoch [19/76], Batch [350/352], Train Acc: 90.5156 Loss: 0.8229\n",
      "  Validation Accuracy after Epoch 19: 87.7000\n",
      "  Cidar10.1 Accuracy: 75.75\n",
      "  Epoch [20/76], Batch [350/352], Train Acc: 91.0179 Loss: 0.7135\n",
      "  Validation Accuracy after Epoch 20: 86.6200\n",
      "  Cidar10.1 Accuracy: 77.6\n",
      "  Epoch [21/76], Batch [350/352], Train Acc: 91.5893 Loss: 0.7111\n",
      "  Validation Accuracy after Epoch 21: 86.0400\n",
      "  Cidar10.1 Accuracy: 76.35\n",
      "  Epoch [22/76], Batch [350/352], Train Acc: 92.0379 Loss: 0.7567\n",
      "  Validation Accuracy after Epoch 22: 85.6000\n",
      "  Cidar10.1 Accuracy: 77.85\n",
      "  Epoch [23/76], Batch [350/352], Train Acc: 92.6473 Loss: 0.6428\n",
      "  Validation Accuracy after Epoch 23: 87.2800\n",
      "  Cidar10.1 Accuracy: 77.85\n",
      "  Epoch [24/76], Batch [350/352], Train Acc: 93.0536 Loss: 0.7499\n",
      "  Validation Accuracy after Epoch 24: 88.3400\n",
      "  Cidar10.1 Accuracy: 78.8\n",
      "  Epoch [25/76], Batch [350/352], Train Acc: 93.5804 Loss: 0.6936\n",
      "  Validation Accuracy after Epoch 25: 89.2000\n",
      "  Cidar10.1 Accuracy: 79.1\n",
      "  Epoch [26/76], Batch [350/352], Train Acc: 94.0558 Loss: 0.5915\n",
      "  Validation Accuracy after Epoch 26: 88.8800\n",
      "  Cidar10.1 Accuracy: 78.35\n",
      "  Epoch [27/76], Batch [350/352], Train Acc: 94.4554 Loss: 0.6593\n",
      "  Validation Accuracy after Epoch 27: 89.0000\n",
      "  Cidar10.1 Accuracy: 81.45\n",
      "  Epoch [28/76], Batch [350/352], Train Acc: 94.9643 Loss: 0.6155\n",
      "  Validation Accuracy after Epoch 28: 89.8000\n",
      "  Cidar10.1 Accuracy: 82.25\n",
      "  Epoch [29/76], Batch [350/352], Train Acc: 95.2455 Loss: 0.6479\n",
      "  Validation Accuracy after Epoch 29: 89.9000\n",
      "  Cidar10.1 Accuracy: 81.0\n",
      "  Epoch [30/76], Batch [350/352], Train Acc: 95.5022 Loss: 0.6364\n",
      "  Validation Accuracy after Epoch 30: 89.3800\n",
      "  Cidar10.1 Accuracy: 81.25\n",
      "  Epoch [31/76], Batch [350/352], Train Acc: 95.8661 Loss: 0.6355\n",
      "  Validation Accuracy after Epoch 31: 89.9800\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [32/76], Batch [350/352], Train Acc: 96.1897 Loss: 0.5747\n",
      "  Validation Accuracy after Epoch 32: 89.8200\n",
      "  Cidar10.1 Accuracy: 81.4\n",
      "  Epoch [33/76], Batch [350/352], Train Acc: 96.5112 Loss: 0.6061\n",
      "  Validation Accuracy after Epoch 33: 91.0600\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [34/76], Batch [350/352], Train Acc: 96.7455 Loss: 0.5660\n",
      "  Validation Accuracy after Epoch 34: 90.9000\n",
      "  Cidar10.1 Accuracy: 82.25\n",
      "  Epoch [35/76], Batch [350/352], Train Acc: 97.0022 Loss: 0.5641\n",
      "  Validation Accuracy after Epoch 35: 90.4400\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [36/76], Batch [350/352], Train Acc: 97.3460 Loss: 0.6389\n",
      "  Validation Accuracy after Epoch 36: 90.9400\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [37/76], Batch [350/352], Train Acc: 97.4442 Loss: 0.5986\n",
      "  Validation Accuracy after Epoch 37: 91.1000\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [38/76], Batch [350/352], Train Acc: 97.6161 Loss: 0.5684\n",
      "  Validation Accuracy after Epoch 38: 91.1200\n",
      "  Cidar10.1 Accuracy: 84.05\n",
      "  Epoch [39/76], Batch [350/352], Train Acc: 97.8571 Loss: 0.5860\n",
      "  Validation Accuracy after Epoch 39: 91.7800\n",
      "  Cidar10.1 Accuracy: 83.1\n",
      "  Epoch [40/76], Batch [350/352], Train Acc: 98.0424 Loss: 0.5818\n",
      "  Validation Accuracy after Epoch 40: 90.9000\n",
      "  Cidar10.1 Accuracy: 83.9\n",
      "  Epoch [41/76], Batch [350/352], Train Acc: 98.2701 Loss: 0.5661\n",
      "  Validation Accuracy after Epoch 41: 90.8800\n",
      "  Cidar10.1 Accuracy: 82.55\n",
      "  Epoch [42/76], Batch [350/352], Train Acc: 98.4174 Loss: 0.5913\n",
      "  Validation Accuracy after Epoch 42: 91.5600\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [43/76], Batch [350/352], Train Acc: 98.5156 Loss: 0.5490\n",
      "  Validation Accuracy after Epoch 43: 91.6200\n",
      "  Cidar10.1 Accuracy: 82.45\n",
      "  Epoch [44/76], Batch [350/352], Train Acc: 98.7567 Loss: 0.5366\n",
      "  Validation Accuracy after Epoch 44: 91.8200\n",
      "  Cidar10.1 Accuracy: 84.5\n",
      "  Epoch [45/76], Batch [350/352], Train Acc: 98.8259 Loss: 0.5641\n",
      "  Validation Accuracy after Epoch 45: 91.7800\n",
      "  Cidar10.1 Accuracy: 83.35\n",
      "  Epoch [46/76], Batch [350/352], Train Acc: 99.0179 Loss: 0.5491\n",
      "  Validation Accuracy after Epoch 46: 92.2200\n",
      "  Cidar10.1 Accuracy: 84.9\n",
      "  Epoch [47/76], Batch [350/352], Train Acc: 99.0335 Loss: 0.5237\n",
      "  Validation Accuracy after Epoch 47: 91.9800\n",
      "  Cidar10.1 Accuracy: 82.8\n",
      "  Epoch [48/76], Batch [350/352], Train Acc: 99.1897 Loss: 0.5482\n",
      "  Validation Accuracy after Epoch 48: 91.9600\n",
      "  Cidar10.1 Accuracy: 83.85\n",
      "  Epoch [49/76], Batch [350/352], Train Acc: 99.2701 Loss: 0.5264\n",
      "  Validation Accuracy after Epoch 49: 92.5000\n",
      "  Cidar10.1 Accuracy: 84.45\n",
      "  Epoch [50/76], Batch [350/352], Train Acc: 99.3460 Loss: 0.5326\n",
      "  Validation Accuracy after Epoch 50: 92.2200\n",
      "  Cidar10.1 Accuracy: 84.5\n",
      "  Epoch [51/76], Batch [350/352], Train Acc: 99.4018 Loss: 0.5380\n",
      "  Validation Accuracy after Epoch 51: 92.1800\n",
      "  Cidar10.1 Accuracy: 84.55\n",
      "  Epoch [52/76], Batch [350/352], Train Acc: 99.4040 Loss: 0.5374\n",
      "  Validation Accuracy after Epoch 52: 92.9200\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [53/76], Batch [350/352], Train Acc: 99.5513 Loss: 0.5419\n",
      "  Validation Accuracy after Epoch 53: 92.2800\n",
      "  Cidar10.1 Accuracy: 84.7\n",
      "  Epoch [54/76], Batch [350/352], Train Acc: 99.6540 Loss: 0.5395\n",
      "  Validation Accuracy after Epoch 54: 92.7200\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "  Epoch [55/76], Batch [350/352], Train Acc: 99.6897 Loss: 0.5209\n",
      "  Validation Accuracy after Epoch 55: 92.7400\n",
      "  Cidar10.1 Accuracy: 84.85\n",
      "  Epoch [56/76], Batch [350/352], Train Acc: 99.6942 Loss: 0.5249\n",
      "  Validation Accuracy after Epoch 56: 93.0200\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [57/76], Batch [350/352], Train Acc: 99.7701 Loss: 0.5254\n",
      "  Validation Accuracy after Epoch 57: 92.9200\n",
      "  Cidar10.1 Accuracy: 84.85\n",
      "  Epoch [58/76], Batch [350/352], Train Acc: 99.8080 Loss: 0.5167\n",
      "  Validation Accuracy after Epoch 58: 93.0400\n",
      "  Cidar10.1 Accuracy: 85.9\n",
      "  Epoch [59/76], Batch [350/352], Train Acc: 99.8036 Loss: 0.5195\n",
      "  Validation Accuracy after Epoch 59: 93.1600\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [60/76], Batch [350/352], Train Acc: 99.7790 Loss: 0.5091\n",
      "  Validation Accuracy after Epoch 60: 93.4400\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [61/76], Batch [350/352], Train Acc: 99.8705 Loss: 0.5149\n",
      "  Validation Accuracy after Epoch 61: 93.1200\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [62/76], Batch [350/352], Train Acc: 99.8616 Loss: 0.5097\n",
      "  Validation Accuracy after Epoch 62: 93.2000\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [63/76], Batch [350/352], Train Acc: 99.9040 Loss: 0.5199\n",
      "  Validation Accuracy after Epoch 63: 92.9800\n",
      "  Cidar10.1 Accuracy: 86.25\n",
      "  Epoch [64/76], Batch [350/352], Train Acc: 99.9085 Loss: 0.5119\n",
      "  Validation Accuracy after Epoch 64: 93.6400\n",
      "  Cidar10.1 Accuracy: 86.55\n",
      "  Epoch [65/76], Batch [350/352], Train Acc: 99.9018 Loss: 0.5089\n",
      "  Validation Accuracy after Epoch 65: 93.0800\n",
      "  Cidar10.1 Accuracy: 86.6\n",
      "  Epoch [66/76], Batch [350/352], Train Acc: 99.9241 Loss: 0.5115\n",
      "  Validation Accuracy after Epoch 66: 93.4000\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [67/76], Batch [350/352], Train Acc: 99.9085 Loss: 0.5084\n",
      "  Validation Accuracy after Epoch 67: 93.4000\n",
      "  Cidar10.1 Accuracy: 86.75\n",
      "  Epoch [68/76], Batch [350/352], Train Acc: 99.9487 Loss: 0.5087\n",
      "  Validation Accuracy after Epoch 68: 93.4200\n",
      "  Cidar10.1 Accuracy: 86.8\n",
      "  Epoch [69/76], Batch [350/352], Train Acc: 99.9241 Loss: 0.5076\n",
      "  Validation Accuracy after Epoch 69: 93.0400\n",
      "  Cidar10.1 Accuracy: 86.4\n",
      "  Epoch [70/76], Batch [350/352], Train Acc: 99.9397 Loss: 0.5098\n",
      "  Validation Accuracy after Epoch 70: 93.4800\n",
      "  Cidar10.1 Accuracy: 86.85\n",
      "  Epoch [71/76], Batch [350/352], Train Acc: 99.9799 Loss: 0.5068\n",
      "  Validation Accuracy after Epoch 71: 93.0400\n",
      "  Cidar10.1 Accuracy: 86.85\n",
      "  Epoch [72/76], Batch [350/352], Train Acc: 99.9397 Loss: 0.5058\n",
      "  Validation Accuracy after Epoch 72: 93.2200\n",
      "  Cidar10.1 Accuracy: 86.95\n",
      "  Epoch [73/76], Batch [350/352], Train Acc: 99.9464 Loss: 0.5070\n",
      "  Validation Accuracy after Epoch 73: 93.0000\n",
      "  Cidar10.1 Accuracy: 87.0\n",
      "  Epoch [74/76], Batch [350/352], Train Acc: 99.9688 Loss: 0.5120\n",
      "  Validation Accuracy after Epoch 74: 93.3400\n",
      "  Cidar10.1 Accuracy: 86.85\n",
      "  Epoch [75/76], Batch [350/352], Train Acc: 99.9732 Loss: 0.5071\n",
      "  Validation Accuracy after Epoch 75: 93.6400\n",
      "  Cidar10.1 Accuracy: 87.05\n",
      "  Epoch [76/76], Batch [350/352], Train Acc: 99.9777 Loss: 0.5085\n",
      "  Validation Accuracy after Epoch 76: 93.3400\n",
      "  Cidar10.1 Accuracy: 86.85\n",
      "Trial 21 complete. Best Validation Accuracy: 93.6400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 06:20:40,150] Trial 21 finished with value: 93.64 and parameters: {'num_epochs': 76, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8989450645955427, 'beta2': 0.9958117445521014, 'lr': 0.0010497858203851631, 'weight_decay': 0.0021788986817215493, 'max_lr': 0.005119536702611704}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=22\n",
      "num_epochs: 76\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8892095972869166\n",
      "beta2: 0.9952335347814336\n",
      "lr: 0.0012216922003737806\n",
      "weight_decay: 0.002300171785168988\n",
      "max_lr: 0.004790854126159991\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/76], Batch [350/352], Train Acc: 44.9598 Loss: 1.5482\n",
      "  Validation Accuracy after Epoch 1: 54.5600\n",
      "  Cidar10.1 Accuracy: 44.25\n",
      "  Epoch [2/76], Batch [350/352], Train Acc: 61.6786 Loss: 1.2348\n",
      "  Validation Accuracy after Epoch 2: 63.5000\n",
      "  Cidar10.1 Accuracy: 51.15\n",
      "  Epoch [3/76], Batch [350/352], Train Acc: 68.9241 Loss: 1.2612\n",
      "  Validation Accuracy after Epoch 3: 68.2600\n",
      "  Cidar10.1 Accuracy: 56.15\n",
      "  Epoch [4/76], Batch [350/352], Train Acc: 73.3058 Loss: 1.1454\n",
      "  Validation Accuracy after Epoch 4: 68.9600\n",
      "  Cidar10.1 Accuracy: 54.65\n",
      "  Epoch [5/76], Batch [350/352], Train Acc: 75.8192 Loss: 1.0369\n",
      "  Validation Accuracy after Epoch 5: 75.1600\n",
      "  Cidar10.1 Accuracy: 65.7\n",
      "  Epoch [6/76], Batch [350/352], Train Acc: 77.6071 Loss: 0.9840\n",
      "  Validation Accuracy after Epoch 6: 77.1200\n",
      "  Cidar10.1 Accuracy: 66.9\n",
      "  Epoch [7/76], Batch [350/352], Train Acc: 79.6652 Loss: 0.9394\n",
      "  Validation Accuracy after Epoch 7: 75.1800\n",
      "  Cidar10.1 Accuracy: 62.75\n",
      "  Epoch [8/76], Batch [350/352], Train Acc: 81.0625 Loss: 0.9826\n",
      "  Validation Accuracy after Epoch 8: 75.8800\n",
      "  Cidar10.1 Accuracy: 67.55\n",
      "  Epoch [9/76], Batch [350/352], Train Acc: 82.0022 Loss: 1.0052\n",
      "  Validation Accuracy after Epoch 9: 76.7800\n",
      "  Cidar10.1 Accuracy: 63.75\n",
      "  Epoch [10/76], Batch [350/352], Train Acc: 83.3594 Loss: 0.8228\n",
      "  Validation Accuracy after Epoch 10: 77.3400\n",
      "  Cidar10.1 Accuracy: 67.0\n",
      "  Epoch [11/76], Batch [350/352], Train Acc: 84.2143 Loss: 0.9754\n",
      "  Validation Accuracy after Epoch 11: 80.8200\n",
      "  Cidar10.1 Accuracy: 70.9\n",
      "  Epoch [12/76], Batch [350/352], Train Acc: 85.2344 Loss: 0.7818\n",
      "  Validation Accuracy after Epoch 12: 84.7400\n",
      "  Cidar10.1 Accuracy: 72.75\n",
      "  Epoch [13/76], Batch [350/352], Train Acc: 86.2388 Loss: 0.8589\n",
      "  Validation Accuracy after Epoch 13: 84.4200\n",
      "  Cidar10.1 Accuracy: 73.95\n",
      "  Epoch [14/76], Batch [350/352], Train Acc: 87.1920 Loss: 0.8022\n",
      "  Validation Accuracy after Epoch 14: 82.1600\n",
      "  Cidar10.1 Accuracy: 71.4\n",
      "  Epoch [15/76], Batch [350/352], Train Acc: 87.8571 Loss: 0.8243\n",
      "  Validation Accuracy after Epoch 15: 84.3800\n",
      "  Cidar10.1 Accuracy: 72.9\n",
      "  Epoch [16/76], Batch [350/352], Train Acc: 88.3817 Loss: 0.8743\n",
      "  Validation Accuracy after Epoch 16: 82.2200\n",
      "  Cidar10.1 Accuracy: 69.65\n",
      "  Epoch [17/76], Batch [350/352], Train Acc: 89.1674 Loss: 0.7010\n",
      "  Validation Accuracy after Epoch 17: 85.2000\n",
      "  Cidar10.1 Accuracy: 75.95\n",
      "  Epoch [18/76], Batch [350/352], Train Acc: 89.8036 Loss: 0.7497\n",
      "  Validation Accuracy after Epoch 18: 86.7200\n",
      "  Cidar10.1 Accuracy: 78.45\n",
      "  Epoch [19/76], Batch [350/352], Train Acc: 90.6004 Loss: 0.7432\n",
      "  Validation Accuracy after Epoch 19: 87.0200\n",
      "  Cidar10.1 Accuracy: 78.4\n",
      "  Epoch [20/76], Batch [350/352], Train Acc: 91.1629 Loss: 0.7439\n",
      "  Validation Accuracy after Epoch 20: 86.6000\n",
      "  Cidar10.1 Accuracy: 78.05\n",
      "  Epoch [21/76], Batch [350/352], Train Acc: 91.3348 Loss: 0.7679\n",
      "  Validation Accuracy after Epoch 21: 87.1400\n",
      "  Cidar10.1 Accuracy: 78.0\n",
      "  Epoch [22/76], Batch [350/352], Train Acc: 92.3996 Loss: 0.6597\n",
      "  Validation Accuracy after Epoch 22: 88.5200\n",
      "  Cidar10.1 Accuracy: 79.8\n",
      "  Epoch [23/76], Batch [350/352], Train Acc: 92.7076 Loss: 0.6557\n",
      "  Validation Accuracy after Epoch 23: 88.5800\n",
      "  Cidar10.1 Accuracy: 78.35\n",
      "  Epoch [24/76], Batch [350/352], Train Acc: 93.2812 Loss: 0.6846\n",
      "  Validation Accuracy after Epoch 24: 88.7800\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [25/76], Batch [350/352], Train Acc: 93.7835 Loss: 0.6910\n",
      "  Validation Accuracy after Epoch 25: 88.3600\n",
      "  Cidar10.1 Accuracy: 79.7\n",
      "  Epoch [26/76], Batch [350/352], Train Acc: 94.3103 Loss: 0.7421\n",
      "  Validation Accuracy after Epoch 26: 89.1600\n",
      "  Cidar10.1 Accuracy: 81.3\n",
      "  Epoch [27/76], Batch [350/352], Train Acc: 94.6585 Loss: 0.6743\n",
      "  Validation Accuracy after Epoch 27: 89.3000\n",
      "  Cidar10.1 Accuracy: 80.45\n",
      "  Epoch [28/76], Batch [350/352], Train Acc: 94.8750 Loss: 0.6011\n",
      "  Validation Accuracy after Epoch 28: 89.5400\n",
      "  Cidar10.1 Accuracy: 81.95\n",
      "  Epoch [29/76], Batch [350/352], Train Acc: 95.1786 Loss: 0.6444\n",
      "  Validation Accuracy after Epoch 29: 89.6000\n",
      "  Cidar10.1 Accuracy: 80.85\n",
      "  Epoch [30/76], Batch [350/352], Train Acc: 95.6786 Loss: 0.6225\n",
      "  Validation Accuracy after Epoch 30: 89.9400\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [31/76], Batch [350/352], Train Acc: 96.0223 Loss: 0.6030\n",
      "  Validation Accuracy after Epoch 31: 88.6600\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [32/76], Batch [350/352], Train Acc: 96.3348 Loss: 0.5784\n",
      "  Validation Accuracy after Epoch 32: 90.3400\n",
      "  Cidar10.1 Accuracy: 82.65\n",
      "  Epoch [33/76], Batch [350/352], Train Acc: 96.6272 Loss: 0.6384\n",
      "  Validation Accuracy after Epoch 33: 90.1200\n",
      "  Cidar10.1 Accuracy: 81.35\n",
      "  Epoch [34/76], Batch [350/352], Train Acc: 96.9353 Loss: 0.5750\n",
      "  Validation Accuracy after Epoch 34: 90.5800\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [35/76], Batch [350/352], Train Acc: 97.0379 Loss: 0.6003\n",
      "  Validation Accuracy after Epoch 35: 91.1800\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [36/76], Batch [350/352], Train Acc: 97.1719 Loss: 0.5898\n",
      "  Validation Accuracy after Epoch 36: 91.1000\n",
      "  Cidar10.1 Accuracy: 83.2\n",
      "  Epoch [37/76], Batch [350/352], Train Acc: 97.4040 Loss: 0.5658\n",
      "  Validation Accuracy after Epoch 37: 90.4600\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [38/76], Batch [350/352], Train Acc: 97.6607 Loss: 0.5452\n",
      "  Validation Accuracy after Epoch 38: 91.3400\n",
      "  Cidar10.1 Accuracy: 83.95\n",
      "  Epoch [39/76], Batch [350/352], Train Acc: 97.9777 Loss: 0.5607\n",
      "  Validation Accuracy after Epoch 39: 91.3400\n",
      "  Cidar10.1 Accuracy: 83.2\n",
      "  Epoch [40/76], Batch [350/352], Train Acc: 98.1540 Loss: 0.5683\n",
      "  Validation Accuracy after Epoch 40: 90.8000\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [41/76], Batch [350/352], Train Acc: 98.2545 Loss: 0.5674\n",
      "  Validation Accuracy after Epoch 41: 91.6600\n",
      "  Cidar10.1 Accuracy: 83.05\n",
      "  Epoch [42/76], Batch [350/352], Train Acc: 98.4621 Loss: 0.5924\n",
      "  Validation Accuracy after Epoch 42: 91.5200\n",
      "  Cidar10.1 Accuracy: 84.3\n",
      "  Epoch [43/76], Batch [350/352], Train Acc: 98.4621 Loss: 0.5594\n",
      "  Validation Accuracy after Epoch 43: 91.4200\n",
      "  Cidar10.1 Accuracy: 84.35\n",
      "  Epoch [44/76], Batch [350/352], Train Acc: 98.7188 Loss: 0.5251\n",
      "  Validation Accuracy after Epoch 44: 91.9600\n",
      "  Cidar10.1 Accuracy: 84.45\n",
      "  Epoch [45/76], Batch [350/352], Train Acc: 98.8973 Loss: 0.5312\n",
      "  Validation Accuracy after Epoch 45: 91.7600\n",
      "  Cidar10.1 Accuracy: 84.1\n",
      "  Epoch [46/76], Batch [350/352], Train Acc: 98.9754 Loss: 0.5850\n",
      "  Validation Accuracy after Epoch 46: 91.9800\n",
      "  Cidar10.1 Accuracy: 83.95\n",
      "  Epoch [47/76], Batch [350/352], Train Acc: 99.0692 Loss: 0.5495\n",
      "  Validation Accuracy after Epoch 47: 92.0600\n",
      "  Cidar10.1 Accuracy: 85.0\n",
      "  Epoch [48/76], Batch [350/352], Train Acc: 99.2656 Loss: 0.5369\n",
      "  Validation Accuracy after Epoch 48: 91.9000\n",
      "  Cidar10.1 Accuracy: 85.5\n",
      "  Epoch [49/76], Batch [350/352], Train Acc: 99.2031 Loss: 0.5305\n",
      "  Validation Accuracy after Epoch 49: 92.4200\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [50/76], Batch [350/352], Train Acc: 99.4174 Loss: 0.5324\n",
      "  Validation Accuracy after Epoch 50: 92.6400\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [51/76], Batch [350/352], Train Acc: 99.4643 Loss: 0.5326\n",
      "  Validation Accuracy after Epoch 51: 92.6800\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [52/76], Batch [350/352], Train Acc: 99.5089 Loss: 0.5219\n",
      "  Validation Accuracy after Epoch 52: 92.5800\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [53/76], Batch [350/352], Train Acc: 99.5357 Loss: 0.5266\n",
      "  Validation Accuracy after Epoch 53: 92.5600\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [54/76], Batch [350/352], Train Acc: 99.6004 Loss: 0.5198\n",
      "  Validation Accuracy after Epoch 54: 92.2600\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [55/76], Batch [350/352], Train Acc: 99.6496 Loss: 0.5201\n",
      "  Validation Accuracy after Epoch 55: 92.9000\n",
      "  Cidar10.1 Accuracy: 85.8\n",
      "  Epoch [56/76], Batch [350/352], Train Acc: 99.7344 Loss: 0.5224\n",
      "  Validation Accuracy after Epoch 56: 92.5200\n",
      "  Cidar10.1 Accuracy: 86.3\n",
      "  Epoch [57/76], Batch [350/352], Train Acc: 99.7254 Loss: 0.5272\n",
      "  Validation Accuracy after Epoch 57: 92.5400\n",
      "  Cidar10.1 Accuracy: 86.35\n",
      "  Epoch [58/76], Batch [350/352], Train Acc: 99.7857 Loss: 0.5115\n",
      "  Validation Accuracy after Epoch 58: 92.6800\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [59/76], Batch [350/352], Train Acc: 99.8214 Loss: 0.5167\n",
      "  Validation Accuracy after Epoch 59: 93.1200\n",
      "  Cidar10.1 Accuracy: 86.2\n",
      "  Epoch [60/76], Batch [350/352], Train Acc: 99.8438 Loss: 0.5129\n",
      "  Validation Accuracy after Epoch 60: 93.4000\n",
      "  Cidar10.1 Accuracy: 86.6\n",
      "  Epoch [61/76], Batch [350/352], Train Acc: 99.8415 Loss: 0.5145\n",
      "  Validation Accuracy after Epoch 61: 92.9000\n",
      "  Cidar10.1 Accuracy: 86.3\n",
      "  Epoch [62/76], Batch [350/352], Train Acc: 99.8683 Loss: 0.5083\n",
      "  Validation Accuracy after Epoch 62: 92.8400\n",
      "  Cidar10.1 Accuracy: 86.1\n",
      "  Epoch [63/76], Batch [350/352], Train Acc: 99.8839 Loss: 0.5197\n",
      "  Validation Accuracy after Epoch 63: 92.5400\n",
      "  Cidar10.1 Accuracy: 85.95\n",
      "  Epoch [64/76], Batch [350/352], Train Acc: 99.8817 Loss: 0.5191\n",
      "  Validation Accuracy after Epoch 64: 93.2600\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [65/76], Batch [350/352], Train Acc: 99.9107 Loss: 0.5122\n",
      "  Validation Accuracy after Epoch 65: 93.3800\n",
      "  Cidar10.1 Accuracy: 86.75\n",
      "  Epoch [66/76], Batch [350/352], Train Acc: 99.9263 Loss: 0.5140\n",
      "  Validation Accuracy after Epoch 66: 93.1600\n",
      "  Cidar10.1 Accuracy: 86.7\n",
      "  Epoch [67/76], Batch [350/352], Train Acc: 99.9531 Loss: 0.5085\n",
      "  Validation Accuracy after Epoch 67: 93.3600\n",
      "  Cidar10.1 Accuracy: 86.45\n",
      "  Epoch [68/76], Batch [350/352], Train Acc: 99.9576 Loss: 0.5090\n",
      "  Validation Accuracy after Epoch 68: 93.3200\n",
      "  Cidar10.1 Accuracy: 86.7\n",
      "  Epoch [69/76], Batch [350/352], Train Acc: 99.9353 Loss: 0.5123\n",
      "  Validation Accuracy after Epoch 69: 93.0800\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [70/76], Batch [350/352], Train Acc: 99.9487 Loss: 0.5166\n",
      "  Validation Accuracy after Epoch 70: 93.1800\n",
      "  Cidar10.1 Accuracy: 86.55\n",
      "  Epoch [71/76], Batch [350/352], Train Acc: 99.9554 Loss: 0.5135\n",
      "  Validation Accuracy after Epoch 71: 93.5000\n",
      "  Cidar10.1 Accuracy: 86.6\n",
      "  Epoch [72/76], Batch [350/352], Train Acc: 99.9598 Loss: 0.5096\n",
      "  Validation Accuracy after Epoch 72: 93.1800\n",
      "  Cidar10.1 Accuracy: 86.3\n",
      "  Epoch [73/76], Batch [350/352], Train Acc: 99.9732 Loss: 0.5080\n",
      "  Validation Accuracy after Epoch 73: 93.4000\n",
      "  Cidar10.1 Accuracy: 86.9\n",
      "  Epoch [74/76], Batch [350/352], Train Acc: 99.9554 Loss: 0.5134\n",
      "  Validation Accuracy after Epoch 74: 93.3600\n",
      "  Cidar10.1 Accuracy: 86.75\n",
      "  Epoch [75/76], Batch [350/352], Train Acc: 99.9754 Loss: 0.5060\n",
      "  Validation Accuracy after Epoch 75: 93.3800\n",
      "  Cidar10.1 Accuracy: 86.75\n",
      "  Epoch [76/76], Batch [350/352], Train Acc: 99.9554 Loss: 0.5067\n",
      "  Validation Accuracy after Epoch 76: 93.0800\n",
      "  Cidar10.1 Accuracy: 86.6\n",
      "Trial 22 complete. Best Validation Accuracy: 93.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 06:32:54,216] Trial 22 finished with value: 93.5 and parameters: {'num_epochs': 76, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8892095972869166, 'beta2': 0.9952335347814336, 'lr': 0.0012216922003737806, 'weight_decay': 0.002300171785168988, 'max_lr': 0.004790854126159991}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=23\n",
      "num_epochs: 63\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9066341681534535\n",
      "beta2: 0.9945001521636125\n",
      "lr: 0.0012798428035638134\n",
      "weight_decay: 0.0997729796430048\n",
      "max_lr: 0.0033205714453662747\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/63], Batch [350/352], Train Acc: 43.8281 Loss: 1.6026\n",
      "  Validation Accuracy after Epoch 1: 52.2600\n",
      "  Cidar10.1 Accuracy: 44.2\n",
      "  Epoch [2/63], Batch [350/352], Train Acc: 59.7076 Loss: 1.3059\n",
      "  Validation Accuracy after Epoch 2: 61.9600\n",
      "  Cidar10.1 Accuracy: 49.8\n",
      "  Epoch [3/63], Batch [350/352], Train Acc: 66.3884 Loss: 1.3199\n",
      "  Validation Accuracy after Epoch 3: 65.2200\n",
      "  Cidar10.1 Accuracy: 53.1\n",
      "  Epoch [4/63], Batch [350/352], Train Acc: 71.2656 Loss: 1.1055\n",
      "  Validation Accuracy after Epoch 4: 70.0600\n",
      "  Cidar10.1 Accuracy: 55.5\n",
      "  Epoch [5/63], Batch [350/352], Train Acc: 74.0692 Loss: 1.1618\n",
      "  Validation Accuracy after Epoch 5: 73.4800\n",
      "  Cidar10.1 Accuracy: 62.3\n",
      "  Epoch [6/63], Batch [350/352], Train Acc: 76.7031 Loss: 1.1764\n",
      "  Validation Accuracy after Epoch 6: 69.9600\n",
      "  Cidar10.1 Accuracy: 58.4\n",
      "  Epoch [7/63], Batch [350/352], Train Acc: 77.9821 Loss: 1.0327\n",
      "  Validation Accuracy after Epoch 7: 69.2800\n",
      "  Cidar10.1 Accuracy: 57.1\n",
      "  Epoch [8/63], Batch [350/352], Train Acc: 79.7790 Loss: 1.0159\n",
      "  Validation Accuracy after Epoch 8: 76.1000\n",
      "  Cidar10.1 Accuracy: 65.0\n",
      "  Epoch [9/63], Batch [350/352], Train Acc: 81.1786 Loss: 0.9422\n",
      "  Validation Accuracy after Epoch 9: 78.6000\n",
      "  Cidar10.1 Accuracy: 67.5\n",
      "  Epoch [10/63], Batch [350/352], Train Acc: 82.3638 Loss: 0.9594\n",
      "  Validation Accuracy after Epoch 10: 72.9200\n",
      "  Cidar10.1 Accuracy: 60.0\n",
      "  Epoch [11/63], Batch [350/352], Train Acc: 83.3259 Loss: 0.8699\n",
      "  Validation Accuracy after Epoch 11: 81.2400\n",
      "  Cidar10.1 Accuracy: 68.85\n",
      "  Epoch [12/63], Batch [350/352], Train Acc: 84.2701 Loss: 0.8489\n",
      "  Validation Accuracy after Epoch 12: 81.6200\n",
      "  Cidar10.1 Accuracy: 71.45\n",
      "  Epoch [13/63], Batch [350/352], Train Acc: 85.2009 Loss: 0.8223\n",
      "  Validation Accuracy after Epoch 13: 80.3600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 06:35:01,339] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=24\n",
      "num_epochs: 74\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9237793377344584\n",
      "beta2: 0.9936891185794973\n",
      "lr: 0.0006419363282453342\n",
      "weight_decay: 0.002131817133368106\n",
      "max_lr: 0.005485628581173591\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/74], Batch [350/352], Train Acc: 45.0446 Loss: 1.5614\n",
      "  Validation Accuracy after Epoch 1: 53.8400\n",
      "  Cidar10.1 Accuracy: 43.7\n",
      "  Epoch [2/74], Batch [350/352], Train Acc: 61.8237 Loss: 1.3453\n",
      "  Validation Accuracy after Epoch 2: 63.2400\n",
      "  Cidar10.1 Accuracy: 51.8\n",
      "  Epoch [3/74], Batch [350/352], Train Acc: 69.4308 Loss: 1.0852\n",
      "  Validation Accuracy after Epoch 3: 68.4400\n",
      "  Cidar10.1 Accuracy: 53.8\n",
      "  Epoch [4/74], Batch [350/352], Train Acc: 73.6317 Loss: 1.1833\n",
      "  Validation Accuracy after Epoch 4: 67.6400\n",
      "  Cidar10.1 Accuracy: 55.85\n",
      "  Epoch [5/74], Batch [350/352], Train Acc: 76.1384 Loss: 1.0549\n",
      "  Validation Accuracy after Epoch 5: 73.1000\n",
      "  Cidar10.1 Accuracy: 59.55\n",
      "  Epoch [6/74], Batch [350/352], Train Acc: 77.9308 Loss: 0.9752\n",
      "  Validation Accuracy after Epoch 6: 76.4200\n",
      "  Cidar10.1 Accuracy: 63.0\n",
      "  Epoch [7/74], Batch [350/352], Train Acc: 79.5893 Loss: 1.0909\n",
      "  Validation Accuracy after Epoch 7: 74.3400\n",
      "  Cidar10.1 Accuracy: 64.1\n",
      "  Epoch [8/74], Batch [350/352], Train Acc: 81.0424 Loss: 0.9963\n",
      "  Validation Accuracy after Epoch 8: 78.7600\n",
      "  Cidar10.1 Accuracy: 67.35\n",
      "  Epoch [9/74], Batch [350/352], Train Acc: 82.4665 Loss: 0.9097\n",
      "  Validation Accuracy after Epoch 9: 76.1200\n",
      "  Cidar10.1 Accuracy: 64.55\n",
      "  Epoch [10/74], Batch [350/352], Train Acc: 83.4286 Loss: 0.8538\n",
      "  Validation Accuracy after Epoch 10: 83.3800\n",
      "  Cidar10.1 Accuracy: 71.35\n",
      "  Epoch [11/74], Batch [350/352], Train Acc: 84.4955 Loss: 0.9431\n",
      "  Validation Accuracy after Epoch 11: 77.0200\n",
      "  Cidar10.1 Accuracy: 64.1\n",
      "  Epoch [12/74], Batch [350/352], Train Acc: 85.4554 Loss: 0.9400\n",
      "  Validation Accuracy after Epoch 12: 82.5000\n",
      "  Cidar10.1 Accuracy: 69.45\n",
      "  Epoch [13/74], Batch [350/352], Train Acc: 86.5268 Loss: 0.8515\n",
      "  Validation Accuracy after Epoch 13: 85.1400\n",
      "  Cidar10.1 Accuracy: 75.4\n",
      "  Epoch [14/74], Batch [350/352], Train Acc: 87.3371 Loss: 0.8095\n",
      "  Validation Accuracy after Epoch 14: 83.7600\n",
      "  Cidar10.1 Accuracy: 72.5\n",
      "  Epoch [15/74], Batch [350/352], Train Acc: 87.9330 Loss: 0.8327\n",
      "  Validation Accuracy after Epoch 15: 85.5200\n",
      "  Cidar10.1 Accuracy: 72.85\n",
      "  Epoch [16/74], Batch [350/352], Train Acc: 88.7143 Loss: 0.8519\n",
      "  Validation Accuracy after Epoch 16: 82.5600\n",
      "  Cidar10.1 Accuracy: 74.05\n",
      "  Epoch [17/74], Batch [350/352], Train Acc: 89.5134 Loss: 0.7476\n",
      "  Validation Accuracy after Epoch 17: 82.0800\n",
      "  Cidar10.1 Accuracy: 71.1\n",
      "  Epoch [18/74], Batch [350/352], Train Acc: 89.7812 Loss: 0.8244\n",
      "  Validation Accuracy after Epoch 18: 85.7600\n",
      "  Cidar10.1 Accuracy: 76.45\n",
      "  Epoch [19/74], Batch [350/352], Train Acc: 90.8013 Loss: 0.7850\n",
      "  Validation Accuracy after Epoch 19: 84.9400\n",
      "  Cidar10.1 Accuracy: 75.95\n",
      "  Epoch [20/74], Batch [350/352], Train Acc: 91.2054 Loss: 0.7279\n",
      "  Validation Accuracy after Epoch 20: 85.6800\n",
      "  Cidar10.1 Accuracy: 76.6\n",
      "  Epoch [21/74], Batch [350/352], Train Acc: 91.7344 Loss: 0.7165\n",
      "  Validation Accuracy after Epoch 21: 88.2400\n",
      "  Cidar10.1 Accuracy: 79.2\n",
      "  Epoch [22/74], Batch [350/352], Train Acc: 92.3683 Loss: 0.7265\n",
      "  Validation Accuracy after Epoch 22: 87.6600\n",
      "  Cidar10.1 Accuracy: 78.55\n",
      "  Epoch [23/74], Batch [350/352], Train Acc: 92.8147 Loss: 0.6419\n",
      "  Validation Accuracy after Epoch 23: 88.1800\n",
      "  Cidar10.1 Accuracy: 80.25\n",
      "  Epoch [24/74], Batch [350/352], Train Acc: 93.1652 Loss: 0.6665\n",
      "  Validation Accuracy after Epoch 24: 88.9600\n",
      "  Cidar10.1 Accuracy: 80.0\n",
      "  Epoch [25/74], Batch [350/352], Train Acc: 93.7946 Loss: 0.6825\n",
      "  Validation Accuracy after Epoch 25: 87.5200\n",
      "  Cidar10.1 Accuracy: 78.35\n",
      "  Epoch [26/74], Batch [350/352], Train Acc: 94.2165 Loss: 0.6405\n",
      "  Validation Accuracy after Epoch 26: 89.3600\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [27/74], Batch [350/352], Train Acc: 94.6496 Loss: 0.6674\n",
      "  Validation Accuracy after Epoch 27: 88.8600\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [28/74], Batch [350/352], Train Acc: 95.0201 Loss: 0.6487\n",
      "  Validation Accuracy after Epoch 28: 89.5800\n",
      "  Cidar10.1 Accuracy: 80.0\n",
      "  Epoch [29/74], Batch [350/352], Train Acc: 95.5156 Loss: 0.6069\n",
      "  Validation Accuracy after Epoch 29: 90.1000\n",
      "  Cidar10.1 Accuracy: 81.35\n",
      "  Epoch [30/74], Batch [350/352], Train Acc: 95.7545 Loss: 0.6174\n",
      "  Validation Accuracy after Epoch 30: 90.3400\n",
      "  Cidar10.1 Accuracy: 81.2\n",
      "  Epoch [31/74], Batch [350/352], Train Acc: 96.0826 Loss: 0.6800\n",
      "  Validation Accuracy after Epoch 31: 89.8800\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [32/74], Batch [350/352], Train Acc: 96.2188 Loss: 0.6336\n",
      "  Validation Accuracy after Epoch 32: 90.1000\n",
      "  Cidar10.1 Accuracy: 80.15\n",
      "  Epoch [33/74], Batch [350/352], Train Acc: 96.6652 Loss: 0.6005\n",
      "  Validation Accuracy after Epoch 33: 90.6400\n",
      "  Cidar10.1 Accuracy: 80.9\n",
      "  Epoch [34/74], Batch [350/352], Train Acc: 96.9688 Loss: 0.6139\n",
      "  Validation Accuracy after Epoch 34: 90.8400\n",
      "  Cidar10.1 Accuracy: 82.65\n",
      "  Epoch [35/74], Batch [350/352], Train Acc: 97.1384 Loss: 0.6146\n",
      "  Validation Accuracy after Epoch 35: 90.5400\n",
      "  Cidar10.1 Accuracy: 83.25\n",
      "  Epoch [36/74], Batch [350/352], Train Acc: 97.4844 Loss: 0.5742\n",
      "  Validation Accuracy after Epoch 36: 90.9200\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [37/74], Batch [350/352], Train Acc: 97.6295 Loss: 0.5616\n",
      "  Validation Accuracy after Epoch 37: 90.9800\n",
      "  Cidar10.1 Accuracy: 81.3\n",
      "  Epoch [38/74], Batch [350/352], Train Acc: 97.8683 Loss: 0.5813\n",
      "  Validation Accuracy after Epoch 38: 91.3800\n",
      "  Cidar10.1 Accuracy: 81.9\n",
      "  Epoch [39/74], Batch [350/352], Train Acc: 97.9353 Loss: 0.5871\n",
      "  Validation Accuracy after Epoch 39: 90.9000\n",
      "  Cidar10.1 Accuracy: 83.3\n",
      "  Epoch [40/74], Batch [350/352], Train Acc: 98.1295 Loss: 0.5638\n",
      "  Validation Accuracy after Epoch 40: 90.5600\n",
      "  Cidar10.1 Accuracy: 82.7\n",
      "  Epoch [41/74], Batch [350/352], Train Acc: 98.2656 Loss: 0.5442\n",
      "  Validation Accuracy after Epoch 41: 91.9600\n",
      "  Cidar10.1 Accuracy: 84.05\n",
      "  Epoch [42/74], Batch [350/352], Train Acc: 98.5246 Loss: 0.5480\n",
      "  Validation Accuracy after Epoch 42: 91.4600\n",
      "  Cidar10.1 Accuracy: 84.4\n",
      "  Epoch [43/74], Batch [350/352], Train Acc: 98.6071 Loss: 0.5709\n",
      "  Validation Accuracy after Epoch 43: 91.8400\n",
      "  Cidar10.1 Accuracy: 84.55\n",
      "  Epoch [44/74], Batch [350/352], Train Acc: 98.8192 Loss: 0.5485\n",
      "  Validation Accuracy after Epoch 44: 91.8200\n",
      "  Cidar10.1 Accuracy: 84.0\n",
      "  Epoch [45/74], Batch [350/352], Train Acc: 98.8705 Loss: 0.5280\n",
      "  Validation Accuracy after Epoch 45: 91.6200\n",
      "  Cidar10.1 Accuracy: 83.4\n",
      "  Epoch [46/74], Batch [350/352], Train Acc: 98.9844 Loss: 0.5504\n",
      "  Validation Accuracy after Epoch 46: 92.0200\n",
      "  Cidar10.1 Accuracy: 84.15\n",
      "  Epoch [47/74], Batch [350/352], Train Acc: 99.0759 Loss: 0.5530\n",
      "  Validation Accuracy after Epoch 47: 91.9000\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [48/74], Batch [350/352], Train Acc: 99.2344 Loss: 0.5262\n",
      "  Validation Accuracy after Epoch 48: 92.4400\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [49/74], Batch [350/352], Train Acc: 99.3415 Loss: 0.5283\n",
      "  Validation Accuracy after Epoch 49: 92.5000\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [50/74], Batch [350/352], Train Acc: 99.4174 Loss: 0.5231\n",
      "  Validation Accuracy after Epoch 50: 92.5000\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [51/74], Batch [350/352], Train Acc: 99.5201 Loss: 0.5451\n",
      "  Validation Accuracy after Epoch 51: 92.6000\n",
      "  Cidar10.1 Accuracy: 84.75\n",
      "  Epoch [52/74], Batch [350/352], Train Acc: 99.5513 Loss: 0.5409\n",
      "  Validation Accuracy after Epoch 52: 92.2800\n",
      "  Cidar10.1 Accuracy: 84.55\n",
      "  Epoch [53/74], Batch [350/352], Train Acc: 99.5848 Loss: 0.5163\n",
      "  Validation Accuracy after Epoch 53: 92.9600\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [54/74], Batch [350/352], Train Acc: 99.6429 Loss: 0.5420\n",
      "  Validation Accuracy after Epoch 54: 92.7400\n",
      "  Cidar10.1 Accuracy: 86.35\n",
      "  Epoch [55/74], Batch [350/352], Train Acc: 99.7388 Loss: 0.5175\n",
      "  Validation Accuracy after Epoch 55: 92.5600\n",
      "  Cidar10.1 Accuracy: 85.95\n",
      "  Epoch [56/74], Batch [350/352], Train Acc: 99.7254 Loss: 0.5444\n",
      "  Validation Accuracy after Epoch 56: 93.0000\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [57/74], Batch [350/352], Train Acc: 99.8013 Loss: 0.5223\n",
      "  Validation Accuracy after Epoch 57: 92.9200\n",
      "  Cidar10.1 Accuracy: 86.75\n",
      "  Epoch [58/74], Batch [350/352], Train Acc: 99.8259 Loss: 0.5175\n",
      "  Validation Accuracy after Epoch 58: 92.9600\n",
      "  Cidar10.1 Accuracy: 86.55\n",
      "  Epoch [59/74], Batch [350/352], Train Acc: 99.8326 Loss: 0.5171\n",
      "  Validation Accuracy after Epoch 59: 92.5800\n",
      "  Cidar10.1 Accuracy: 86.45\n",
      "  Epoch [60/74], Batch [350/352], Train Acc: 99.8929 Loss: 0.5084\n",
      "  Validation Accuracy after Epoch 60: 93.3800\n",
      "  Cidar10.1 Accuracy: 86.25\n",
      "  Epoch [61/74], Batch [350/352], Train Acc: 99.9196 Loss: 0.5118\n",
      "  Validation Accuracy after Epoch 61: 93.2200\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "  Epoch [62/74], Batch [350/352], Train Acc: 99.8973 Loss: 0.5096\n",
      "  Validation Accuracy after Epoch 62: 93.4600\n",
      "  Cidar10.1 Accuracy: 86.4\n",
      "  Epoch [63/74], Batch [350/352], Train Acc: 99.8951 Loss: 0.5142\n",
      "  Validation Accuracy after Epoch 63: 93.2600\n",
      "  Cidar10.1 Accuracy: 86.15\n",
      "  Epoch [64/74], Batch [350/352], Train Acc: 99.9263 Loss: 0.5137\n",
      "  Validation Accuracy after Epoch 64: 93.3000\n",
      "  Cidar10.1 Accuracy: 85.95\n",
      "  Epoch [65/74], Batch [350/352], Train Acc: 99.9531 Loss: 0.5116\n",
      "  Validation Accuracy after Epoch 65: 93.0800\n",
      "  Cidar10.1 Accuracy: 86.65\n",
      "  Epoch [66/74], Batch [350/352], Train Acc: 99.9397 Loss: 0.5083\n",
      "  Validation Accuracy after Epoch 66: 93.3600\n",
      "  Cidar10.1 Accuracy: 86.5\n",
      "  Epoch [67/74], Batch [350/352], Train Acc: 99.9531 Loss: 0.5122\n",
      "  Validation Accuracy after Epoch 67: 93.2800\n",
      "  Cidar10.1 Accuracy: 86.4\n",
      "  Epoch [68/74], Batch [350/352], Train Acc: 99.9509 Loss: 0.5169\n",
      "  Validation Accuracy after Epoch 68: 93.4400\n",
      "  Cidar10.1 Accuracy: 86.65\n",
      "  Epoch [69/74], Batch [350/352], Train Acc: 99.9375 Loss: 0.5072\n",
      "  Validation Accuracy after Epoch 69: 93.3600\n",
      "  Cidar10.1 Accuracy: 87.1\n",
      "  Epoch [70/74], Batch [350/352], Train Acc: 99.9598 Loss: 0.5117\n",
      "  Validation Accuracy after Epoch 70: 93.2200\n",
      "  Cidar10.1 Accuracy: 87.05\n",
      "  Epoch [71/74], Batch [350/352], Train Acc: 99.9420 Loss: 0.5084\n",
      "  Validation Accuracy after Epoch 71: 93.5600\n",
      "  Cidar10.1 Accuracy: 86.75\n",
      "  Epoch [72/74], Batch [350/352], Train Acc: 99.9531 Loss: 0.5097\n",
      "  Validation Accuracy after Epoch 72: 93.4000\n",
      "  Cidar10.1 Accuracy: 86.9\n",
      "  Epoch [73/74], Batch [350/352], Train Acc: 99.9509 Loss: 0.5083\n",
      "  Validation Accuracy after Epoch 73: 93.7600\n",
      "  Cidar10.1 Accuracy: 86.4\n",
      "  Epoch [74/74], Batch [350/352], Train Acc: 99.9710 Loss: 0.5070\n",
      "  Validation Accuracy after Epoch 74: 93.2800\n",
      "  Cidar10.1 Accuracy: 86.85\n",
      "Trial 24 complete. Best Validation Accuracy: 93.7600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 06:46:53,918] Trial 24 finished with value: 93.76 and parameters: {'num_epochs': 74, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.9237793377344584, 'beta2': 0.9936891185794973, 'lr': 0.0006419363282453342, 'weight_decay': 0.002131817133368106, 'max_lr': 0.005485628581173591}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=25\n",
      "num_epochs: 84\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9428400373757252\n",
      "beta2: 0.9937819065658108\n",
      "lr: 0.002056578257710991\n",
      "weight_decay: 0.013935024052936505\n",
      "max_lr: 0.006501391629359601\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/84], Batch [350/352], Train Acc: 45.3571 Loss: 1.5528\n",
      "  Validation Accuracy after Epoch 1: 53.6200\n",
      "  Cidar10.1 Accuracy: 44.7\n",
      "  Epoch [2/84], Batch [350/352], Train Acc: 62.7031 Loss: 1.2012\n",
      "  Validation Accuracy after Epoch 2: 65.3400\n",
      "  Cidar10.1 Accuracy: 52.5\n",
      "  Epoch [3/84], Batch [350/352], Train Acc: 70.4732 Loss: 1.0393\n",
      "  Validation Accuracy after Epoch 3: 71.6800\n",
      "  Cidar10.1 Accuracy: 57.55\n",
      "  Epoch [4/84], Batch [350/352], Train Acc: 74.1228 Loss: 0.9924\n",
      "  Validation Accuracy after Epoch 4: 68.2000\n",
      "  Cidar10.1 Accuracy: 58.65\n",
      "  Epoch [5/84], Batch [350/352], Train Acc: 76.9888 Loss: 1.1251\n",
      "  Validation Accuracy after Epoch 5: 74.4800\n",
      "  Cidar10.1 Accuracy: 64.05\n",
      "  Epoch [6/84], Batch [350/352], Train Acc: 78.4420 Loss: 0.8695\n",
      "  Validation Accuracy after Epoch 6: 74.2400\n",
      "  Cidar10.1 Accuracy: 61.95\n",
      "  Epoch [7/84], Batch [350/352], Train Acc: 79.8973 Loss: 0.9714\n",
      "  Validation Accuracy after Epoch 7: 77.3800\n",
      "  Cidar10.1 Accuracy: 63.3\n",
      "  Epoch [8/84], Batch [350/352], Train Acc: 81.5960 Loss: 1.0098\n",
      "  Validation Accuracy after Epoch 8: 80.0600\n",
      "  Cidar10.1 Accuracy: 68.45\n",
      "  Epoch [9/84], Batch [350/352], Train Acc: 82.3348 Loss: 0.9334\n",
      "  Validation Accuracy after Epoch 9: 80.7200\n",
      "  Cidar10.1 Accuracy: 70.55\n",
      "  Epoch [10/84], Batch [350/352], Train Acc: 83.7232 Loss: 0.8846\n",
      "  Validation Accuracy after Epoch 10: 77.5400\n",
      "  Cidar10.1 Accuracy: 68.2\n",
      "  Epoch [11/84], Batch [350/352], Train Acc: 84.3661 Loss: 0.8008\n",
      "  Validation Accuracy after Epoch 11: 81.6600\n",
      "  Cidar10.1 Accuracy: 71.45\n",
      "  Epoch [12/84], Batch [350/352], Train Acc: 85.4241 Loss: 0.8790\n",
      "  Validation Accuracy after Epoch 12: 82.8600\n",
      "  Cidar10.1 Accuracy: 73.7\n",
      "  Epoch [13/84], Batch [350/352], Train Acc: 86.1004 Loss: 0.8076\n",
      "  Validation Accuracy after Epoch 13: 83.2400\n",
      "  Cidar10.1 Accuracy: 72.55\n",
      "  Epoch [14/84], Batch [350/352], Train Acc: 87.0982 Loss: 0.7772\n",
      "  Validation Accuracy after Epoch 14: 84.1400\n",
      "  Cidar10.1 Accuracy: 72.4\n",
      "  Epoch [15/84], Batch [350/352], Train Acc: 87.6540 Loss: 0.8396\n",
      "  Validation Accuracy after Epoch 15: 84.6200\n",
      "  Cidar10.1 Accuracy: 73.9\n",
      "  Epoch [16/84], Batch [350/352], Train Acc: 88.3683 Loss: 0.7206\n",
      "  Validation Accuracy after Epoch 16: 85.3400\n",
      "  Cidar10.1 Accuracy: 77.65\n",
      "  Epoch [17/84], Batch [350/352], Train Acc: 88.9509 Loss: 0.8197\n",
      "  Validation Accuracy after Epoch 17: 84.8200\n",
      "  Cidar10.1 Accuracy: 74.75\n",
      "  Epoch [18/84], Batch [350/352], Train Acc: 89.2433 Loss: 0.7560\n",
      "  Validation Accuracy after Epoch 18: 87.3000\n",
      "  Cidar10.1 Accuracy: 78.25\n",
      "  Epoch [19/84], Batch [350/352], Train Acc: 89.5156 Loss: 0.7789\n",
      "  Validation Accuracy after Epoch 19: 85.1600\n",
      "  Cidar10.1 Accuracy: 75.45\n",
      "  Epoch [20/84], Batch [350/352], Train Acc: 90.2121 Loss: 0.8427\n",
      "  Validation Accuracy after Epoch 20: 85.6000\n",
      "  Cidar10.1 Accuracy: 76.2\n",
      "  Epoch [21/84], Batch [350/352], Train Acc: 90.6138 Loss: 0.8067\n",
      "  Validation Accuracy after Epoch 21: 86.8000\n",
      "  Cidar10.1 Accuracy: 77.5\n",
      "  Epoch [22/84], Batch [350/352], Train Acc: 91.2567 Loss: 0.7202\n",
      "  Validation Accuracy after Epoch 22: 87.8800\n",
      "  Cidar10.1 Accuracy: 79.85\n",
      "  Epoch [23/84], Batch [350/352], Train Acc: 91.3013 Loss: 0.6864\n",
      "  Validation Accuracy after Epoch 23: 87.5600\n",
      "  Cidar10.1 Accuracy: 77.1\n",
      "  Epoch [24/84], Batch [350/352], Train Acc: 91.9509 Loss: 0.6809\n",
      "  Validation Accuracy after Epoch 24: 88.0000\n",
      "  Cidar10.1 Accuracy: 79.4\n",
      "  Epoch [25/84], Batch [350/352], Train Acc: 92.4018 Loss: 0.7113\n",
      "  Validation Accuracy after Epoch 25: 87.3000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 06:50:55,214] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=26\n",
      "num_epochs: 94\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9237005066109784\n",
      "beta2: 0.9916430427463933\n",
      "lr: 0.0005442520140501909\n",
      "weight_decay: 0.004998604466921799\n",
      "max_lr: 0.005958193621535537\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/94], Batch [350/352], Train Acc: 45.0156 Loss: 1.5414\n",
      "  Validation Accuracy after Epoch 1: 55.3200\n",
      "  Cidar10.1 Accuracy: 45.25\n",
      "  Epoch [2/94], Batch [350/352], Train Acc: 62.5893 Loss: 1.3104\n",
      "  Validation Accuracy after Epoch 2: 65.1400\n",
      "  Cidar10.1 Accuracy: 54.2\n",
      "  Epoch [3/94], Batch [350/352], Train Acc: 69.6451 Loss: 1.2034\n",
      "  Validation Accuracy after Epoch 3: 72.7200\n",
      "  Cidar10.1 Accuracy: 60.1\n",
      "  Epoch [4/94], Batch [350/352], Train Acc: 74.0089 Loss: 1.1189\n",
      "  Validation Accuracy after Epoch 4: 72.0000\n",
      "  Cidar10.1 Accuracy: 59.15\n",
      "  Epoch [5/94], Batch [350/352], Train Acc: 76.5737 Loss: 1.0024\n",
      "  Validation Accuracy after Epoch 5: 75.1600\n",
      "  Cidar10.1 Accuracy: 62.85\n",
      "  Epoch [6/94], Batch [350/352], Train Acc: 78.6049 Loss: 1.0906\n",
      "  Validation Accuracy after Epoch 6: 74.5400\n",
      "  Cidar10.1 Accuracy: 60.05\n",
      "  Epoch [7/94], Batch [350/352], Train Acc: 79.7009 Loss: 1.0321\n",
      "  Validation Accuracy after Epoch 7: 77.2400\n",
      "  Cidar10.1 Accuracy: 65.0\n",
      "  Epoch [8/94], Batch [350/352], Train Acc: 81.0647 Loss: 0.9748\n",
      "  Validation Accuracy after Epoch 8: 77.5200\n",
      "  Cidar10.1 Accuracy: 68.75\n",
      "  Epoch [9/94], Batch [350/352], Train Acc: 82.5179 Loss: 0.8831\n",
      "  Validation Accuracy after Epoch 9: 78.9000\n",
      "  Cidar10.1 Accuracy: 65.7\n",
      "  Epoch [10/94], Batch [350/352], Train Acc: 83.1763 Loss: 0.9862\n",
      "  Validation Accuracy after Epoch 10: 82.3800\n",
      "  Cidar10.1 Accuracy: 70.75\n",
      "  Epoch [11/94], Batch [350/352], Train Acc: 84.3438 Loss: 0.8275\n",
      "  Validation Accuracy after Epoch 11: 81.3200\n",
      "  Cidar10.1 Accuracy: 70.4\n",
      "  Epoch [12/94], Batch [350/352], Train Acc: 85.2790 Loss: 0.7911\n",
      "  Validation Accuracy after Epoch 12: 81.5000\n",
      "  Cidar10.1 Accuracy: 69.65\n",
      "  Epoch [13/94], Batch [350/352], Train Acc: 85.9375 Loss: 0.8172\n",
      "  Validation Accuracy after Epoch 13: 81.6000\n",
      "  Cidar10.1 Accuracy: 70.45\n",
      "  Epoch [14/94], Batch [350/352], Train Acc: 86.7991 Loss: 0.8414\n",
      "  Validation Accuracy after Epoch 14: 84.9000\n",
      "  Cidar10.1 Accuracy: 76.35\n",
      "  Epoch [15/94], Batch [350/352], Train Acc: 87.5469 Loss: 0.9064\n",
      "  Validation Accuracy after Epoch 15: 83.3800\n",
      "  Cidar10.1 Accuracy: 74.0\n",
      "  Epoch [16/94], Batch [350/352], Train Acc: 88.4308 Loss: 0.7732\n",
      "  Validation Accuracy after Epoch 16: 84.5800\n",
      "  Cidar10.1 Accuracy: 74.75\n",
      "  Epoch [17/94], Batch [350/352], Train Acc: 88.6897 Loss: 0.7975\n",
      "  Validation Accuracy after Epoch 17: 84.7400\n",
      "  Cidar10.1 Accuracy: 74.9\n",
      "  Epoch [18/94], Batch [350/352], Train Acc: 89.4330 Loss: 0.7874\n",
      "  Validation Accuracy after Epoch 18: 84.8600\n",
      "  Cidar10.1 Accuracy: 75.55\n",
      "  Epoch [19/94], Batch [350/352], Train Acc: 89.8661 Loss: 0.7456\n",
      "  Validation Accuracy after Epoch 19: 85.5600\n",
      "  Cidar10.1 Accuracy: 77.9\n",
      "  Epoch [20/94], Batch [350/352], Train Acc: 90.1830 Loss: 0.7644\n",
      "  Validation Accuracy after Epoch 20: 87.1800\n",
      "  Cidar10.1 Accuracy: 79.05\n",
      "  Epoch [21/94], Batch [350/352], Train Acc: 90.8951 Loss: 0.7713\n",
      "  Validation Accuracy after Epoch 21: 88.2400\n",
      "  Cidar10.1 Accuracy: 79.2\n",
      "  Epoch [22/94], Batch [350/352], Train Acc: 91.3259 Loss: 0.7167\n",
      "  Validation Accuracy after Epoch 22: 86.7000\n",
      "  Cidar10.1 Accuracy: 77.3\n",
      "  Epoch [23/94], Batch [350/352], Train Acc: 91.8906 Loss: 0.7016\n",
      "  Validation Accuracy after Epoch 23: 85.8400\n",
      "  Cidar10.1 Accuracy: 77.0\n",
      "  Epoch [24/94], Batch [350/352], Train Acc: 92.1406 Loss: 0.7896\n",
      "  Validation Accuracy after Epoch 24: 88.1800\n",
      "  Cidar10.1 Accuracy: 79.5\n",
      "  Epoch [25/94], Batch [350/352], Train Acc: 92.5179 Loss: 0.7163\n",
      "  Validation Accuracy after Epoch 25: 86.7000\n",
      "  Cidar10.1 Accuracy: 77.4\n",
      "  Epoch [26/94], Batch [350/352], Train Acc: 93.0134 Loss: 0.6682\n",
      "  Validation Accuracy after Epoch 26: 88.0600\n",
      "  Cidar10.1 Accuracy: 79.75\n",
      "  Epoch [27/94], Batch [350/352], Train Acc: 93.1741 Loss: 0.6803\n",
      "  Validation Accuracy after Epoch 27: 88.5800\n",
      "  Cidar10.1 Accuracy: 79.1\n",
      "  Epoch [28/94], Batch [350/352], Train Acc: 93.8772 Loss: 0.6364\n",
      "  Validation Accuracy after Epoch 28: 87.2200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 06:55:25,446] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=27\n",
      "num_epochs: 51\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9302203578127347\n",
      "beta2: 0.9940021142253973\n",
      "lr: 0.0007164495594447045\n",
      "weight_decay: 0.006508624466658578\n",
      "max_lr: 0.0036585600818756277\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/51], Batch [350/352], Train Acc: 44.0045 Loss: 1.5973\n",
      "  Validation Accuracy after Epoch 1: 52.3000\n",
      "  Cidar10.1 Accuracy: 43.3\n",
      "  Epoch [2/51], Batch [350/352], Train Acc: 60.0982 Loss: 1.4598\n",
      "  Validation Accuracy after Epoch 2: 60.1400\n",
      "  Cidar10.1 Accuracy: 47.95\n",
      "  Epoch [3/51], Batch [350/352], Train Acc: 67.4732 Loss: 1.1577\n",
      "  Validation Accuracy after Epoch 3: 63.9600\n",
      "  Cidar10.1 Accuracy: 51.9\n",
      "  Epoch [4/51], Batch [350/352], Train Acc: 72.2455 Loss: 1.1026\n",
      "  Validation Accuracy after Epoch 4: 72.4000\n",
      "  Cidar10.1 Accuracy: 58.35\n",
      "  Epoch [5/51], Batch [350/352], Train Acc: 75.1071 Loss: 1.2303\n",
      "  Validation Accuracy after Epoch 5: 71.2000\n",
      "  Cidar10.1 Accuracy: 58.45\n",
      "  Epoch [6/51], Batch [350/352], Train Acc: 77.2188 Loss: 1.0241\n",
      "  Validation Accuracy after Epoch 6: 71.4400\n",
      "  Cidar10.1 Accuracy: 56.4\n",
      "  Epoch [7/51], Batch [350/352], Train Acc: 78.8348 Loss: 1.0972\n",
      "  Validation Accuracy after Epoch 7: 74.2400\n",
      "  Cidar10.1 Accuracy: 62.5\n",
      "  Epoch [8/51], Batch [350/352], Train Acc: 80.7478 Loss: 0.9467\n",
      "  Validation Accuracy after Epoch 8: 76.1000\n",
      "  Cidar10.1 Accuracy: 64.95\n",
      "  Epoch [9/51], Batch [350/352], Train Acc: 82.1362 Loss: 0.8802\n",
      "  Validation Accuracy after Epoch 9: 81.4400\n",
      "  Cidar10.1 Accuracy: 71.55\n",
      "  Epoch [10/51], Batch [350/352], Train Acc: 83.6295 Loss: 0.8481\n",
      "  Validation Accuracy after Epoch 10: 82.1200\n",
      "  Cidar10.1 Accuracy: 72.6\n",
      "  Epoch [11/51], Batch [350/352], Train Acc: 84.7366 Loss: 0.8112\n",
      "  Validation Accuracy after Epoch 11: 82.4000\n",
      "  Cidar10.1 Accuracy: 71.55\n",
      "  Epoch [12/51], Batch [350/352], Train Acc: 85.8415 Loss: 0.7690\n",
      "  Validation Accuracy after Epoch 12: 83.4400\n",
      "  Cidar10.1 Accuracy: 74.45\n",
      "  Epoch [13/51], Batch [350/352], Train Acc: 86.9665 Loss: 0.8605\n",
      "  Validation Accuracy after Epoch 13: 78.2200\n",
      "  Cidar10.1 Accuracy: 69.15\n",
      "  Epoch [14/51], Batch [350/352], Train Acc: 88.0022 Loss: 0.7195\n",
      "  Validation Accuracy after Epoch 14: 83.8000\n",
      "  Cidar10.1 Accuracy: 74.8\n",
      "  Epoch [15/51], Batch [350/352], Train Acc: 88.9420 Loss: 0.7047\n",
      "  Validation Accuracy after Epoch 15: 84.4200\n",
      "  Cidar10.1 Accuracy: 75.05\n",
      "  Epoch [16/51], Batch [350/352], Train Acc: 89.8527 Loss: 0.7224\n",
      "  Validation Accuracy after Epoch 16: 85.8800\n",
      "  Cidar10.1 Accuracy: 76.85\n",
      "  Epoch [17/51], Batch [350/352], Train Acc: 90.6830 Loss: 0.7603\n",
      "  Validation Accuracy after Epoch 17: 87.7400\n",
      "  Cidar10.1 Accuracy: 78.5\n",
      "  Epoch [18/51], Batch [350/352], Train Acc: 91.5558 Loss: 0.6359\n",
      "  Validation Accuracy after Epoch 18: 88.0600\n",
      "  Cidar10.1 Accuracy: 77.45\n",
      "  Epoch [19/51], Batch [350/352], Train Acc: 92.1741 Loss: 0.6889\n",
      "  Validation Accuracy after Epoch 19: 87.4000\n",
      "  Cidar10.1 Accuracy: 79.35\n",
      "  Epoch [20/51], Batch [350/352], Train Acc: 92.9933 Loss: 0.6052\n",
      "  Validation Accuracy after Epoch 20: 88.8000\n",
      "  Cidar10.1 Accuracy: 78.65\n",
      "  Epoch [21/51], Batch [350/352], Train Acc: 93.2768 Loss: 0.6998\n",
      "  Validation Accuracy after Epoch 21: 88.6400\n",
      "  Cidar10.1 Accuracy: 78.85\n",
      "  Epoch [22/51], Batch [350/352], Train Acc: 93.9263 Loss: 0.6973\n",
      "  Validation Accuracy after Epoch 22: 89.3200\n",
      "  Cidar10.1 Accuracy: 80.0\n",
      "  Epoch [23/51], Batch [350/352], Train Acc: 94.4821 Loss: 0.6602\n",
      "  Validation Accuracy after Epoch 23: 89.9200\n",
      "  Cidar10.1 Accuracy: 80.7\n",
      "  Epoch [24/51], Batch [350/352], Train Acc: 95.0067 Loss: 0.6779\n",
      "  Validation Accuracy after Epoch 24: 88.9600\n",
      "  Cidar10.1 Accuracy: 81.3\n",
      "  Epoch [25/51], Batch [350/352], Train Acc: 95.4062 Loss: 0.6640\n",
      "  Validation Accuracy after Epoch 25: 89.7800\n",
      "  Cidar10.1 Accuracy: 82.15\n",
      "  Epoch [26/51], Batch [350/352], Train Acc: 95.6741 Loss: 0.6458\n",
      "  Validation Accuracy after Epoch 26: 90.6800\n",
      "  Cidar10.1 Accuracy: 81.15\n",
      "  Epoch [27/51], Batch [350/352], Train Acc: 96.3058 Loss: 0.6345\n",
      "  Validation Accuracy after Epoch 27: 90.4800\n",
      "  Cidar10.1 Accuracy: 81.95\n",
      "  Epoch [28/51], Batch [350/352], Train Acc: 96.5558 Loss: 0.6228\n",
      "  Validation Accuracy after Epoch 28: 90.7600\n",
      "  Cidar10.1 Accuracy: 82.0\n",
      "  Epoch [29/51], Batch [350/352], Train Acc: 97.0179 Loss: 0.6181\n",
      "  Validation Accuracy after Epoch 29: 90.1400\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [30/51], Batch [350/352], Train Acc: 97.1786 Loss: 0.5899\n",
      "  Validation Accuracy after Epoch 30: 90.3600\n",
      "  Cidar10.1 Accuracy: 81.95\n",
      "  Epoch [31/51], Batch [350/352], Train Acc: 97.7321 Loss: 0.5657\n",
      "  Validation Accuracy after Epoch 31: 91.5200\n",
      "  Cidar10.1 Accuracy: 82.55\n",
      "  Epoch [32/51], Batch [350/352], Train Acc: 98.0022 Loss: 0.5760\n",
      "  Validation Accuracy after Epoch 32: 91.2000\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [33/51], Batch [350/352], Train Acc: 98.2031 Loss: 0.5516\n",
      "  Validation Accuracy after Epoch 33: 91.2200\n",
      "  Cidar10.1 Accuracy: 83.85\n",
      "  Epoch [34/51], Batch [350/352], Train Acc: 98.4777 Loss: 0.6303\n",
      "  Validation Accuracy after Epoch 34: 91.6400\n",
      "  Cidar10.1 Accuracy: 84.1\n",
      "  Epoch [35/51], Batch [350/352], Train Acc: 98.6763 Loss: 0.5436\n",
      "  Validation Accuracy after Epoch 35: 92.0000\n",
      "  Cidar10.1 Accuracy: 82.85\n",
      "  Epoch [36/51], Batch [350/352], Train Acc: 98.8683 Loss: 0.5730\n",
      "  Validation Accuracy after Epoch 36: 92.1200\n",
      "  Cidar10.1 Accuracy: 84.4\n",
      "  Epoch [37/51], Batch [350/352], Train Acc: 99.0737 Loss: 0.5347\n",
      "  Validation Accuracy after Epoch 37: 92.2800\n",
      "  Cidar10.1 Accuracy: 84.7\n",
      "  Epoch [38/51], Batch [350/352], Train Acc: 99.1362 Loss: 0.5459\n",
      "  Validation Accuracy after Epoch 38: 92.6200\n",
      "  Cidar10.1 Accuracy: 84.65\n",
      "  Epoch [39/51], Batch [350/352], Train Acc: 99.3348 Loss: 0.5260\n",
      "  Validation Accuracy after Epoch 39: 92.1800\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [40/51], Batch [350/352], Train Acc: 99.3616 Loss: 0.5251\n",
      "  Validation Accuracy after Epoch 40: 92.7000\n",
      "  Cidar10.1 Accuracy: 85.15\n",
      "  Epoch [41/51], Batch [350/352], Train Acc: 99.5603 Loss: 0.5281\n",
      "  Validation Accuracy after Epoch 41: 92.2800\n",
      "  Cidar10.1 Accuracy: 85.15\n",
      "  Epoch [42/51], Batch [350/352], Train Acc: 99.5134 Loss: 0.5176\n",
      "  Validation Accuracy after Epoch 42: 92.7600\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [43/51], Batch [350/352], Train Acc: 99.6674 Loss: 0.5286\n",
      "  Validation Accuracy after Epoch 43: 92.2800\n",
      "  Cidar10.1 Accuracy: 84.65\n",
      "  Epoch [44/51], Batch [350/352], Train Acc: 99.7321 Loss: 0.5170\n",
      "  Validation Accuracy after Epoch 44: 92.7400\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [45/51], Batch [350/352], Train Acc: 99.7031 Loss: 0.5140\n",
      "  Validation Accuracy after Epoch 45: 92.3400\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [46/51], Batch [350/352], Train Acc: 99.7366 Loss: 0.5309\n",
      "  Validation Accuracy after Epoch 46: 92.9000\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "  Epoch [47/51], Batch [350/352], Train Acc: 99.7902 Loss: 0.5212\n",
      "  Validation Accuracy after Epoch 47: 92.7600\n",
      "  Cidar10.1 Accuracy: 84.85\n",
      "  Epoch [48/51], Batch [350/352], Train Acc: 99.7946 Loss: 0.5160\n",
      "  Validation Accuracy after Epoch 48: 92.8800\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [49/51], Batch [350/352], Train Acc: 99.7857 Loss: 0.5163\n",
      "  Validation Accuracy after Epoch 49: 93.4600\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [50/51], Batch [350/352], Train Acc: 99.8304 Loss: 0.5180\n",
      "  Validation Accuracy after Epoch 50: 92.6400\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [51/51], Batch [350/352], Train Acc: 99.8504 Loss: 0.5157\n",
      "  Validation Accuracy after Epoch 51: 92.7000\n",
      "  Cidar10.1 Accuracy: 85.65\n",
      "Trial 27 complete. Best Validation Accuracy: 93.4600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:03:38,311] Trial 27 finished with value: 93.46 and parameters: {'num_epochs': 51, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.9302203578127347, 'beta2': 0.9940021142253973, 'lr': 0.0007164495594447045, 'weight_decay': 0.006508624466658578, 'max_lr': 0.0036585600818756277}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=28\n",
      "num_epochs: 73\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: SGD\n",
      "scheduler_type: CosineAnnealingLR\n",
      "lr: 0.00238369333690372\n",
      "momentum: 0.8081171763424195\n",
      "weight_decay: 0.0003351100948064262\n",
      "eta_min: 2.2358247100084492e-05\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/73], Batch [350/352], Train Acc: 31.0871 Loss: 1.8207\n",
      "  Validation Accuracy after Epoch 1: 38.4200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:03:49,277] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=29\n",
      "num_epochs: 62\n",
      "model_type: smallresnet\n",
      "batch_size: 64\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.9340475997279718\n",
      "beta2: 0.9937511673456696\n",
      "lr: 0.0002704457631765823\n",
      "weight_decay: 0.0005039225923947062\n",
      "factor: 0.4808583638157734\n",
      "patience: 5\n",
      "threshold: 0.01247080576255135\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/62], Batch [700/704], Train Acc: 38.0603 Loss: 1.5746\n",
      "  Validation Accuracy after Epoch 1: 47.7200\n",
      "  Cidar10.1 Accuracy: 39.2\n",
      "  Epoch [2/62], Batch [700/704], Train Acc: 56.1830 Loss: 1.2488\n",
      "  Validation Accuracy after Epoch 2: 58.2600\n",
      "  Cidar10.1 Accuracy: 50.5\n",
      "  Epoch [3/62], Batch [700/704], Train Acc: 65.6205 Loss: 1.2196\n",
      "  Validation Accuracy after Epoch 3: 68.0400\n",
      "  Cidar10.1 Accuracy: 55.25\n",
      "  Epoch [4/62], Batch [700/704], Train Acc: 71.1897 Loss: 1.0720\n",
      "  Validation Accuracy after Epoch 4: 72.7400\n",
      "  Cidar10.1 Accuracy: 58.55\n",
      "  Epoch [5/62], Batch [700/704], Train Acc: 74.4621 Loss: 1.0663\n",
      "  Validation Accuracy after Epoch 5: 74.7400\n",
      "  Cidar10.1 Accuracy: 63.3\n",
      "  Epoch [6/62], Batch [700/704], Train Acc: 76.9085 Loss: 1.0281\n",
      "  Validation Accuracy after Epoch 6: 77.3400\n",
      "  Cidar10.1 Accuracy: 63.55\n",
      "  Epoch [7/62], Batch [700/704], Train Acc: 78.8058 Loss: 0.9845\n",
      "  Validation Accuracy after Epoch 7: 79.6400\n",
      "  Cidar10.1 Accuracy: 67.1\n",
      "  Epoch [8/62], Batch [700/704], Train Acc: 80.0893 Loss: 0.8475\n",
      "  Validation Accuracy after Epoch 8: 79.5000\n",
      "  Cidar10.1 Accuracy: 69.65\n",
      "  Epoch [9/62], Batch [700/704], Train Acc: 81.4621 Loss: 0.9773\n",
      "  Validation Accuracy after Epoch 9: 80.7800\n",
      "  Cidar10.1 Accuracy: 71.05\n",
      "  Epoch [10/62], Batch [700/704], Train Acc: 82.2701 Loss: 0.9810\n",
      "  Validation Accuracy after Epoch 10: 80.2000\n",
      "  Cidar10.1 Accuracy: 70.3\n",
      "  Epoch [11/62], Batch [700/704], Train Acc: 83.2009 Loss: 0.8656\n",
      "  Validation Accuracy after Epoch 11: 81.2400\n",
      "  Cidar10.1 Accuracy: 71.15\n",
      "  Epoch [12/62], Batch [700/704], Train Acc: 83.5759 Loss: 0.8565\n",
      "  Validation Accuracy after Epoch 12: 82.9800\n",
      "  Cidar10.1 Accuracy: 72.8\n",
      "  Epoch [13/62], Batch [700/704], Train Acc: 84.7768 Loss: 0.8274\n",
      "  Validation Accuracy after Epoch 13: 83.1800\n",
      "  Cidar10.1 Accuracy: 71.3\n",
      "  Epoch [14/62], Batch [700/704], Train Acc: 85.3415 Loss: 0.8752\n",
      "  Validation Accuracy after Epoch 14: 83.3400\n",
      "  Cidar10.1 Accuracy: 73.7\n",
      "  Epoch [15/62], Batch [700/704], Train Acc: 85.6942 Loss: 0.8063\n",
      "  Validation Accuracy after Epoch 15: 82.7800\n",
      "  Cidar10.1 Accuracy: 73.4\n",
      "  Epoch [16/62], Batch [700/704], Train Acc: 86.3839 Loss: 0.8095\n",
      "  Validation Accuracy after Epoch 16: 84.1200\n",
      "  Cidar10.1 Accuracy: 71.95\n",
      "  Epoch [17/62], Batch [700/704], Train Acc: 86.8125 Loss: 0.6421\n",
      "  Validation Accuracy after Epoch 17: 84.4600\n",
      "  Cidar10.1 Accuracy: 74.15\n",
      "  Epoch [18/62], Batch [700/704], Train Acc: 87.2812 Loss: 0.9196\n",
      "  Validation Accuracy after Epoch 18: 82.3600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:08:56,614] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=30\n",
      "num_epochs: 65\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: CosineAnnealingLR\n",
      "beta1: 0.9079294319315979\n",
      "beta2: 0.9973713639817936\n",
      "lr: 0.0017555866700141353\n",
      "weight_decay: 0.012525383077033568\n",
      "eta_min: 0.0009628102373520947\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/65], Batch [350/352], Train Acc: 42.1138 Loss: 1.5540\n",
      "  Validation Accuracy after Epoch 1: 54.0400\n",
      "  Cidar10.1 Accuracy: 43.1\n",
      "  Epoch [2/65], Batch [350/352], Train Acc: 60.7946 Loss: 1.2801\n",
      "  Validation Accuracy after Epoch 2: 63.9600\n",
      "  Cidar10.1 Accuracy: 52.85\n",
      "  Epoch [3/65], Batch [350/352], Train Acc: 68.3259 Loss: 1.1169\n",
      "  Validation Accuracy after Epoch 3: 65.4200\n",
      "  Cidar10.1 Accuracy: 53.4\n",
      "  Epoch [4/65], Batch [350/352], Train Acc: 73.8304 Loss: 1.1034\n",
      "  Validation Accuracy after Epoch 4: 71.6800\n",
      "  Cidar10.1 Accuracy: 59.75\n",
      "  Epoch [5/65], Batch [350/352], Train Acc: 77.6116 Loss: 0.9561\n",
      "  Validation Accuracy after Epoch 5: 78.9800\n",
      "  Cidar10.1 Accuracy: 67.7\n",
      "  Epoch [6/65], Batch [350/352], Train Acc: 80.1161 Loss: 0.9395\n",
      "  Validation Accuracy after Epoch 6: 77.6400\n",
      "  Cidar10.1 Accuracy: 67.95\n",
      "  Epoch [7/65], Batch [350/352], Train Acc: 82.2701 Loss: 0.8804\n",
      "  Validation Accuracy after Epoch 7: 78.1400\n",
      "  Cidar10.1 Accuracy: 68.65\n",
      "  Epoch [8/65], Batch [350/352], Train Acc: 83.9353 Loss: 0.9069\n",
      "  Validation Accuracy after Epoch 8: 83.1200\n",
      "  Cidar10.1 Accuracy: 73.25\n",
      "  Epoch [9/65], Batch [350/352], Train Acc: 85.3616 Loss: 0.8862\n",
      "  Validation Accuracy after Epoch 9: 83.8200\n",
      "  Cidar10.1 Accuracy: 74.35\n",
      "  Epoch [10/65], Batch [350/352], Train Acc: 86.5848 Loss: 0.8586\n",
      "  Validation Accuracy after Epoch 10: 83.3600\n",
      "  Cidar10.1 Accuracy: 74.2\n",
      "  Epoch [11/65], Batch [350/352], Train Acc: 87.3170 Loss: 0.8195\n",
      "  Validation Accuracy after Epoch 11: 84.9000\n",
      "  Cidar10.1 Accuracy: 75.5\n",
      "  Epoch [12/65], Batch [350/352], Train Acc: 88.1920 Loss: 0.8073\n",
      "  Validation Accuracy after Epoch 12: 86.4400\n",
      "  Cidar10.1 Accuracy: 77.1\n",
      "  Epoch [13/65], Batch [350/352], Train Acc: 89.1317 Loss: 0.7672\n",
      "  Validation Accuracy after Epoch 13: 84.8800\n",
      "  Cidar10.1 Accuracy: 75.8\n",
      "  Epoch [14/65], Batch [350/352], Train Acc: 90.1004 Loss: 0.8162\n",
      "  Validation Accuracy after Epoch 14: 87.0200\n",
      "  Cidar10.1 Accuracy: 78.3\n",
      "  Epoch [15/65], Batch [350/352], Train Acc: 90.4576 Loss: 0.7165\n",
      "  Validation Accuracy after Epoch 15: 88.1600\n",
      "  Cidar10.1 Accuracy: 80.75\n",
      "  Epoch [16/65], Batch [350/352], Train Acc: 91.2098 Loss: 0.7098\n",
      "  Validation Accuracy after Epoch 16: 88.1400\n",
      "  Cidar10.1 Accuracy: 79.45\n",
      "  Epoch [17/65], Batch [350/352], Train Acc: 91.8549 Loss: 0.6826\n",
      "  Validation Accuracy after Epoch 17: 86.3200\n",
      "  Cidar10.1 Accuracy: 75.05\n",
      "  Epoch [18/65], Batch [350/352], Train Acc: 92.3415 Loss: 0.6537\n",
      "  Validation Accuracy after Epoch 18: 88.6600\n",
      "  Cidar10.1 Accuracy: 78.05\n",
      "  Epoch [19/65], Batch [350/352], Train Acc: 92.8884 Loss: 0.6766\n",
      "  Validation Accuracy after Epoch 19: 89.4200\n",
      "  Cidar10.1 Accuracy: 80.45\n",
      "  Epoch [20/65], Batch [350/352], Train Acc: 93.4844 Loss: 0.7149\n",
      "  Validation Accuracy after Epoch 20: 87.9600\n",
      "  Cidar10.1 Accuracy: 80.35\n",
      "  Epoch [21/65], Batch [350/352], Train Acc: 93.8862 Loss: 0.7139\n",
      "  Validation Accuracy after Epoch 21: 89.3800\n",
      "  Cidar10.1 Accuracy: 80.9\n",
      "  Epoch [22/65], Batch [350/352], Train Acc: 93.9509 Loss: 0.6123\n",
      "  Validation Accuracy after Epoch 22: 90.1600\n",
      "  Cidar10.1 Accuracy: 81.0\n",
      "  Epoch [23/65], Batch [350/352], Train Acc: 94.4777 Loss: 0.6729\n",
      "  Validation Accuracy after Epoch 23: 88.7000\n",
      "  Cidar10.1 Accuracy: 78.45\n",
      "  Epoch [24/65], Batch [350/352], Train Acc: 94.9263 Loss: 0.6899\n",
      "  Validation Accuracy after Epoch 24: 88.3800\n",
      "  Cidar10.1 Accuracy: 79.75\n",
      "  Epoch [25/65], Batch [350/352], Train Acc: 95.1161 Loss: 0.5859\n",
      "  Validation Accuracy after Epoch 25: 89.6400\n",
      "  Cidar10.1 Accuracy: 79.9\n",
      "  Epoch [26/65], Batch [350/352], Train Acc: 95.3594 Loss: 0.6420\n",
      "  Validation Accuracy after Epoch 26: 89.6800\n",
      "  Cidar10.1 Accuracy: 80.75\n",
      "  Epoch [27/65], Batch [350/352], Train Acc: 95.7567 Loss: 0.6454\n",
      "  Validation Accuracy after Epoch 27: 89.5400\n",
      "  Cidar10.1 Accuracy: 81.05\n",
      "  Epoch [28/65], Batch [350/352], Train Acc: 96.0067 Loss: 0.6355\n",
      "  Validation Accuracy after Epoch 28: 90.2800\n",
      "  Cidar10.1 Accuracy: 82.0\n",
      "  Epoch [29/65], Batch [350/352], Train Acc: 96.1004 Loss: 0.6086\n",
      "  Validation Accuracy after Epoch 29: 89.9000\n",
      "  Cidar10.1 Accuracy: 81.25\n",
      "  Epoch [30/65], Batch [350/352], Train Acc: 96.4688 Loss: 0.5907\n",
      "  Validation Accuracy after Epoch 30: 89.5200\n",
      "  Cidar10.1 Accuracy: 80.6\n",
      "  Epoch [31/65], Batch [350/352], Train Acc: 96.4219 Loss: 0.6060\n",
      "  Validation Accuracy after Epoch 31: 90.0200\n",
      "  Cidar10.1 Accuracy: 81.4\n",
      "  Epoch [32/65], Batch [350/352], Train Acc: 96.6540 Loss: 0.6150\n",
      "  Validation Accuracy after Epoch 32: 90.6800\n",
      "  Cidar10.1 Accuracy: 82.35\n",
      "  Epoch [33/65], Batch [350/352], Train Acc: 96.8571 Loss: 0.6237\n",
      "  Validation Accuracy after Epoch 33: 90.3200\n",
      "  Cidar10.1 Accuracy: 81.75\n",
      "  Epoch [34/65], Batch [350/352], Train Acc: 97.1406 Loss: 0.5784\n",
      "  Validation Accuracy after Epoch 34: 89.1000\n",
      "  Cidar10.1 Accuracy: 78.05\n",
      "  Epoch [35/65], Batch [350/352], Train Acc: 97.1094 Loss: 0.5733\n",
      "  Validation Accuracy after Epoch 35: 90.3800\n",
      "  Cidar10.1 Accuracy: 81.7\n",
      "  Epoch [36/65], Batch [350/352], Train Acc: 97.2924 Loss: 0.5890\n",
      "  Validation Accuracy after Epoch 36: 90.9800\n",
      "  Cidar10.1 Accuracy: 81.65\n",
      "  Epoch [37/65], Batch [350/352], Train Acc: 97.3929 Loss: 0.5795\n",
      "  Validation Accuracy after Epoch 37: 89.9000\n",
      "  Cidar10.1 Accuracy: 81.5\n",
      "  Epoch [38/65], Batch [350/352], Train Acc: 97.5915 Loss: 0.5701\n",
      "  Validation Accuracy after Epoch 38: 90.6600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:15:02,435] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=31\n",
      "num_epochs: 74\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8921002719215918\n",
      "beta2: 0.9954717049767702\n",
      "lr: 0.000988724043189535\n",
      "weight_decay: 0.002128337349619262\n",
      "max_lr: 0.005342362606133308\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/74], Batch [350/352], Train Acc: 45.1205 Loss: 1.5639\n",
      "  Validation Accuracy after Epoch 1: 53.1200\n",
      "  Cidar10.1 Accuracy: 44.9\n",
      "  Epoch [2/74], Batch [350/352], Train Acc: 62.0112 Loss: 1.2907\n",
      "  Validation Accuracy after Epoch 2: 64.2800\n",
      "  Cidar10.1 Accuracy: 50.85\n",
      "  Epoch [3/74], Batch [350/352], Train Acc: 69.3839 Loss: 1.1386\n",
      "  Validation Accuracy after Epoch 3: 67.6400\n",
      "  Cidar10.1 Accuracy: 57.0\n",
      "  Epoch [4/74], Batch [350/352], Train Acc: 73.4353 Loss: 1.1005\n",
      "  Validation Accuracy after Epoch 4: 72.0400\n",
      "  Cidar10.1 Accuracy: 56.4\n",
      "  Epoch [5/74], Batch [350/352], Train Acc: 76.0223 Loss: 0.9983\n",
      "  Validation Accuracy after Epoch 5: 70.7000\n",
      "  Cidar10.1 Accuracy: 59.35\n",
      "  Epoch [6/74], Batch [350/352], Train Acc: 77.8951 Loss: 1.0177\n",
      "  Validation Accuracy after Epoch 6: 74.0600\n",
      "  Cidar10.1 Accuracy: 59.6\n",
      "  Epoch [7/74], Batch [350/352], Train Acc: 79.8862 Loss: 0.9352\n",
      "  Validation Accuracy after Epoch 7: 77.8600\n",
      "  Cidar10.1 Accuracy: 67.55\n",
      "  Epoch [8/74], Batch [350/352], Train Acc: 81.0268 Loss: 0.9135\n",
      "  Validation Accuracy after Epoch 8: 78.1000\n",
      "  Cidar10.1 Accuracy: 64.75\n",
      "  Epoch [9/74], Batch [350/352], Train Acc: 82.4040 Loss: 0.9345\n",
      "  Validation Accuracy after Epoch 9: 77.1200\n",
      "  Cidar10.1 Accuracy: 64.9\n",
      "  Epoch [10/74], Batch [350/352], Train Acc: 83.3571 Loss: 0.8274\n",
      "  Validation Accuracy after Epoch 10: 79.0000\n",
      "  Cidar10.1 Accuracy: 68.1\n",
      "  Epoch [11/74], Batch [350/352], Train Acc: 84.5089 Loss: 0.8613\n",
      "  Validation Accuracy after Epoch 11: 81.5200\n",
      "  Cidar10.1 Accuracy: 72.5\n",
      "  Epoch [12/74], Batch [350/352], Train Acc: 85.5692 Loss: 1.0024\n",
      "  Validation Accuracy after Epoch 12: 81.0600\n",
      "  Cidar10.1 Accuracy: 67.7\n",
      "  Epoch [13/74], Batch [350/352], Train Acc: 86.2723 Loss: 0.7696\n",
      "  Validation Accuracy after Epoch 13: 81.9800\n",
      "  Cidar10.1 Accuracy: 72.8\n",
      "  Epoch [14/74], Batch [350/352], Train Acc: 87.2299 Loss: 0.8675\n",
      "  Validation Accuracy after Epoch 14: 84.0800\n",
      "  Cidar10.1 Accuracy: 75.15\n",
      "  Epoch [15/74], Batch [350/352], Train Acc: 87.7478 Loss: 0.7772\n",
      "  Validation Accuracy after Epoch 15: 83.0800\n",
      "  Cidar10.1 Accuracy: 72.35\n",
      "  Epoch [16/74], Batch [350/352], Train Acc: 88.4241 Loss: 0.7628\n",
      "  Validation Accuracy after Epoch 16: 83.9400\n",
      "  Cidar10.1 Accuracy: 75.25\n",
      "  Epoch [17/74], Batch [350/352], Train Acc: 89.3460 Loss: 0.8183\n",
      "  Validation Accuracy after Epoch 17: 86.2000\n",
      "  Cidar10.1 Accuracy: 76.05\n",
      "  Epoch [18/74], Batch [350/352], Train Acc: 89.8929 Loss: 0.6861\n",
      "  Validation Accuracy after Epoch 18: 86.9200\n",
      "  Cidar10.1 Accuracy: 76.35\n",
      "  Epoch [19/74], Batch [350/352], Train Acc: 90.4085 Loss: 0.7698\n",
      "  Validation Accuracy after Epoch 19: 85.4800\n",
      "  Cidar10.1 Accuracy: 73.35\n",
      "  Epoch [20/74], Batch [350/352], Train Acc: 91.2098 Loss: 0.6684\n",
      "  Validation Accuracy after Epoch 20: 88.3400\n",
      "  Cidar10.1 Accuracy: 79.75\n",
      "  Epoch [21/74], Batch [350/352], Train Acc: 91.6094 Loss: 0.7488\n",
      "  Validation Accuracy after Epoch 21: 86.6800\n",
      "  Cidar10.1 Accuracy: 76.65\n",
      "  Epoch [22/74], Batch [350/352], Train Acc: 92.2589 Loss: 0.6852\n",
      "  Validation Accuracy after Epoch 22: 88.0600\n",
      "  Cidar10.1 Accuracy: 78.0\n",
      "  Epoch [23/74], Batch [350/352], Train Acc: 92.6741 Loss: 0.6903\n",
      "  Validation Accuracy after Epoch 23: 88.2400\n",
      "  Cidar10.1 Accuracy: 79.0\n",
      "  Epoch [24/74], Batch [350/352], Train Acc: 93.2076 Loss: 0.7591\n",
      "  Validation Accuracy after Epoch 24: 89.3200\n",
      "  Cidar10.1 Accuracy: 80.3\n",
      "  Epoch [25/74], Batch [350/352], Train Acc: 93.8147 Loss: 0.6440\n",
      "  Validation Accuracy after Epoch 25: 88.6400\n",
      "  Cidar10.1 Accuracy: 77.85\n",
      "  Epoch [26/74], Batch [350/352], Train Acc: 94.3036 Loss: 0.6026\n",
      "  Validation Accuracy after Epoch 26: 87.1800\n",
      "  Cidar10.1 Accuracy: 77.45\n",
      "  Epoch [27/74], Batch [350/352], Train Acc: 94.3929 Loss: 0.7261\n",
      "  Validation Accuracy after Epoch 27: 89.0800\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [28/74], Batch [350/352], Train Acc: 95.0804 Loss: 0.6956\n",
      "  Validation Accuracy after Epoch 28: 90.2400\n",
      "  Cidar10.1 Accuracy: 82.3\n",
      "  Epoch [29/74], Batch [350/352], Train Acc: 95.3683 Loss: 0.6845\n",
      "  Validation Accuracy after Epoch 29: 88.8800\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [30/74], Batch [350/352], Train Acc: 95.5112 Loss: 0.6087\n",
      "  Validation Accuracy after Epoch 30: 89.1000\n",
      "  Cidar10.1 Accuracy: 80.7\n",
      "  Epoch [31/74], Batch [350/352], Train Acc: 96.0513 Loss: 0.5778\n",
      "  Validation Accuracy after Epoch 31: 90.2200\n",
      "  Cidar10.1 Accuracy: 83.95\n",
      "  Epoch [32/74], Batch [350/352], Train Acc: 96.0402 Loss: 0.6182\n",
      "  Validation Accuracy after Epoch 32: 90.4200\n",
      "  Cidar10.1 Accuracy: 82.6\n",
      "  Epoch [33/74], Batch [350/352], Train Acc: 96.6562 Loss: 0.5781\n",
      "  Validation Accuracy after Epoch 33: 90.3000\n",
      "  Cidar10.1 Accuracy: 81.1\n",
      "  Epoch [34/74], Batch [350/352], Train Acc: 96.7701 Loss: 0.6292\n",
      "  Validation Accuracy after Epoch 34: 90.9400\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [35/74], Batch [350/352], Train Acc: 97.0491 Loss: 0.5979\n",
      "  Validation Accuracy after Epoch 35: 90.5600\n",
      "  Cidar10.1 Accuracy: 83.0\n",
      "  Epoch [36/74], Batch [350/352], Train Acc: 97.2165 Loss: 0.5948\n",
      "  Validation Accuracy after Epoch 36: 90.7800\n",
      "  Cidar10.1 Accuracy: 82.4\n",
      "  Epoch [37/74], Batch [350/352], Train Acc: 97.5134 Loss: 0.6214\n",
      "  Validation Accuracy after Epoch 37: 91.1600\n",
      "  Cidar10.1 Accuracy: 83.15\n",
      "  Epoch [38/74], Batch [350/352], Train Acc: 97.7946 Loss: 0.5451\n",
      "  Validation Accuracy after Epoch 38: 90.7800\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [39/74], Batch [350/352], Train Acc: 98.1250 Loss: 0.5845\n",
      "  Validation Accuracy after Epoch 39: 91.3400\n",
      "  Cidar10.1 Accuracy: 83.3\n",
      "  Epoch [40/74], Batch [350/352], Train Acc: 98.1071 Loss: 0.5882\n",
      "  Validation Accuracy after Epoch 40: 91.5200\n",
      "  Cidar10.1 Accuracy: 83.8\n",
      "  Epoch [41/74], Batch [350/352], Train Acc: 98.3125 Loss: 0.5607\n",
      "  Validation Accuracy after Epoch 41: 91.8200\n",
      "  Cidar10.1 Accuracy: 83.95\n",
      "  Epoch [42/74], Batch [350/352], Train Acc: 98.5647 Loss: 0.5784\n",
      "  Validation Accuracy after Epoch 42: 90.9600\n",
      "  Cidar10.1 Accuracy: 82.8\n",
      "  Epoch [43/74], Batch [350/352], Train Acc: 98.6853 Loss: 0.5489\n",
      "  Validation Accuracy after Epoch 43: 91.5000\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [44/74], Batch [350/352], Train Acc: 98.7098 Loss: 0.5433\n",
      "  Validation Accuracy after Epoch 44: 91.8200\n",
      "  Cidar10.1 Accuracy: 84.1\n",
      "  Epoch [45/74], Batch [350/352], Train Acc: 98.9062 Loss: 0.5608\n",
      "  Validation Accuracy after Epoch 45: 91.8600\n",
      "  Cidar10.1 Accuracy: 84.4\n",
      "  Epoch [46/74], Batch [350/352], Train Acc: 99.0893 Loss: 0.5359\n",
      "  Validation Accuracy after Epoch 46: 92.4800\n",
      "  Cidar10.1 Accuracy: 83.45\n",
      "  Epoch [47/74], Batch [350/352], Train Acc: 99.0580 Loss: 0.5517\n",
      "  Validation Accuracy after Epoch 47: 92.3800\n",
      "  Cidar10.1 Accuracy: 84.15\n",
      "  Epoch [48/74], Batch [350/352], Train Acc: 99.2500 Loss: 0.5631\n",
      "  Validation Accuracy after Epoch 48: 91.9400\n",
      "  Cidar10.1 Accuracy: 84.75\n",
      "  Epoch [49/74], Batch [350/352], Train Acc: 99.2656 Loss: 0.5457\n",
      "  Validation Accuracy after Epoch 49: 91.9200\n",
      "  Cidar10.1 Accuracy: 85.35\n",
      "  Epoch [50/74], Batch [350/352], Train Acc: 99.3415 Loss: 0.5320\n",
      "  Validation Accuracy after Epoch 50: 91.9600\n",
      "  Cidar10.1 Accuracy: 84.6\n",
      "  Epoch [51/74], Batch [350/352], Train Acc: 99.4018 Loss: 0.5417\n",
      "  Validation Accuracy after Epoch 51: 92.1800\n",
      "  Cidar10.1 Accuracy: 83.35\n",
      "  Epoch [52/74], Batch [350/352], Train Acc: 99.6004 Loss: 0.5211\n",
      "  Validation Accuracy after Epoch 52: 92.3600\n",
      "  Cidar10.1 Accuracy: 84.7\n",
      "  Epoch [53/74], Batch [350/352], Train Acc: 99.6027 Loss: 0.5164\n",
      "  Validation Accuracy after Epoch 53: 92.4800\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [54/74], Batch [350/352], Train Acc: 99.6696 Loss: 0.5228\n",
      "  Validation Accuracy after Epoch 54: 92.9000\n",
      "  Cidar10.1 Accuracy: 84.8\n",
      "  Epoch [55/74], Batch [350/352], Train Acc: 99.7500 Loss: 0.5257\n",
      "  Validation Accuracy after Epoch 55: 92.3400\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [56/74], Batch [350/352], Train Acc: 99.7411 Loss: 0.5175\n",
      "  Validation Accuracy after Epoch 56: 92.6400\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [57/74], Batch [350/352], Train Acc: 99.7500 Loss: 0.5120\n",
      "  Validation Accuracy after Epoch 57: 92.5600\n",
      "  Cidar10.1 Accuracy: 85.85\n",
      "  Epoch [58/74], Batch [350/352], Train Acc: 99.7589 Loss: 0.5157\n",
      "  Validation Accuracy after Epoch 58: 93.2400\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [59/74], Batch [350/352], Train Acc: 99.8728 Loss: 0.5165\n",
      "  Validation Accuracy after Epoch 59: 93.4400\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [60/74], Batch [350/352], Train Acc: 99.8705 Loss: 0.5161\n",
      "  Validation Accuracy after Epoch 60: 93.1000\n",
      "  Cidar10.1 Accuracy: 85.8\n",
      "  Epoch [61/74], Batch [350/352], Train Acc: 99.8482 Loss: 0.5090\n",
      "  Validation Accuracy after Epoch 61: 92.9200\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [62/74], Batch [350/352], Train Acc: 99.8705 Loss: 0.5113\n",
      "  Validation Accuracy after Epoch 62: 93.1200\n",
      "  Cidar10.1 Accuracy: 86.1\n",
      "  Epoch [63/74], Batch [350/352], Train Acc: 99.9129 Loss: 0.5112\n",
      "  Validation Accuracy after Epoch 63: 93.0800\n",
      "  Cidar10.1 Accuracy: 86.8\n",
      "  Epoch [64/74], Batch [350/352], Train Acc: 99.9040 Loss: 0.5115\n",
      "  Validation Accuracy after Epoch 64: 93.0800\n",
      "  Cidar10.1 Accuracy: 86.9\n",
      "  Epoch [65/74], Batch [350/352], Train Acc: 99.9397 Loss: 0.5092\n",
      "  Validation Accuracy after Epoch 65: 93.0200\n",
      "  Cidar10.1 Accuracy: 86.7\n",
      "  Epoch [66/74], Batch [350/352], Train Acc: 99.9420 Loss: 0.5146\n",
      "  Validation Accuracy after Epoch 66: 93.1200\n",
      "  Cidar10.1 Accuracy: 86.1\n",
      "  Epoch [67/74], Batch [350/352], Train Acc: 99.9286 Loss: 0.5123\n",
      "  Validation Accuracy after Epoch 67: 93.4400\n",
      "  Cidar10.1 Accuracy: 86.35\n",
      "  Epoch [68/74], Batch [350/352], Train Acc: 99.9464 Loss: 0.5095\n",
      "  Validation Accuracy after Epoch 68: 93.4000\n",
      "  Cidar10.1 Accuracy: 86.4\n",
      "  Epoch [69/74], Batch [350/352], Train Acc: 99.9442 Loss: 0.5078\n",
      "  Validation Accuracy after Epoch 69: 93.4200\n",
      "  Cidar10.1 Accuracy: 86.5\n",
      "  Epoch [70/74], Batch [350/352], Train Acc: 99.9643 Loss: 0.5089\n",
      "  Validation Accuracy after Epoch 70: 93.5000\n",
      "  Cidar10.1 Accuracy: 86.8\n",
      "  Epoch [71/74], Batch [350/352], Train Acc: 99.9509 Loss: 0.5115\n",
      "  Validation Accuracy after Epoch 71: 93.2800\n",
      "  Cidar10.1 Accuracy: 86.55\n",
      "  Epoch [72/74], Batch [350/352], Train Acc: 99.9621 Loss: 0.5078\n",
      "  Validation Accuracy after Epoch 72: 93.3400\n",
      "  Cidar10.1 Accuracy: 86.2\n",
      "  Epoch [73/74], Batch [350/352], Train Acc: 99.9554 Loss: 0.5090\n",
      "  Validation Accuracy after Epoch 73: 93.1400\n",
      "  Cidar10.1 Accuracy: 86.55\n",
      "  Epoch [74/74], Batch [350/352], Train Acc: 99.9621 Loss: 0.5087\n",
      "  Validation Accuracy after Epoch 74: 92.8400\n",
      "  Cidar10.1 Accuracy: 86.5\n",
      "Trial 31 complete. Best Validation Accuracy: 93.5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:26:55,772] Trial 31 finished with value: 93.5 and parameters: {'num_epochs': 74, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8921002719215918, 'beta2': 0.9954717049767702, 'lr': 0.000988724043189535, 'weight_decay': 0.002128337349619262, 'max_lr': 0.005342362606133308}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=32\n",
      "num_epochs: 83\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8763810986600915\n",
      "beta2: 0.9955351356527492\n",
      "lr: 0.0014115182488918117\n",
      "weight_decay: 0.001647284097663436\n",
      "max_lr: 0.005371114620981091\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/83], Batch [350/352], Train Acc: 45.0446 Loss: 1.5581\n",
      "  Validation Accuracy after Epoch 1: 54.1000\n",
      "  Cidar10.1 Accuracy: 45.85\n",
      "  Epoch [2/83], Batch [350/352], Train Acc: 62.0603 Loss: 1.3650\n",
      "  Validation Accuracy after Epoch 2: 62.7400\n",
      "  Cidar10.1 Accuracy: 48.55\n",
      "  Epoch [3/83], Batch [350/352], Train Acc: 69.3348 Loss: 1.1520\n",
      "  Validation Accuracy after Epoch 3: 70.6600\n",
      "  Cidar10.1 Accuracy: 57.7\n",
      "  Epoch [4/83], Batch [350/352], Train Acc: 73.6004 Loss: 1.0338\n",
      "  Validation Accuracy after Epoch 4: 72.8800\n",
      "  Cidar10.1 Accuracy: 60.15\n",
      "  Epoch [5/83], Batch [350/352], Train Acc: 75.9241 Loss: 1.0096\n",
      "  Validation Accuracy after Epoch 5: 75.5200\n",
      "  Cidar10.1 Accuracy: 63.15\n",
      "  Epoch [6/83], Batch [350/352], Train Acc: 78.2589 Loss: 1.0407\n",
      "  Validation Accuracy after Epoch 6: 74.3000\n",
      "  Cidar10.1 Accuracy: 63.4\n",
      "  Epoch [7/83], Batch [350/352], Train Acc: 79.4487 Loss: 0.9917\n",
      "  Validation Accuracy after Epoch 7: 77.0800\n",
      "  Cidar10.1 Accuracy: 63.8\n",
      "  Epoch [8/83], Batch [350/352], Train Acc: 80.8795 Loss: 0.9778\n",
      "  Validation Accuracy after Epoch 8: 80.6000\n",
      "  Cidar10.1 Accuracy: 68.85\n",
      "  Epoch [9/83], Batch [350/352], Train Acc: 82.2076 Loss: 0.9665\n",
      "  Validation Accuracy after Epoch 9: 76.7200\n",
      "  Cidar10.1 Accuracy: 66.45\n",
      "  Epoch [10/83], Batch [350/352], Train Acc: 83.4174 Loss: 0.9403\n",
      "  Validation Accuracy after Epoch 10: 76.2800\n",
      "  Cidar10.1 Accuracy: 65.15\n",
      "  Epoch [11/83], Batch [350/352], Train Acc: 84.3103 Loss: 0.8489\n",
      "  Validation Accuracy after Epoch 11: 82.5200\n",
      "  Cidar10.1 Accuracy: 71.75\n",
      "  Epoch [12/83], Batch [350/352], Train Acc: 85.1183 Loss: 0.8126\n",
      "  Validation Accuracy after Epoch 12: 83.7000\n",
      "  Cidar10.1 Accuracy: 73.75\n",
      "  Epoch [13/83], Batch [350/352], Train Acc: 86.2612 Loss: 0.8775\n",
      "  Validation Accuracy after Epoch 13: 82.4600\n",
      "  Cidar10.1 Accuracy: 71.1\n",
      "  Epoch [14/83], Batch [350/352], Train Acc: 86.9353 Loss: 0.8276\n",
      "  Validation Accuracy after Epoch 14: 83.9400\n",
      "  Cidar10.1 Accuracy: 75.45\n",
      "  Epoch [15/83], Batch [350/352], Train Acc: 87.5536 Loss: 0.8398\n",
      "  Validation Accuracy after Epoch 15: 81.7000\n",
      "  Cidar10.1 Accuracy: 73.25\n",
      "  Epoch [16/83], Batch [350/352], Train Acc: 88.5402 Loss: 0.7897\n",
      "  Validation Accuracy after Epoch 16: 86.0600\n",
      "  Cidar10.1 Accuracy: 74.45\n",
      "  Epoch [17/83], Batch [350/352], Train Acc: 89.0424 Loss: 0.7990\n",
      "  Validation Accuracy after Epoch 17: 86.9600\n",
      "  Cidar10.1 Accuracy: 77.4\n",
      "  Epoch [18/83], Batch [350/352], Train Acc: 89.5179 Loss: 0.7480\n",
      "  Validation Accuracy after Epoch 18: 86.9800\n",
      "  Cidar10.1 Accuracy: 76.65\n",
      "  Epoch [19/83], Batch [350/352], Train Acc: 90.3862 Loss: 0.7474\n",
      "  Validation Accuracy after Epoch 19: 87.9800\n",
      "  Cidar10.1 Accuracy: 78.15\n",
      "  Epoch [20/83], Batch [350/352], Train Acc: 90.7656 Loss: 0.7309\n",
      "  Validation Accuracy after Epoch 20: 87.0600\n",
      "  Cidar10.1 Accuracy: 79.2\n",
      "  Epoch [21/83], Batch [350/352], Train Acc: 91.2768 Loss: 0.7104\n",
      "  Validation Accuracy after Epoch 21: 88.0400\n",
      "  Cidar10.1 Accuracy: 78.7\n",
      "  Epoch [22/83], Batch [350/352], Train Acc: 91.5290 Loss: 0.6924\n",
      "  Validation Accuracy after Epoch 22: 87.4000\n",
      "  Cidar10.1 Accuracy: 76.55\n",
      "  Epoch [23/83], Batch [350/352], Train Acc: 92.1942 Loss: 0.6604\n",
      "  Validation Accuracy after Epoch 23: 88.2000\n",
      "  Cidar10.1 Accuracy: 80.0\n",
      "  Epoch [24/83], Batch [350/352], Train Acc: 92.8013 Loss: 0.7586\n",
      "  Validation Accuracy after Epoch 24: 88.9400\n",
      "  Cidar10.1 Accuracy: 79.7\n",
      "  Epoch [25/83], Batch [350/352], Train Acc: 93.1786 Loss: 0.6355\n",
      "  Validation Accuracy after Epoch 25: 89.4600\n",
      "  Cidar10.1 Accuracy: 79.05\n",
      "  Epoch [26/83], Batch [350/352], Train Acc: 93.7165 Loss: 0.6467\n",
      "  Validation Accuracy after Epoch 26: 88.5800\n",
      "  Cidar10.1 Accuracy: 78.0\n",
      "  Epoch [27/83], Batch [350/352], Train Acc: 94.1451 Loss: 0.5855\n",
      "  Validation Accuracy after Epoch 27: 89.3600\n",
      "  Cidar10.1 Accuracy: 80.35\n",
      "  Epoch [28/83], Batch [350/352], Train Acc: 94.4710 Loss: 0.6656\n",
      "  Validation Accuracy after Epoch 28: 88.5400\n",
      "  Cidar10.1 Accuracy: 80.05\n",
      "  Epoch [29/83], Batch [350/352], Train Acc: 94.8549 Loss: 0.5911\n",
      "  Validation Accuracy after Epoch 29: 90.2400\n",
      "  Cidar10.1 Accuracy: 80.25\n",
      "  Epoch [30/83], Batch [350/352], Train Acc: 95.0714 Loss: 0.6400\n",
      "  Validation Accuracy after Epoch 30: 89.2800\n",
      "  Cidar10.1 Accuracy: 80.25\n",
      "  Epoch [31/83], Batch [350/352], Train Acc: 95.6116 Loss: 0.6540\n",
      "  Validation Accuracy after Epoch 31: 89.1600\n",
      "  Cidar10.1 Accuracy: 81.4\n",
      "  Epoch [32/83], Batch [350/352], Train Acc: 95.8103 Loss: 0.6463\n",
      "  Validation Accuracy after Epoch 32: 89.8200\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [33/83], Batch [350/352], Train Acc: 96.1808 Loss: 0.6343\n",
      "  Validation Accuracy after Epoch 33: 90.1800\n",
      "  Cidar10.1 Accuracy: 81.2\n",
      "  Epoch [34/83], Batch [350/352], Train Acc: 96.3304 Loss: 0.5965\n",
      "  Validation Accuracy after Epoch 34: 90.5400\n",
      "  Cidar10.1 Accuracy: 81.55\n",
      "  Epoch [35/83], Batch [350/352], Train Acc: 96.7232 Loss: 0.5849\n",
      "  Validation Accuracy after Epoch 35: 91.0400\n",
      "  Cidar10.1 Accuracy: 81.4\n",
      "  Epoch [36/83], Batch [350/352], Train Acc: 96.8839 Loss: 0.5595\n",
      "  Validation Accuracy after Epoch 36: 90.8000\n",
      "  Cidar10.1 Accuracy: 80.7\n",
      "  Epoch [37/83], Batch [350/352], Train Acc: 97.1853 Loss: 0.5676\n",
      "  Validation Accuracy after Epoch 37: 90.3400\n",
      "  Cidar10.1 Accuracy: 81.95\n",
      "  Epoch [38/83], Batch [350/352], Train Acc: 97.4062 Loss: 0.5855\n",
      "  Validation Accuracy after Epoch 38: 90.6600\n",
      "  Cidar10.1 Accuracy: 82.5\n",
      "  Epoch [39/83], Batch [350/352], Train Acc: 97.5781 Loss: 0.5847\n",
      "  Validation Accuracy after Epoch 39: 91.1600\n",
      "  Cidar10.1 Accuracy: 82.4\n",
      "  Epoch [40/83], Batch [350/352], Train Acc: 97.7277 Loss: 0.5765\n",
      "  Validation Accuracy after Epoch 40: 90.4200\n",
      "  Cidar10.1 Accuracy: 81.3\n",
      "  Epoch [41/83], Batch [350/352], Train Acc: 97.8996 Loss: 0.5813\n",
      "  Validation Accuracy after Epoch 41: 90.9000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:33:31,171] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=33\n",
      "num_epochs: 79\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9001718422710838\n",
      "beta2: 0.9940176430135621\n",
      "lr: 0.0006715050944127252\n",
      "weight_decay: 0.002985920992930216\n",
      "max_lr: 0.007472250594440746\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/79], Batch [350/352], Train Acc: 45.3906 Loss: 1.5493\n",
      "  Validation Accuracy after Epoch 1: 54.6000\n",
      "  Cidar10.1 Accuracy: 44.35\n",
      "  Epoch [2/79], Batch [350/352], Train Acc: 63.0179 Loss: 1.2564\n",
      "  Validation Accuracy after Epoch 2: 63.3200\n",
      "  Cidar10.1 Accuracy: 51.65\n",
      "  Epoch [3/79], Batch [350/352], Train Acc: 70.1406 Loss: 1.1126\n",
      "  Validation Accuracy after Epoch 3: 71.6800\n",
      "  Cidar10.1 Accuracy: 57.95\n",
      "  Epoch [4/79], Batch [350/352], Train Acc: 74.2812 Loss: 1.0171\n",
      "  Validation Accuracy after Epoch 4: 70.1600\n",
      "  Cidar10.1 Accuracy: 55.2\n",
      "  Epoch [5/79], Batch [350/352], Train Acc: 76.6942 Loss: 0.9745\n",
      "  Validation Accuracy after Epoch 5: 74.9600\n",
      "  Cidar10.1 Accuracy: 64.8\n",
      "  Epoch [6/79], Batch [350/352], Train Acc: 78.6205 Loss: 0.9909\n",
      "  Validation Accuracy after Epoch 6: 69.2800\n",
      "  Cidar10.1 Accuracy: 59.35\n",
      "  Epoch [7/79], Batch [350/352], Train Acc: 79.8817 Loss: 1.0316\n",
      "  Validation Accuracy after Epoch 7: 77.3000\n",
      "  Cidar10.1 Accuracy: 66.2\n",
      "  Epoch [8/79], Batch [350/352], Train Acc: 81.4018 Loss: 0.9145\n",
      "  Validation Accuracy after Epoch 8: 77.1000\n",
      "  Cidar10.1 Accuracy: 62.5\n",
      "  Epoch [9/79], Batch [350/352], Train Acc: 82.7165 Loss: 0.8174\n",
      "  Validation Accuracy after Epoch 9: 80.5200\n",
      "  Cidar10.1 Accuracy: 68.85\n",
      "  Epoch [10/79], Batch [350/352], Train Acc: 83.6295 Loss: 0.9050\n",
      "  Validation Accuracy after Epoch 10: 82.3800\n",
      "  Cidar10.1 Accuracy: 72.15\n",
      "  Epoch [11/79], Batch [350/352], Train Acc: 84.6808 Loss: 0.9339\n",
      "  Validation Accuracy after Epoch 11: 78.8000\n",
      "  Cidar10.1 Accuracy: 63.2\n",
      "  Epoch [12/79], Batch [350/352], Train Acc: 85.6317 Loss: 0.9147\n",
      "  Validation Accuracy after Epoch 12: 81.1000\n",
      "  Cidar10.1 Accuracy: 71.8\n",
      "  Epoch [13/79], Batch [350/352], Train Acc: 86.6830 Loss: 0.8315\n",
      "  Validation Accuracy after Epoch 13: 82.2200\n",
      "  Cidar10.1 Accuracy: 70.1\n",
      "  Epoch [14/79], Batch [350/352], Train Acc: 87.2589 Loss: 0.8157\n",
      "  Validation Accuracy after Epoch 14: 83.6200\n",
      "  Cidar10.1 Accuracy: 72.35\n",
      "  Epoch [15/79], Batch [350/352], Train Acc: 87.9330 Loss: 0.7291\n",
      "  Validation Accuracy after Epoch 15: 84.7200\n",
      "  Cidar10.1 Accuracy: 74.05\n",
      "  Epoch [16/79], Batch [350/352], Train Acc: 88.6496 Loss: 0.7593\n",
      "  Validation Accuracy after Epoch 16: 85.4000\n",
      "  Cidar10.1 Accuracy: 75.25\n",
      "  Epoch [17/79], Batch [350/352], Train Acc: 89.2545 Loss: 0.7597\n",
      "  Validation Accuracy after Epoch 17: 85.0800\n",
      "  Cidar10.1 Accuracy: 75.25\n",
      "  Epoch [18/79], Batch [350/352], Train Acc: 89.7143 Loss: 0.7457\n",
      "  Validation Accuracy after Epoch 18: 85.4200\n",
      "  Cidar10.1 Accuracy: 74.0\n",
      "  Epoch [19/79], Batch [350/352], Train Acc: 90.3772 Loss: 0.7290\n",
      "  Validation Accuracy after Epoch 19: 86.5200\n",
      "  Cidar10.1 Accuracy: 76.05\n",
      "  Epoch [20/79], Batch [350/352], Train Acc: 90.6540 Loss: 0.7305\n",
      "  Validation Accuracy after Epoch 20: 87.6400\n",
      "  Cidar10.1 Accuracy: 77.05\n",
      "  Epoch [21/79], Batch [350/352], Train Acc: 91.2500 Loss: 0.7373\n",
      "  Validation Accuracy after Epoch 21: 85.6800\n",
      "  Cidar10.1 Accuracy: 77.85\n",
      "  Epoch [22/79], Batch [350/352], Train Acc: 91.8438 Loss: 0.6539\n",
      "  Validation Accuracy after Epoch 22: 86.4600\n",
      "  Cidar10.1 Accuracy: 77.9\n",
      "  Epoch [23/79], Batch [350/352], Train Acc: 92.3259 Loss: 0.7630\n",
      "  Validation Accuracy after Epoch 23: 86.3000\n",
      "  Cidar10.1 Accuracy: 77.05\n",
      "  Epoch [24/79], Batch [350/352], Train Acc: 92.8839 Loss: 0.7095\n",
      "  Validation Accuracy after Epoch 24: 87.5600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:37:22,741] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=34\n",
      "num_epochs: 72\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.884271023376763\n",
      "beta2: 0.9951349307077931\n",
      "lr: 0.0004005652168834438\n",
      "weight_decay: 0.0015319351676706355\n",
      "max_lr: 0.0026813770655853665\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/72], Batch [350/352], Train Acc: 43.1585 Loss: 1.6426\n",
      "  Validation Accuracy after Epoch 1: 50.4000\n",
      "  Cidar10.1 Accuracy: 41.9\n",
      "  Epoch [2/72], Batch [350/352], Train Acc: 58.1853 Loss: 1.4540\n",
      "  Validation Accuracy after Epoch 2: 59.6600\n",
      "  Cidar10.1 Accuracy: 45.6\n",
      "  Epoch [3/72], Batch [350/352], Train Acc: 65.2254 Loss: 1.1853\n",
      "  Validation Accuracy after Epoch 3: 64.3800\n",
      "  Cidar10.1 Accuracy: 53.75\n",
      "  Epoch [4/72], Batch [350/352], Train Acc: 70.2991 Loss: 1.1232\n",
      "  Validation Accuracy after Epoch 4: 71.7200\n",
      "  Cidar10.1 Accuracy: 60.25\n",
      "  Epoch [5/72], Batch [350/352], Train Acc: 73.7254 Loss: 1.0052\n",
      "  Validation Accuracy after Epoch 5: 72.8000\n",
      "  Cidar10.1 Accuracy: 57.6\n",
      "  Epoch [6/72], Batch [350/352], Train Acc: 76.3482 Loss: 1.0507\n",
      "  Validation Accuracy after Epoch 6: 75.9000\n",
      "  Cidar10.1 Accuracy: 63.85\n",
      "  Epoch [7/72], Batch [350/352], Train Acc: 77.8906 Loss: 0.9605\n",
      "  Validation Accuracy after Epoch 7: 77.8600\n",
      "  Cidar10.1 Accuracy: 65.45\n",
      "  Epoch [8/72], Batch [350/352], Train Acc: 79.2411 Loss: 0.9885\n",
      "  Validation Accuracy after Epoch 8: 77.2600\n",
      "  Cidar10.1 Accuracy: 66.3\n",
      "  Epoch [9/72], Batch [350/352], Train Acc: 80.9420 Loss: 1.0069\n",
      "  Validation Accuracy after Epoch 9: 74.9800\n",
      "  Cidar10.1 Accuracy: 62.2\n",
      "  Epoch [10/72], Batch [350/352], Train Acc: 82.1473 Loss: 0.9597\n",
      "  Validation Accuracy after Epoch 10: 79.6800\n",
      "  Cidar10.1 Accuracy: 68.9\n",
      "  Epoch [11/72], Batch [350/352], Train Acc: 83.4107 Loss: 0.9012\n",
      "  Validation Accuracy after Epoch 11: 81.2400\n",
      "  Cidar10.1 Accuracy: 71.2\n",
      "  Epoch [12/72], Batch [350/352], Train Acc: 84.4018 Loss: 0.8845\n",
      "  Validation Accuracy after Epoch 12: 82.7600\n",
      "  Cidar10.1 Accuracy: 73.1\n",
      "  Epoch [13/72], Batch [350/352], Train Acc: 85.5379 Loss: 0.9073\n",
      "  Validation Accuracy after Epoch 13: 84.1600\n",
      "  Cidar10.1 Accuracy: 75.05\n",
      "  Epoch [14/72], Batch [350/352], Train Acc: 86.3080 Loss: 0.8470\n",
      "  Validation Accuracy after Epoch 14: 85.2800\n",
      "  Cidar10.1 Accuracy: 75.7\n",
      "  Epoch [15/72], Batch [350/352], Train Acc: 87.3839 Loss: 0.7862\n",
      "  Validation Accuracy after Epoch 15: 84.0800\n",
      "  Cidar10.1 Accuracy: 73.5\n",
      "  Epoch [16/72], Batch [350/352], Train Acc: 87.9509 Loss: 0.7080\n",
      "  Validation Accuracy after Epoch 16: 85.6000\n",
      "  Cidar10.1 Accuracy: 75.95\n",
      "  Epoch [17/72], Batch [350/352], Train Acc: 88.5603 Loss: 0.7620\n",
      "  Validation Accuracy after Epoch 17: 85.4000\n",
      "  Cidar10.1 Accuracy: 76.4\n",
      "  Epoch [18/72], Batch [350/352], Train Acc: 89.4531 Loss: 0.7665\n",
      "  Validation Accuracy after Epoch 18: 86.0600\n",
      "  Cidar10.1 Accuracy: 77.15\n",
      "  Epoch [19/72], Batch [350/352], Train Acc: 90.1205 Loss: 0.6973\n",
      "  Validation Accuracy after Epoch 19: 87.1400\n",
      "  Cidar10.1 Accuracy: 77.5\n",
      "  Epoch [20/72], Batch [350/352], Train Acc: 90.7366 Loss: 0.8377\n",
      "  Validation Accuracy after Epoch 20: 87.4000\n",
      "  Cidar10.1 Accuracy: 79.75\n",
      "  Epoch [21/72], Batch [350/352], Train Acc: 91.4129 Loss: 0.7482\n",
      "  Validation Accuracy after Epoch 21: 87.0600\n",
      "  Cidar10.1 Accuracy: 78.05\n",
      "  Epoch [22/72], Batch [350/352], Train Acc: 92.0357 Loss: 0.7116\n",
      "  Validation Accuracy after Epoch 22: 88.1200\n",
      "  Cidar10.1 Accuracy: 79.1\n",
      "  Epoch [23/72], Batch [350/352], Train Acc: 92.7299 Loss: 0.7346\n",
      "  Validation Accuracy after Epoch 23: 87.9400\n",
      "  Cidar10.1 Accuracy: 78.8\n",
      "  Epoch [24/72], Batch [350/352], Train Acc: 93.3415 Loss: 0.6982\n",
      "  Validation Accuracy after Epoch 24: 88.7800\n",
      "  Cidar10.1 Accuracy: 81.1\n",
      "  Epoch [25/72], Batch [350/352], Train Acc: 93.6429 Loss: 0.7086\n",
      "  Validation Accuracy after Epoch 25: 89.7800\n",
      "  Cidar10.1 Accuracy: 80.75\n",
      "  Epoch [26/72], Batch [350/352], Train Acc: 94.2031 Loss: 0.6230\n",
      "  Validation Accuracy after Epoch 26: 88.0600\n",
      "  Cidar10.1 Accuracy: 78.45\n",
      "  Epoch [27/72], Batch [350/352], Train Acc: 94.5938 Loss: 0.6197\n",
      "  Validation Accuracy after Epoch 27: 89.7600\n",
      "  Cidar10.1 Accuracy: 82.6\n",
      "  Epoch [28/72], Batch [350/352], Train Acc: 95.1384 Loss: 0.6343\n",
      "  Validation Accuracy after Epoch 28: 89.6600\n",
      "  Cidar10.1 Accuracy: 82.15\n",
      "  Epoch [29/72], Batch [350/352], Train Acc: 95.4665 Loss: 0.6514\n",
      "  Validation Accuracy after Epoch 29: 89.7000\n",
      "  Cidar10.1 Accuracy: 80.5\n",
      "  Epoch [30/72], Batch [350/352], Train Acc: 95.7567 Loss: 0.6806\n",
      "  Validation Accuracy after Epoch 30: 89.3200\n",
      "  Cidar10.1 Accuracy: 81.2\n",
      "  Epoch [31/72], Batch [350/352], Train Acc: 96.3996 Loss: 0.6495\n",
      "  Validation Accuracy after Epoch 31: 90.7200\n",
      "  Cidar10.1 Accuracy: 82.7\n",
      "  Epoch [32/72], Batch [350/352], Train Acc: 96.3571 Loss: 0.5858\n",
      "  Validation Accuracy after Epoch 32: 90.3600\n",
      "  Cidar10.1 Accuracy: 82.15\n",
      "  Epoch [33/72], Batch [350/352], Train Acc: 96.7433 Loss: 0.6002\n",
      "  Validation Accuracy after Epoch 33: 90.7800\n",
      "  Cidar10.1 Accuracy: 82.25\n",
      "  Epoch [34/72], Batch [350/352], Train Acc: 97.1674 Loss: 0.5563\n",
      "  Validation Accuracy after Epoch 34: 90.2400\n",
      "  Cidar10.1 Accuracy: 81.7\n",
      "  Epoch [35/72], Batch [350/352], Train Acc: 97.2522 Loss: 0.5920\n",
      "  Validation Accuracy after Epoch 35: 90.1600\n",
      "  Cidar10.1 Accuracy: 81.9\n",
      "  Epoch [36/72], Batch [350/352], Train Acc: 97.4308 Loss: 0.5571\n",
      "  Validation Accuracy after Epoch 36: 90.7600\n",
      "  Cidar10.1 Accuracy: 83.65\n",
      "  Epoch [37/72], Batch [350/352], Train Acc: 97.8661 Loss: 0.5932\n",
      "  Validation Accuracy after Epoch 37: 91.4600\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [38/72], Batch [350/352], Train Acc: 97.9531 Loss: 0.5871\n",
      "  Validation Accuracy after Epoch 38: 91.1600\n",
      "  Cidar10.1 Accuracy: 84.0\n",
      "  Epoch [39/72], Batch [350/352], Train Acc: 98.2143 Loss: 0.5559\n",
      "  Validation Accuracy after Epoch 39: 91.6800\n",
      "  Cidar10.1 Accuracy: 84.1\n",
      "  Epoch [40/72], Batch [350/352], Train Acc: 98.3415 Loss: 0.5628\n",
      "  Validation Accuracy after Epoch 40: 91.3800\n",
      "  Cidar10.1 Accuracy: 83.8\n",
      "  Epoch [41/72], Batch [350/352], Train Acc: 98.5156 Loss: 0.5534\n",
      "  Validation Accuracy after Epoch 41: 90.8800\n",
      "  Cidar10.1 Accuracy: 82.45\n",
      "  Epoch [42/72], Batch [350/352], Train Acc: 98.6562 Loss: 0.5567\n",
      "  Validation Accuracy after Epoch 42: 91.8600\n",
      "  Cidar10.1 Accuracy: 83.7\n",
      "  Epoch [43/72], Batch [350/352], Train Acc: 98.7433 Loss: 0.5432\n",
      "  Validation Accuracy after Epoch 43: 91.7400\n",
      "  Cidar10.1 Accuracy: 84.95\n",
      "  Epoch [44/72], Batch [350/352], Train Acc: 98.9554 Loss: 0.5420\n",
      "  Validation Accuracy after Epoch 44: 91.5400\n",
      "  Cidar10.1 Accuracy: 83.4\n",
      "  Epoch [45/72], Batch [350/352], Train Acc: 99.0871 Loss: 0.5529\n",
      "  Validation Accuracy after Epoch 45: 91.7800\n",
      "  Cidar10.1 Accuracy: 84.25\n",
      "  Epoch [46/72], Batch [350/352], Train Acc: 99.2031 Loss: 0.5260\n",
      "  Validation Accuracy after Epoch 46: 92.2400\n",
      "  Cidar10.1 Accuracy: 84.65\n",
      "  Epoch [47/72], Batch [350/352], Train Acc: 99.2500 Loss: 0.5569\n",
      "  Validation Accuracy after Epoch 47: 92.2200\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [48/72], Batch [350/352], Train Acc: 99.2679 Loss: 0.5314\n",
      "  Validation Accuracy after Epoch 48: 92.2600\n",
      "  Cidar10.1 Accuracy: 84.7\n",
      "  Epoch [49/72], Batch [350/352], Train Acc: 99.4196 Loss: 0.5206\n",
      "  Validation Accuracy after Epoch 49: 91.7400\n",
      "  Cidar10.1 Accuracy: 84.5\n",
      "  Epoch [50/72], Batch [350/352], Train Acc: 99.4688 Loss: 0.5415\n",
      "  Validation Accuracy after Epoch 50: 91.7200\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [51/72], Batch [350/352], Train Acc: 99.5759 Loss: 0.5223\n",
      "  Validation Accuracy after Epoch 51: 92.4400\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [52/72], Batch [350/352], Train Acc: 99.6473 Loss: 0.5298\n",
      "  Validation Accuracy after Epoch 52: 92.2400\n",
      "  Cidar10.1 Accuracy: 86.1\n",
      "  Epoch [53/72], Batch [350/352], Train Acc: 99.7031 Loss: 0.5367\n",
      "  Validation Accuracy after Epoch 53: 92.5800\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [54/72], Batch [350/352], Train Acc: 99.6808 Loss: 0.5245\n",
      "  Validation Accuracy after Epoch 54: 92.6400\n",
      "  Cidar10.1 Accuracy: 85.8\n",
      "  Epoch [55/72], Batch [350/352], Train Acc: 99.7589 Loss: 0.5305\n",
      "  Validation Accuracy after Epoch 55: 92.5000\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [56/72], Batch [350/352], Train Acc: 99.8125 Loss: 0.5137\n",
      "  Validation Accuracy after Epoch 56: 92.9600\n",
      "  Cidar10.1 Accuracy: 85.9\n",
      "  Epoch [57/72], Batch [350/352], Train Acc: 99.7991 Loss: 0.5167\n",
      "  Validation Accuracy after Epoch 57: 92.7800\n",
      "  Cidar10.1 Accuracy: 85.45\n",
      "  Epoch [58/72], Batch [350/352], Train Acc: 99.8393 Loss: 0.5207\n",
      "  Validation Accuracy after Epoch 58: 93.1200\n",
      "  Cidar10.1 Accuracy: 85.75\n",
      "  Epoch [59/72], Batch [350/352], Train Acc: 99.8504 Loss: 0.5113\n",
      "  Validation Accuracy after Epoch 59: 92.9200\n",
      "  Cidar10.1 Accuracy: 86.15\n",
      "  Epoch [60/72], Batch [350/352], Train Acc: 99.8750 Loss: 0.5155\n",
      "  Validation Accuracy after Epoch 60: 92.4600\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [61/72], Batch [350/352], Train Acc: 99.8616 Loss: 0.5128\n",
      "  Validation Accuracy after Epoch 61: 93.3200\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [62/72], Batch [350/352], Train Acc: 99.9085 Loss: 0.5121\n",
      "  Validation Accuracy after Epoch 62: 92.8600\n",
      "  Cidar10.1 Accuracy: 85.95\n",
      "  Epoch [63/72], Batch [350/352], Train Acc: 99.9018 Loss: 0.5088\n",
      "  Validation Accuracy after Epoch 63: 93.1800\n",
      "  Cidar10.1 Accuracy: 85.8\n",
      "  Epoch [64/72], Batch [350/352], Train Acc: 99.9397 Loss: 0.5079\n",
      "  Validation Accuracy after Epoch 64: 93.4600\n",
      "  Cidar10.1 Accuracy: 85.85\n",
      "  Epoch [65/72], Batch [350/352], Train Acc: 99.9598 Loss: 0.5098\n",
      "  Validation Accuracy after Epoch 65: 92.9400\n",
      "  Cidar10.1 Accuracy: 85.9\n",
      "  Epoch [66/72], Batch [350/352], Train Acc: 99.9598 Loss: 0.5180\n",
      "  Validation Accuracy after Epoch 66: 93.3400\n",
      "  Cidar10.1 Accuracy: 85.95\n",
      "  Epoch [67/72], Batch [350/352], Train Acc: 99.9598 Loss: 0.5088\n",
      "  Validation Accuracy after Epoch 67: 92.9600\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "  Epoch [68/72], Batch [350/352], Train Acc: 99.9576 Loss: 0.5065\n",
      "  Validation Accuracy after Epoch 68: 93.1200\n",
      "  Cidar10.1 Accuracy: 85.8\n",
      "  Epoch [69/72], Batch [350/352], Train Acc: 99.9554 Loss: 0.5080\n",
      "  Validation Accuracy after Epoch 69: 93.1400\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "  Epoch [70/72], Batch [350/352], Train Acc: 99.9509 Loss: 0.5088\n",
      "  Validation Accuracy after Epoch 70: 93.6200\n",
      "  Cidar10.1 Accuracy: 85.9\n",
      "  Epoch [71/72], Batch [350/352], Train Acc: 99.9509 Loss: 0.5081\n",
      "  Validation Accuracy after Epoch 71: 93.5600\n",
      "  Cidar10.1 Accuracy: 86.15\n",
      "  Epoch [72/72], Batch [350/352], Train Acc: 99.9531 Loss: 0.5088\n",
      "  Validation Accuracy after Epoch 72: 93.4200\n",
      "  Cidar10.1 Accuracy: 86.05\n",
      "Trial 34 complete. Best Validation Accuracy: 93.6200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:48:54,056] Trial 34 finished with value: 93.62 and parameters: {'num_epochs': 72, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.884271023376763, 'beta2': 0.9951349307077931, 'lr': 0.0004005652168834438, 'weight_decay': 0.0015319351676706355, 'max_lr': 0.0026813770655853665}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=35\n",
      "num_epochs: 56\n",
      "model_type: efficientnet\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.9236113193432982\n",
      "beta2: 0.9971087219192833\n",
      "lr: 0.0036197521756823913\n",
      "weight_decay: 1.9304968623112836e-06\n",
      "factor: 0.395420447090195\n",
      "patience: 12\n",
      "threshold: 0.04073536840989944\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/56], Batch [350/352], Train Acc: 28.8973 Loss: 1.6696\n",
      "  Validation Accuracy after Epoch 1: 38.5400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:49:12,593] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=36\n",
      "num_epochs: 77\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8691036942242727\n",
      "beta2: 0.9980585970032295\n",
      "lr: 0.0007645024828404152\n",
      "weight_decay: 0.0026090938989054946\n",
      "max_lr: 0.004431443918776483\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/77], Batch [350/352], Train Acc: 44.5915 Loss: 1.5845\n",
      "  Validation Accuracy after Epoch 1: 53.6600\n",
      "  Cidar10.1 Accuracy: 45.15\n",
      "  Epoch [2/77], Batch [350/352], Train Acc: 61.3036 Loss: 1.2755\n",
      "  Validation Accuracy after Epoch 2: 61.1400\n",
      "  Cidar10.1 Accuracy: 48.3\n",
      "  Epoch [3/77], Batch [350/352], Train Acc: 68.7388 Loss: 1.1205\n",
      "  Validation Accuracy after Epoch 3: 68.8800\n",
      "  Cidar10.1 Accuracy: 56.05\n",
      "  Epoch [4/77], Batch [350/352], Train Acc: 72.8705 Loss: 1.0422\n",
      "  Validation Accuracy after Epoch 4: 68.2600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:49:52,643] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=37\n",
      "num_epochs: 86\n",
      "model_type: smallresnet\n",
      "batch_size: 64\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9076854929173471\n",
      "beta2: 0.9920098939691865\n",
      "lr: 0.000940856322310039\n",
      "weight_decay: 0.0016902872483510808\n",
      "max_lr: 0.00621611095613139\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/86], Batch [700/704], Train Acc: 38.1272 Loss: 1.5431\n",
      "  Validation Accuracy after Epoch 1: 46.7200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:50:11,136] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=38\n",
      "num_epochs: 98\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: CosineAnnealingLR\n",
      "beta1: 0.9196180293656578\n",
      "beta2: 0.9961911456860105\n",
      "lr: 0.003991954007558586\n",
      "weight_decay: 0.0005701230415544971\n",
      "eta_min: 1.0625331144193528e-05\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/98], Batch [350/352], Train Acc: 33.4799 Loss: 1.7667\n",
      "  Validation Accuracy after Epoch 1: 37.9000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:50:22,186] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=39\n",
      "num_epochs: 80\n",
      "model_type: efficientnet\n",
      "batch_size: 256\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.9010629419283134\n",
      "beta2: 0.9943807084798203\n",
      "lr: 0.00020755762816292655\n",
      "weight_decay: 0.0057415202671418685\n",
      "factor: 0.2839614991187505\n",
      "patience: 12\n",
      "threshold: 0.04758901736319455\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/80], Batch [170/176], Train Acc: 20.9858 Loss: 2.0030\n",
      "  Validation Accuracy after Epoch 1: 31.1800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:50:34,645] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=40\n",
      "num_epochs: 90\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "lr: 0.027964770773100004\n",
      "momentum: 0.9042583323913435\n",
      "weight_decay: 6.123421436856628e-05\n",
      "max_lr: 0.05758463112165749\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/90], Batch [350/352], Train Acc: 40.6696 Loss: 1.6255\n",
      "  Validation Accuracy after Epoch 1: 49.1800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:50:45,745] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=41\n",
      "num_epochs: 71\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8837644722680488\n",
      "beta2: 0.9951729922333051\n",
      "lr: 0.0004160919351921743\n",
      "weight_decay: 0.0017044795021567002\n",
      "max_lr: 0.00183825401141263\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/71], Batch [350/352], Train Acc: 41.4509 Loss: 1.7010\n",
      "  Validation Accuracy after Epoch 1: 47.2400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:50:56,999] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=42\n",
      "num_epochs: 74\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8938022965540827\n",
      "beta2: 0.9956319331245538\n",
      "lr: 0.00046342202431285637\n",
      "weight_decay: 0.0019033866361377423\n",
      "max_lr: 0.0010529073568140606\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/74], Batch [350/352], Train Acc: 38.7121 Loss: 1.6966\n",
      "  Validation Accuracy after Epoch 1: 44.0400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:51:07,944] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=43\n",
      "num_epochs: 66\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8827833613868782\n",
      "beta2: 0.9948819985082877\n",
      "lr: 0.0003217088697463318\n",
      "weight_decay: 0.00140822873912098\n",
      "max_lr: 0.0028305892300322334\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/66], Batch [350/352], Train Acc: 43.3527 Loss: 1.6379\n",
      "  Validation Accuracy after Epoch 1: 49.4200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:51:19,038] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=44\n",
      "num_epochs: 82\n",
      "model_type: smallresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8696683153987115\n",
      "beta2: 0.9933488909899162\n",
      "lr: 0.0009424375622591268\n",
      "weight_decay: 0.0038466011240915064\n",
      "max_lr: 0.003845667803896496\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/82], Batch [350/352], Train Acc: 33.5781 Loss: 1.7974\n",
      "  Validation Accuracy after Epoch 1: 41.1600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:51:32,056] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=45\n",
      "num_epochs: 60\n",
      "model_type: largeresnet\n",
      "batch_size: 256\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8886740104738021\n",
      "beta2: 0.9942850551333878\n",
      "lr: 0.0005842473726413349\n",
      "weight_decay: 0.0028001051402299806\n",
      "max_lr: 0.0050481093738457905\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/60], Batch [170/176], Train Acc: 42.4724 Loss: 1.5731\n",
      "  Validation Accuracy after Epoch 1: 50.1800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:51:43,129] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=46\n",
      "num_epochs: 69\n",
      "model_type: efficientnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8981082613493693\n",
      "beta2: 0.990535915134037\n",
      "lr: 0.00020903391918654964\n",
      "weight_decay: 0.001345224847402742\n",
      "max_lr: 0.0024101471229715115\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/69], Batch [350/352], Train Acc: 19.5625 Loss: 2.0142\n",
      "  Validation Accuracy after Epoch 1: 29.1400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:52:00,518] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=47\n",
      "num_epochs: 54\n",
      "model_type: largeresnet\n",
      "batch_size: 64\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.8502254994861959\n",
      "beta2: 0.9967344893434553\n",
      "lr: 0.0014869594084288497\n",
      "weight_decay: 0.0006995646411842861\n",
      "factor: 0.2548562311613708\n",
      "patience: 15\n",
      "threshold: 0.09236393370963508\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/54], Batch [700/704], Train Acc: 43.0022 Loss: 1.4216\n",
      "  Validation Accuracy after Epoch 1: 45.6800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:52:12,922] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=48\n",
      "num_epochs: 77\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9124125557788891\n",
      "beta2: 0.9959659941716346\n",
      "lr: 2.3400960978663865e-05\n",
      "weight_decay: 0.02777045789100667\n",
      "max_lr: 0.006012142952119021\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/77], Batch [350/352], Train Acc: 45.1897 Loss: 1.5633\n",
      "  Validation Accuracy after Epoch 1: 53.6800\n",
      "  Cidar10.1 Accuracy: 45.0\n",
      "  Epoch [2/77], Batch [350/352], Train Acc: 62.2545 Loss: 1.2840\n",
      "  Validation Accuracy after Epoch 2: 66.2600\n",
      "  Cidar10.1 Accuracy: 51.75\n",
      "  Epoch [3/77], Batch [350/352], Train Acc: 69.9621 Loss: 1.2777\n",
      "  Validation Accuracy after Epoch 3: 66.6200\n",
      "  Cidar10.1 Accuracy: 54.7\n",
      "  Epoch [4/77], Batch [350/352], Train Acc: 73.8772 Loss: 1.0304\n",
      "  Validation Accuracy after Epoch 4: 75.7600\n",
      "  Cidar10.1 Accuracy: 62.8\n",
      "  Epoch [5/77], Batch [350/352], Train Acc: 76.4576 Loss: 1.0757\n",
      "  Validation Accuracy after Epoch 5: 75.0400\n",
      "  Cidar10.1 Accuracy: 62.25\n",
      "  Epoch [6/77], Batch [350/352], Train Acc: 78.2188 Loss: 1.0841\n",
      "  Validation Accuracy after Epoch 6: 75.0800\n",
      "  Cidar10.1 Accuracy: 61.25\n",
      "  Epoch [7/77], Batch [350/352], Train Acc: 79.7478 Loss: 0.9155\n",
      "  Validation Accuracy after Epoch 7: 74.5000\n",
      "  Cidar10.1 Accuracy: 61.65\n",
      "  Epoch [8/77], Batch [350/352], Train Acc: 81.0223 Loss: 0.8921\n",
      "  Validation Accuracy after Epoch 8: 79.8800\n",
      "  Cidar10.1 Accuracy: 68.05\n",
      "  Epoch [9/77], Batch [350/352], Train Acc: 82.2455 Loss: 0.9530\n",
      "  Validation Accuracy after Epoch 9: 78.1600\n",
      "  Cidar10.1 Accuracy: 67.35\n",
      "  Epoch [10/77], Batch [350/352], Train Acc: 83.1942 Loss: 0.9364\n",
      "  Validation Accuracy after Epoch 10: 81.1000\n",
      "  Cidar10.1 Accuracy: 68.15\n",
      "  Epoch [11/77], Batch [350/352], Train Acc: 84.4888 Loss: 0.9320\n",
      "  Validation Accuracy after Epoch 11: 81.1400\n",
      "  Cidar10.1 Accuracy: 71.75\n",
      "  Epoch [12/77], Batch [350/352], Train Acc: 85.0446 Loss: 0.9277\n",
      "  Validation Accuracy after Epoch 12: 82.8200\n",
      "  Cidar10.1 Accuracy: 73.6\n",
      "  Epoch [13/77], Batch [350/352], Train Acc: 86.2879 Loss: 0.8416\n",
      "  Validation Accuracy after Epoch 13: 83.2000\n",
      "  Cidar10.1 Accuracy: 75.3\n",
      "  Epoch [14/77], Batch [350/352], Train Acc: 86.8080 Loss: 0.9232\n",
      "  Validation Accuracy after Epoch 14: 80.9200\n",
      "  Cidar10.1 Accuracy: 71.1\n",
      "  Epoch [15/77], Batch [350/352], Train Acc: 87.2455 Loss: 0.7825\n",
      "  Validation Accuracy after Epoch 15: 85.1600\n",
      "  Cidar10.1 Accuracy: 74.75\n",
      "  Epoch [16/77], Batch [350/352], Train Acc: 87.8571 Loss: 0.7869\n",
      "  Validation Accuracy after Epoch 16: 84.4000\n",
      "  Cidar10.1 Accuracy: 75.3\n",
      "  Epoch [17/77], Batch [350/352], Train Acc: 88.0268 Loss: 0.7365\n",
      "  Validation Accuracy after Epoch 17: 85.0800\n",
      "  Cidar10.1 Accuracy: 76.9\n",
      "  Epoch [18/77], Batch [350/352], Train Acc: 88.6607 Loss: 0.8511\n",
      "  Validation Accuracy after Epoch 18: 86.7000\n",
      "  Cidar10.1 Accuracy: 78.6\n",
      "  Epoch [19/77], Batch [350/352], Train Acc: 89.2411 Loss: 0.7895\n",
      "  Validation Accuracy after Epoch 19: 85.8800\n",
      "  Cidar10.1 Accuracy: 76.1\n",
      "  Epoch [20/77], Batch [350/352], Train Acc: 89.5446 Loss: 0.6996\n",
      "  Validation Accuracy after Epoch 20: 84.5200\n",
      "  Cidar10.1 Accuracy: 73.95\n",
      "  Epoch [21/77], Batch [350/352], Train Acc: 89.9040 Loss: 0.7356\n",
      "  Validation Accuracy after Epoch 21: 86.3800\n",
      "  Cidar10.1 Accuracy: 76.1\n",
      "  Epoch [22/77], Batch [350/352], Train Acc: 90.5246 Loss: 0.7239\n",
      "  Validation Accuracy after Epoch 22: 83.9000\n",
      "  Cidar10.1 Accuracy: 74.1\n",
      "  Epoch [23/77], Batch [350/352], Train Acc: 90.6562 Loss: 0.7810\n",
      "  Validation Accuracy after Epoch 23: 86.7800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:55:54,199] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=49\n",
      "num_epochs: 72\n",
      "model_type: largeresnet\n",
      "batch_size: 256\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8747378195132446\n",
      "beta2: 0.9949716424990954\n",
      "lr: 0.000489195494827169\n",
      "weight_decay: 0.0032382862422623135\n",
      "max_lr: 0.007359554936660896\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/72], Batch [170/176], Train Acc: 43.4145 Loss: 1.5123\n",
      "  Validation Accuracy after Epoch 1: 52.3800\n",
      "  Cidar10.1 Accuracy: 42.45\n",
      "  Epoch [2/72], Batch [170/176], Train Acc: 60.0483 Loss: 1.2626\n",
      "  Validation Accuracy after Epoch 2: 62.2000\n",
      "  Cidar10.1 Accuracy: 49.25\n",
      "  Epoch [3/72], Batch [170/176], Train Acc: 67.2082 Loss: 1.1931\n",
      "  Validation Accuracy after Epoch 3: 68.0800\n",
      "  Cidar10.1 Accuracy: 55.4\n",
      "  Epoch [4/72], Batch [170/176], Train Acc: 72.4449 Loss: 1.1066\n",
      "  Validation Accuracy after Epoch 4: 69.9600\n",
      "  Cidar10.1 Accuracy: 58.65\n",
      "  Epoch [5/72], Batch [170/176], Train Acc: 75.4527 Loss: 1.0192\n",
      "  Validation Accuracy after Epoch 5: 69.5600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:56:42,929] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=50\n",
      "num_epochs: 64\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "lr: 0.0017464490337696342\n",
      "momentum: 0.8863135872978273\n",
      "weight_decay: 0.00041514290082108615\n",
      "max_lr: 0.0476661958017129\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/64], Batch [350/352], Train Acc: 39.7902 Loss: 1.6639\n",
      "  Validation Accuracy after Epoch 1: 47.1200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 07:56:54,053] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=51\n",
      "num_epochs: 76\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8885776387771799\n",
      "beta2: 0.9951495644701408\n",
      "lr: 0.0011159502593613038\n",
      "weight_decay: 0.002247646316542258\n",
      "max_lr: 0.004346873790834831\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/76], Batch [350/352], Train Acc: 44.6897 Loss: 1.5811\n",
      "  Validation Accuracy after Epoch 1: 54.8400\n",
      "  Cidar10.1 Accuracy: 45.55\n",
      "  Epoch [2/76], Batch [350/352], Train Acc: 61.2500 Loss: 1.3459\n",
      "  Validation Accuracy after Epoch 2: 63.1800\n",
      "  Cidar10.1 Accuracy: 51.95\n",
      "  Epoch [3/76], Batch [350/352], Train Acc: 68.4576 Loss: 1.1335\n",
      "  Validation Accuracy after Epoch 3: 70.0600\n",
      "  Cidar10.1 Accuracy: 57.25\n",
      "  Epoch [4/76], Batch [350/352], Train Acc: 72.7746 Loss: 1.0476\n",
      "  Validation Accuracy after Epoch 4: 70.2400\n",
      "  Cidar10.1 Accuracy: 57.7\n",
      "  Epoch [5/76], Batch [350/352], Train Acc: 75.3549 Loss: 1.0568\n",
      "  Validation Accuracy after Epoch 5: 75.5400\n",
      "  Cidar10.1 Accuracy: 64.45\n",
      "  Epoch [6/76], Batch [350/352], Train Acc: 77.7656 Loss: 0.9185\n",
      "  Validation Accuracy after Epoch 6: 77.3200\n",
      "  Cidar10.1 Accuracy: 64.0\n",
      "  Epoch [7/76], Batch [350/352], Train Acc: 79.0580 Loss: 0.9307\n",
      "  Validation Accuracy after Epoch 7: 73.9400\n",
      "  Cidar10.1 Accuracy: 61.05\n",
      "  Epoch [8/76], Batch [350/352], Train Acc: 80.4799 Loss: 0.9900\n",
      "  Validation Accuracy after Epoch 8: 74.4200\n",
      "  Cidar10.1 Accuracy: 58.35\n",
      "  Epoch [9/76], Batch [350/352], Train Acc: 81.8795 Loss: 0.8588\n",
      "  Validation Accuracy after Epoch 9: 79.5400\n",
      "  Cidar10.1 Accuracy: 69.05\n",
      "  Epoch [10/76], Batch [350/352], Train Acc: 83.1674 Loss: 0.8817\n",
      "  Validation Accuracy after Epoch 10: 81.2800\n",
      "  Cidar10.1 Accuracy: 70.45\n",
      "  Epoch [11/76], Batch [350/352], Train Acc: 83.9866 Loss: 0.8356\n",
      "  Validation Accuracy after Epoch 11: 82.9000\n",
      "  Cidar10.1 Accuracy: 74.25\n",
      "  Epoch [12/76], Batch [350/352], Train Acc: 85.0022 Loss: 0.9444\n",
      "  Validation Accuracy after Epoch 12: 77.1600\n",
      "  Cidar10.1 Accuracy: 68.7\n",
      "  Epoch [13/76], Batch [350/352], Train Acc: 85.8170 Loss: 0.8264\n",
      "  Validation Accuracy after Epoch 13: 81.0600\n",
      "  Cidar10.1 Accuracy: 71.45\n",
      "  Epoch [14/76], Batch [350/352], Train Acc: 86.7902 Loss: 0.9204\n",
      "  Validation Accuracy after Epoch 14: 78.5400\n",
      "  Cidar10.1 Accuracy: 66.65\n",
      "  Epoch [15/76], Batch [350/352], Train Acc: 87.5871 Loss: 0.8112\n",
      "  Validation Accuracy after Epoch 15: 85.5000\n",
      "  Cidar10.1 Accuracy: 75.7\n",
      "  Epoch [16/76], Batch [350/352], Train Acc: 88.3438 Loss: 0.8051\n",
      "  Validation Accuracy after Epoch 16: 85.9400\n",
      "  Cidar10.1 Accuracy: 76.25\n",
      "  Epoch [17/76], Batch [350/352], Train Acc: 89.1629 Loss: 0.8964\n",
      "  Validation Accuracy after Epoch 17: 85.6600\n",
      "  Cidar10.1 Accuracy: 76.35\n",
      "  Epoch [18/76], Batch [350/352], Train Acc: 89.6250 Loss: 0.7909\n",
      "  Validation Accuracy after Epoch 18: 87.1600\n",
      "  Cidar10.1 Accuracy: 78.85\n",
      "  Epoch [19/76], Batch [350/352], Train Acc: 90.3504 Loss: 0.7268\n",
      "  Validation Accuracy after Epoch 19: 86.8200\n",
      "  Cidar10.1 Accuracy: 77.95\n",
      "  Epoch [20/76], Batch [350/352], Train Acc: 90.9844 Loss: 0.7398\n",
      "  Validation Accuracy after Epoch 20: 86.2600\n",
      "  Cidar10.1 Accuracy: 77.3\n",
      "  Epoch [21/76], Batch [350/352], Train Acc: 91.4866 Loss: 0.8354\n",
      "  Validation Accuracy after Epoch 21: 87.1800\n",
      "  Cidar10.1 Accuracy: 78.6\n",
      "  Epoch [22/76], Batch [350/352], Train Acc: 92.0268 Loss: 0.6915\n",
      "  Validation Accuracy after Epoch 22: 88.1800\n",
      "  Cidar10.1 Accuracy: 79.35\n",
      "  Epoch [23/76], Batch [350/352], Train Acc: 92.5938 Loss: 0.6791\n",
      "  Validation Accuracy after Epoch 23: 88.3000\n",
      "  Cidar10.1 Accuracy: 79.95\n",
      "  Epoch [24/76], Batch [350/352], Train Acc: 93.2388 Loss: 0.6249\n",
      "  Validation Accuracy after Epoch 24: 88.4400\n",
      "  Cidar10.1 Accuracy: 79.9\n",
      "  Epoch [25/76], Batch [350/352], Train Acc: 93.6629 Loss: 0.6121\n",
      "  Validation Accuracy after Epoch 25: 88.0000\n",
      "  Cidar10.1 Accuracy: 78.8\n",
      "  Epoch [26/76], Batch [350/352], Train Acc: 94.0781 Loss: 0.6576\n",
      "  Validation Accuracy after Epoch 26: 88.6000\n",
      "  Cidar10.1 Accuracy: 81.65\n",
      "  Epoch [27/76], Batch [350/352], Train Acc: 94.5179 Loss: 0.6450\n",
      "  Validation Accuracy after Epoch 27: 89.1600\n",
      "  Cidar10.1 Accuracy: 80.45\n",
      "  Epoch [28/76], Batch [350/352], Train Acc: 94.9375 Loss: 0.6715\n",
      "  Validation Accuracy after Epoch 28: 89.2200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 08:01:25,492] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=52\n",
      "num_epochs: 86\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8896254073135439\n",
      "beta2: 0.993515144656502\n",
      "lr: 0.0008102148743091755\n",
      "weight_decay: 0.0023995388962418734\n",
      "max_lr: 0.004840680956060926\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/86], Batch [350/352], Train Acc: 45.1362 Loss: 1.5498\n",
      "  Validation Accuracy after Epoch 1: 54.1400\n",
      "  Cidar10.1 Accuracy: 44.65\n",
      "  Epoch [2/86], Batch [350/352], Train Acc: 61.8616 Loss: 1.1796\n",
      "  Validation Accuracy after Epoch 2: 63.3600\n",
      "  Cidar10.1 Accuracy: 50.55\n",
      "  Epoch [3/86], Batch [350/352], Train Acc: 68.9554 Loss: 1.2551\n",
      "  Validation Accuracy after Epoch 3: 67.3000\n",
      "  Cidar10.1 Accuracy: 54.25\n",
      "  Epoch [4/86], Batch [350/352], Train Acc: 73.2946 Loss: 1.0155\n",
      "  Validation Accuracy after Epoch 4: 72.2400\n",
      "  Cidar10.1 Accuracy: 61.4\n",
      "  Epoch [5/86], Batch [350/352], Train Acc: 75.8862 Loss: 1.1141\n",
      "  Validation Accuracy after Epoch 5: 71.4400\n",
      "  Cidar10.1 Accuracy: 59.3\n",
      "  Epoch [6/86], Batch [350/352], Train Acc: 77.9955 Loss: 1.0405\n",
      "  Validation Accuracy after Epoch 6: 73.1600\n",
      "  Cidar10.1 Accuracy: 61.3\n",
      "  Epoch [7/86], Batch [350/352], Train Acc: 79.8281 Loss: 1.0242\n",
      "  Validation Accuracy after Epoch 7: 73.9200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 08:02:34,716] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=53\n",
      "num_epochs: 68\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8805357481275744\n",
      "beta2: 0.9955924937929359\n",
      "lr: 0.0012276282152372906\n",
      "weight_decay: 0.001972683877992677\n",
      "max_lr: 0.005663524668808249\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/68], Batch [350/352], Train Acc: 45.1830 Loss: 1.5523\n",
      "  Validation Accuracy after Epoch 1: 52.1200\n",
      "  Cidar10.1 Accuracy: 43.9\n",
      "  Epoch [2/68], Batch [350/352], Train Acc: 62.4353 Loss: 1.2947\n",
      "  Validation Accuracy after Epoch 2: 66.3200\n",
      "  Cidar10.1 Accuracy: 53.8\n",
      "  Epoch [3/68], Batch [350/352], Train Acc: 69.9844 Loss: 1.1308\n",
      "  Validation Accuracy after Epoch 3: 67.9800\n",
      "  Cidar10.1 Accuracy: 53.6\n",
      "  Epoch [4/68], Batch [350/352], Train Acc: 74.0379 Loss: 1.0700\n",
      "  Validation Accuracy after Epoch 4: 70.0600\n",
      "  Cidar10.1 Accuracy: 57.9\n",
      "  Epoch [5/68], Batch [350/352], Train Acc: 76.1540 Loss: 0.9487\n",
      "  Validation Accuracy after Epoch 5: 75.5800\n",
      "  Cidar10.1 Accuracy: 63.85\n",
      "  Epoch [6/68], Batch [350/352], Train Acc: 77.9754 Loss: 1.0168\n",
      "  Validation Accuracy after Epoch 6: 68.9200\n",
      "  Cidar10.1 Accuracy: 58.3\n",
      "  Epoch [7/68], Batch [350/352], Train Acc: 79.7768 Loss: 1.0208\n",
      "  Validation Accuracy after Epoch 7: 76.1600\n",
      "  Cidar10.1 Accuracy: 66.0\n",
      "  Epoch [8/68], Batch [350/352], Train Acc: 81.1897 Loss: 0.9652\n",
      "  Validation Accuracy after Epoch 8: 74.8600\n",
      "  Cidar10.1 Accuracy: 67.85\n",
      "  Epoch [9/68], Batch [350/352], Train Acc: 82.3058 Loss: 0.8630\n",
      "  Validation Accuracy after Epoch 9: 79.7000\n",
      "  Cidar10.1 Accuracy: 68.35\n",
      "  Epoch [10/68], Batch [350/352], Train Acc: 83.5625 Loss: 0.8894\n",
      "  Validation Accuracy after Epoch 10: 81.0800\n",
      "  Cidar10.1 Accuracy: 70.25\n",
      "  Epoch [11/68], Batch [350/352], Train Acc: 84.8103 Loss: 0.7835\n",
      "  Validation Accuracy after Epoch 11: 79.4600\n",
      "  Cidar10.1 Accuracy: 68.4\n",
      "  Epoch [12/68], Batch [350/352], Train Acc: 85.6116 Loss: 0.7674\n",
      "  Validation Accuracy after Epoch 12: 80.7200\n",
      "  Cidar10.1 Accuracy: 69.15\n",
      "  Epoch [13/68], Batch [350/352], Train Acc: 86.4196 Loss: 0.7710\n",
      "  Validation Accuracy after Epoch 13: 82.4600\n",
      "  Cidar10.1 Accuracy: 71.65\n",
      "  Epoch [14/68], Batch [350/352], Train Acc: 87.5915 Loss: 0.7886\n",
      "  Validation Accuracy after Epoch 14: 81.0800\n",
      "  Cidar10.1 Accuracy: 71.35\n",
      "  Epoch [15/68], Batch [350/352], Train Acc: 88.1138 Loss: 0.7599\n",
      "  Validation Accuracy after Epoch 15: 84.0400\n",
      "  Cidar10.1 Accuracy: 73.05\n",
      "  Epoch [16/68], Batch [350/352], Train Acc: 88.9420 Loss: 0.7929\n",
      "  Validation Accuracy after Epoch 16: 83.8800\n",
      "  Cidar10.1 Accuracy: 72.7\n",
      "  Epoch [17/68], Batch [350/352], Train Acc: 89.5647 Loss: 0.8303\n",
      "  Validation Accuracy after Epoch 17: 86.8800\n",
      "  Cidar10.1 Accuracy: 77.75\n",
      "  Epoch [18/68], Batch [350/352], Train Acc: 90.1183 Loss: 0.7806\n",
      "  Validation Accuracy after Epoch 18: 86.2800\n",
      "  Cidar10.1 Accuracy: 78.4\n",
      "  Epoch [19/68], Batch [350/352], Train Acc: 90.7411 Loss: 0.7668\n",
      "  Validation Accuracy after Epoch 19: 86.5000\n",
      "  Cidar10.1 Accuracy: 77.5\n",
      "  Epoch [20/68], Batch [350/352], Train Acc: 91.2946 Loss: 0.6442\n",
      "  Validation Accuracy after Epoch 20: 87.1600\n",
      "  Cidar10.1 Accuracy: 79.45\n",
      "  Epoch [21/68], Batch [350/352], Train Acc: 92.2723 Loss: 0.6599\n",
      "  Validation Accuracy after Epoch 21: 87.2600\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [22/68], Batch [350/352], Train Acc: 92.6228 Loss: 0.6794\n",
      "  Validation Accuracy after Epoch 22: 87.8000\n",
      "  Cidar10.1 Accuracy: 80.75\n",
      "  Epoch [23/68], Batch [350/352], Train Acc: 92.9018 Loss: 0.6875\n",
      "  Validation Accuracy after Epoch 23: 88.4200\n",
      "  Cidar10.1 Accuracy: 79.25\n",
      "  Epoch [24/68], Batch [350/352], Train Acc: 93.6473 Loss: 0.6407\n",
      "  Validation Accuracy after Epoch 24: 88.9000\n",
      "  Cidar10.1 Accuracy: 79.8\n",
      "  Epoch [25/68], Batch [350/352], Train Acc: 94.0446 Loss: 0.6248\n",
      "  Validation Accuracy after Epoch 25: 89.6800\n",
      "  Cidar10.1 Accuracy: 81.6\n",
      "  Epoch [26/68], Batch [350/352], Train Acc: 94.5022 Loss: 0.6219\n",
      "  Validation Accuracy after Epoch 26: 89.2800\n",
      "  Cidar10.1 Accuracy: 79.4\n",
      "  Epoch [27/68], Batch [350/352], Train Acc: 94.8996 Loss: 0.6528\n",
      "  Validation Accuracy after Epoch 27: 89.7400\n",
      "  Cidar10.1 Accuracy: 82.15\n",
      "  Epoch [28/68], Batch [350/352], Train Acc: 95.3862 Loss: 0.6386\n",
      "  Validation Accuracy after Epoch 28: 88.9800\n",
      "  Cidar10.1 Accuracy: 80.85\n",
      "  Epoch [29/68], Batch [350/352], Train Acc: 95.5424 Loss: 0.6396\n",
      "  Validation Accuracy after Epoch 29: 90.4600\n",
      "  Cidar10.1 Accuracy: 82.35\n",
      "  Epoch [30/68], Batch [350/352], Train Acc: 96.2344 Loss: 0.5603\n",
      "  Validation Accuracy after Epoch 30: 90.6400\n",
      "  Cidar10.1 Accuracy: 81.95\n",
      "  Epoch [31/68], Batch [350/352], Train Acc: 96.2366 Loss: 0.5886\n",
      "  Validation Accuracy after Epoch 31: 90.6400\n",
      "  Cidar10.1 Accuracy: 81.95\n",
      "  Epoch [32/68], Batch [350/352], Train Acc: 96.6875 Loss: 0.5932\n",
      "  Validation Accuracy after Epoch 32: 90.7600\n",
      "  Cidar10.1 Accuracy: 84.35\n",
      "  Epoch [33/68], Batch [350/352], Train Acc: 96.9888 Loss: 0.5915\n",
      "  Validation Accuracy after Epoch 33: 90.8800\n",
      "  Cidar10.1 Accuracy: 81.8\n",
      "  Epoch [34/68], Batch [350/352], Train Acc: 97.2277 Loss: 0.5887\n",
      "  Validation Accuracy after Epoch 34: 90.9800\n",
      "  Cidar10.1 Accuracy: 82.4\n",
      "  Epoch [35/68], Batch [350/352], Train Acc: 97.4487 Loss: 0.5800\n",
      "  Validation Accuracy after Epoch 35: 91.2400\n",
      "  Cidar10.1 Accuracy: 83.75\n",
      "  Epoch [36/68], Batch [350/352], Train Acc: 97.7277 Loss: 0.5602\n",
      "  Validation Accuracy after Epoch 36: 91.6000\n",
      "  Cidar10.1 Accuracy: 82.35\n",
      "  Epoch [37/68], Batch [350/352], Train Acc: 97.9152 Loss: 0.5632\n",
      "  Validation Accuracy after Epoch 37: 90.8200\n",
      "  Cidar10.1 Accuracy: 83.1\n",
      "  Epoch [38/68], Batch [350/352], Train Acc: 98.1116 Loss: 0.5667\n",
      "  Validation Accuracy after Epoch 38: 91.8800\n",
      "  Cidar10.1 Accuracy: 84.35\n",
      "  Epoch [39/68], Batch [350/352], Train Acc: 98.4487 Loss: 0.5617\n",
      "  Validation Accuracy after Epoch 39: 91.6800\n",
      "  Cidar10.1 Accuracy: 84.2\n",
      "  Epoch [40/68], Batch [350/352], Train Acc: 98.4688 Loss: 0.5709\n",
      "  Validation Accuracy after Epoch 40: 91.9200\n",
      "  Cidar10.1 Accuracy: 83.35\n",
      "  Epoch [41/68], Batch [350/352], Train Acc: 98.6808 Loss: 0.5285\n",
      "  Validation Accuracy after Epoch 41: 91.7600\n",
      "  Cidar10.1 Accuracy: 83.6\n",
      "  Epoch [42/68], Batch [350/352], Train Acc: 98.7857 Loss: 0.5432\n",
      "  Validation Accuracy after Epoch 42: 91.4600\n",
      "  Cidar10.1 Accuracy: 83.75\n",
      "  Epoch [43/68], Batch [350/352], Train Acc: 98.9933 Loss: 0.5627\n",
      "  Validation Accuracy after Epoch 43: 92.1600\n",
      "  Cidar10.1 Accuracy: 83.85\n",
      "  Epoch [44/68], Batch [350/352], Train Acc: 99.0201 Loss: 0.5443\n",
      "  Validation Accuracy after Epoch 44: 91.9200\n",
      "  Cidar10.1 Accuracy: 84.1\n",
      "  Epoch [45/68], Batch [350/352], Train Acc: 99.1875 Loss: 0.5431\n",
      "  Validation Accuracy after Epoch 45: 92.2000\n",
      "  Cidar10.1 Accuracy: 83.3\n",
      "  Epoch [46/68], Batch [350/352], Train Acc: 99.3772 Loss: 0.5287\n",
      "  Validation Accuracy after Epoch 46: 91.9000\n",
      "  Cidar10.1 Accuracy: 83.5\n",
      "  Epoch [47/68], Batch [350/352], Train Acc: 99.4152 Loss: 0.5366\n",
      "  Validation Accuracy after Epoch 47: 91.9200\n",
      "  Cidar10.1 Accuracy: 84.9\n",
      "  Epoch [48/68], Batch [350/352], Train Acc: 99.4129 Loss: 0.5422\n",
      "  Validation Accuracy after Epoch 48: 92.5400\n",
      "  Cidar10.1 Accuracy: 84.55\n",
      "  Epoch [49/68], Batch [350/352], Train Acc: 99.5000 Loss: 0.5351\n",
      "  Validation Accuracy after Epoch 49: 92.3600\n",
      "  Cidar10.1 Accuracy: 84.85\n",
      "  Epoch [50/68], Batch [350/352], Train Acc: 99.6049 Loss: 0.5244\n",
      "  Validation Accuracy after Epoch 50: 92.8800\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [51/68], Batch [350/352], Train Acc: 99.6562 Loss: 0.5316\n",
      "  Validation Accuracy after Epoch 51: 92.4600\n",
      "  Cidar10.1 Accuracy: 85.05\n",
      "  Epoch [52/68], Batch [350/352], Train Acc: 99.7254 Loss: 0.5168\n",
      "  Validation Accuracy after Epoch 52: 92.8200\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [53/68], Batch [350/352], Train Acc: 99.6964 Loss: 0.5268\n",
      "  Validation Accuracy after Epoch 53: 92.9800\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [54/68], Batch [350/352], Train Acc: 99.8237 Loss: 0.5181\n",
      "  Validation Accuracy after Epoch 54: 93.4600\n",
      "  Cidar10.1 Accuracy: 85.25\n",
      "  Epoch [55/68], Batch [350/352], Train Acc: 99.8683 Loss: 0.5127\n",
      "  Validation Accuracy after Epoch 55: 93.0800\n",
      "  Cidar10.1 Accuracy: 85.7\n",
      "  Epoch [56/68], Batch [350/352], Train Acc: 99.8705 Loss: 0.5181\n",
      "  Validation Accuracy after Epoch 56: 92.8400\n",
      "  Cidar10.1 Accuracy: 85.2\n",
      "  Epoch [57/68], Batch [350/352], Train Acc: 99.8393 Loss: 0.5196\n",
      "  Validation Accuracy after Epoch 57: 93.0200\n",
      "  Cidar10.1 Accuracy: 85.4\n",
      "  Epoch [58/68], Batch [350/352], Train Acc: 99.8683 Loss: 0.5144\n",
      "  Validation Accuracy after Epoch 58: 93.2000\n",
      "  Cidar10.1 Accuracy: 85.8\n",
      "  Epoch [59/68], Batch [350/352], Train Acc: 99.9107 Loss: 0.5086\n",
      "  Validation Accuracy after Epoch 59: 93.1200\n",
      "  Cidar10.1 Accuracy: 86.0\n",
      "  Epoch [60/68], Batch [350/352], Train Acc: 99.9129 Loss: 0.5161\n",
      "  Validation Accuracy after Epoch 60: 93.2200\n",
      "  Cidar10.1 Accuracy: 85.9\n",
      "  Epoch [61/68], Batch [350/352], Train Acc: 99.9129 Loss: 0.5114\n",
      "  Validation Accuracy after Epoch 61: 93.0200\n",
      "  Cidar10.1 Accuracy: 86.4\n",
      "  Epoch [62/68], Batch [350/352], Train Acc: 99.9353 Loss: 0.5116\n",
      "  Validation Accuracy after Epoch 62: 93.1800\n",
      "  Cidar10.1 Accuracy: 86.35\n",
      "  Epoch [63/68], Batch [350/352], Train Acc: 99.9621 Loss: 0.5092\n",
      "  Validation Accuracy after Epoch 63: 93.3400\n",
      "  Cidar10.1 Accuracy: 86.35\n",
      "  Epoch [64/68], Batch [350/352], Train Acc: 99.9509 Loss: 0.5107\n",
      "  Validation Accuracy after Epoch 64: 93.1000\n",
      "  Cidar10.1 Accuracy: 86.8\n",
      "  Epoch [65/68], Batch [350/352], Train Acc: 99.9464 Loss: 0.5143\n",
      "  Validation Accuracy after Epoch 65: 93.1000\n",
      "  Cidar10.1 Accuracy: 86.5\n",
      "  Epoch [66/68], Batch [350/352], Train Acc: 99.9442 Loss: 0.5089\n",
      "  Validation Accuracy after Epoch 66: 93.2200\n",
      "  Cidar10.1 Accuracy: 86.5\n",
      "  Epoch [67/68], Batch [350/352], Train Acc: 99.9487 Loss: 0.5082\n",
      "  Validation Accuracy after Epoch 67: 93.3000\n",
      "  Cidar10.1 Accuracy: 86.6\n",
      "  Epoch [68/68], Batch [350/352], Train Acc: 99.9487 Loss: 0.5080\n",
      "  Validation Accuracy after Epoch 68: 93.2600\n",
      "  Cidar10.1 Accuracy: 86.6\n",
      "Trial 53 complete. Best Validation Accuracy: 93.4600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 08:13:31,906] Trial 53 finished with value: 93.46 and parameters: {'num_epochs': 68, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8805357481275744, 'beta2': 0.9955924937929359, 'lr': 0.0012276282152372906, 'weight_decay': 0.001972683877992677, 'max_lr': 0.005663524668808249}. Best is trial 20 with value: 93.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=54\n",
      "num_epochs: 80\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.903403689050069\n",
      "beta2: 0.9944854353997653\n",
      "lr: 0.0006508055442592868\n",
      "weight_decay: 0.00133983275181981\n",
      "max_lr: 0.004827358361331066\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/80], Batch [350/352], Train Acc: 45.1116 Loss: 1.5649\n",
      "  Validation Accuracy after Epoch 1: 53.6600\n",
      "  Cidar10.1 Accuracy: 44.65\n",
      "  Epoch [2/80], Batch [350/352], Train Acc: 61.7656 Loss: 1.3281\n",
      "  Validation Accuracy after Epoch 2: 63.2600\n",
      "  Cidar10.1 Accuracy: 51.1\n",
      "  Epoch [3/80], Batch [350/352], Train Acc: 68.6920 Loss: 1.2910\n",
      "  Validation Accuracy after Epoch 3: 63.5200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 08:14:02,098] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=55\n",
      "num_epochs: 75\n",
      "model_type: smallresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8936407149473528\n",
      "beta2: 0.9966856937168362\n",
      "lr: 0.0003744134239293919\n",
      "weight_decay: 0.003928592864932334\n",
      "max_lr: 0.008498398639597823\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/75], Batch [350/352], Train Acc: 36.8460 Loss: 1.7281\n",
      "  Validation Accuracy after Epoch 1: 45.0800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 08:14:15,464] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=56\n",
      "num_epochs: 70\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: CosineAnnealingLR\n",
      "beta1: 0.8965602798454313\n",
      "beta2: 0.9926179784685416\n",
      "lr: 0.0011127033334149478\n",
      "weight_decay: 0.0026495466031555013\n",
      "eta_min: 0.0009446330554198705\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/70], Batch [350/352], Train Acc: 44.5290 Loss: 1.4570\n",
      "  Validation Accuracy after Epoch 1: 55.6200\n",
      "  Cidar10.1 Accuracy: 43.1\n",
      "  Epoch [2/70], Batch [350/352], Train Acc: 62.9464 Loss: 1.1584\n",
      "  Validation Accuracy after Epoch 2: 65.4200\n",
      "  Cidar10.1 Accuracy: 52.7\n",
      "  Epoch [3/70], Batch [350/352], Train Acc: 70.3750 Loss: 1.2020\n",
      "  Validation Accuracy after Epoch 3: 72.2000\n",
      "  Cidar10.1 Accuracy: 59.3\n",
      "  Epoch [4/70], Batch [350/352], Train Acc: 75.7545 Loss: 1.0654\n",
      "  Validation Accuracy after Epoch 4: 74.2200\n",
      "  Cidar10.1 Accuracy: 62.15\n",
      "  Epoch [5/70], Batch [350/352], Train Acc: 78.5089 Loss: 0.9742\n",
      "  Validation Accuracy after Epoch 5: 78.7800\n",
      "  Cidar10.1 Accuracy: 66.15\n",
      "  Epoch [6/70], Batch [350/352], Train Acc: 81.3103 Loss: 0.9706\n",
      "  Validation Accuracy after Epoch 6: 81.1000\n",
      "  Cidar10.1 Accuracy: 69.7\n",
      "  Epoch [7/70], Batch [350/352], Train Acc: 83.0179 Loss: 0.8813\n",
      "  Validation Accuracy after Epoch 7: 81.1000\n",
      "  Cidar10.1 Accuracy: 69.8\n",
      "  Epoch [8/70], Batch [350/352], Train Acc: 84.4911 Loss: 0.8352\n",
      "  Validation Accuracy after Epoch 8: 82.8800\n",
      "  Cidar10.1 Accuracy: 72.8\n",
      "  Epoch [9/70], Batch [350/352], Train Acc: 85.9174 Loss: 0.9000\n",
      "  Validation Accuracy after Epoch 9: 82.4000\n",
      "  Cidar10.1 Accuracy: 71.05\n",
      "  Epoch [10/70], Batch [350/352], Train Acc: 86.8527 Loss: 0.8002\n",
      "  Validation Accuracy after Epoch 10: 82.9000\n",
      "  Cidar10.1 Accuracy: 73.4\n",
      "  Epoch [11/70], Batch [350/352], Train Acc: 87.7634 Loss: 0.7931\n",
      "  Validation Accuracy after Epoch 11: 85.4800\n",
      "  Cidar10.1 Accuracy: 76.85\n",
      "  Epoch [12/70], Batch [350/352], Train Acc: 88.6920 Loss: 0.7996\n",
      "  Validation Accuracy after Epoch 12: 86.4400\n",
      "  Cidar10.1 Accuracy: 76.25\n",
      "  Epoch [13/70], Batch [350/352], Train Acc: 89.3951 Loss: 0.7930\n",
      "  Validation Accuracy after Epoch 13: 85.5800\n",
      "  Cidar10.1 Accuracy: 76.8\n",
      "  Epoch [14/70], Batch [350/352], Train Acc: 90.4375 Loss: 0.7100\n",
      "  Validation Accuracy after Epoch 14: 85.6600\n",
      "  Cidar10.1 Accuracy: 73.5\n",
      "  Epoch [15/70], Batch [350/352], Train Acc: 90.7679 Loss: 0.7512\n",
      "  Validation Accuracy after Epoch 15: 88.8200\n",
      "  Cidar10.1 Accuracy: 79.75\n",
      "  Epoch [16/70], Batch [350/352], Train Acc: 91.4353 Loss: 0.6739\n",
      "  Validation Accuracy after Epoch 16: 87.5800\n",
      "  Cidar10.1 Accuracy: 77.3\n",
      "  Epoch [17/70], Batch [350/352], Train Acc: 92.0670 Loss: 0.6390\n",
      "  Validation Accuracy after Epoch 17: 88.6000\n",
      "  Cidar10.1 Accuracy: 79.75\n",
      "  Epoch [18/70], Batch [350/352], Train Acc: 92.5625 Loss: 0.6431\n",
      "  Validation Accuracy after Epoch 18: 87.7600\n",
      "  Cidar10.1 Accuracy: 79.1\n",
      "  Epoch [19/70], Batch [350/352], Train Acc: 93.0290 Loss: 0.6931\n",
      "  Validation Accuracy after Epoch 19: 88.4400\n",
      "  Cidar10.1 Accuracy: 78.85\n",
      "  Epoch [20/70], Batch [350/352], Train Acc: 93.3281 Loss: 0.6665\n",
      "  Validation Accuracy after Epoch 20: 88.4800\n",
      "  Cidar10.1 Accuracy: 80.75\n",
      "  Epoch [21/70], Batch [350/352], Train Acc: 93.8862 Loss: 0.6134\n",
      "  Validation Accuracy after Epoch 21: 89.2600\n",
      "  Cidar10.1 Accuracy: 80.1\n",
      "  Epoch [22/70], Batch [350/352], Train Acc: 94.3013 Loss: 0.6658\n",
      "  Validation Accuracy after Epoch 22: 88.6800\n",
      "  Cidar10.1 Accuracy: 79.4\n",
      "  Epoch [23/70], Batch [350/352], Train Acc: 94.6339 Loss: 0.6115\n",
      "  Validation Accuracy after Epoch 23: 88.6800\n",
      "  Cidar10.1 Accuracy: 79.0\n",
      "  Epoch [24/70], Batch [350/352], Train Acc: 94.8906 Loss: 0.6429\n",
      "  Validation Accuracy after Epoch 24: 88.7600\n",
      "  Cidar10.1 Accuracy: 78.3\n",
      "  Epoch [25/70], Batch [350/352], Train Acc: 95.3772 Loss: 0.6648\n",
      "  Validation Accuracy after Epoch 25: 88.8400\n",
      "  Cidar10.1 Accuracy: 80.05\n",
      "  Epoch [26/70], Batch [350/352], Train Acc: 95.3661 Loss: 0.6131\n",
      "  Validation Accuracy after Epoch 26: 88.4200\n",
      "  Cidar10.1 Accuracy: 80.25\n",
      "  Epoch [27/70], Batch [350/352], Train Acc: 95.9330 Loss: 0.6639\n",
      "  Validation Accuracy after Epoch 27: 89.2200\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [28/70], Batch [350/352], Train Acc: 96.1562 Loss: 0.6337\n",
      "  Validation Accuracy after Epoch 28: 90.0800\n",
      "  Cidar10.1 Accuracy: 82.1\n",
      "  Epoch [29/70], Batch [350/352], Train Acc: 96.3013 Loss: 0.6461\n",
      "  Validation Accuracy after Epoch 29: 89.3600\n",
      "  Cidar10.1 Accuracy: 82.3\n",
      "  Epoch [30/70], Batch [350/352], Train Acc: 96.6362 Loss: 0.5971\n",
      "  Validation Accuracy after Epoch 30: 90.0000\n",
      "  Cidar10.1 Accuracy: 81.05\n",
      "  Epoch [31/70], Batch [190/352], Train Acc: 96.7722 Loss: 0.6093"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=\"sqlite:///study.db\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume study\n",
    "Helps run more studies since we only have 4 hour time limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:04:13,481] Using an existing study with name 'study_2025-03-12_02-29-51' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=98\n",
      "num_epochs: 72\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8797085934596846\n",
      "beta2: 0.9949971606374951\n",
      "lr: 0.0004585314299323415\n",
      "weight_decay: 0.0014826433974480398\n",
      "max_lr: 0.007995567499122606\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/72], Batch [350/352], Train Acc: 45.5223 Loss: 1.5296\n",
      "  Validation Accuracy after Epoch 1: 54.1200\n",
      "  Cidar10.1 Accuracy: 45.0\n",
      "  Epoch [2/72], Batch [350/352], Train Acc: 63.0960 Loss: 1.4150\n",
      "  Validation Accuracy after Epoch 2: 62.1200\n",
      "  Cidar10.1 Accuracy: 47.45\n",
      "  Epoch [3/72], Batch [350/352], Train Acc: 70.1987 Loss: 1.0942\n",
      "  Validation Accuracy after Epoch 3: 68.2400\n",
      "  Cidar10.1 Accuracy: 52.65\n",
      "  Epoch [4/72], Batch [350/352], Train Acc: 74.2098 Loss: 1.1175\n",
      "  Validation Accuracy after Epoch 4: 70.5200\n",
      "  Cidar10.1 Accuracy: 57.95\n",
      "  Epoch [5/72], Batch [350/352], Train Acc: 76.7701 Loss: 1.0115\n",
      "  Validation Accuracy after Epoch 5: 69.2200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:05:05,184] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=99\n",
      "num_epochs: 122\n",
      "model_type: largeresnet\n",
      "batch_size: 256\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9356739822937291\n",
      "beta2: 0.9965169612969706\n",
      "lr: 0.0009038583428644764\n",
      "weight_decay: 0.002498746736724739\n",
      "max_lr: 0.009283908511003962\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/122], Batch [170/176], Train Acc: 43.5179 Loss: 1.5090\n",
      "  Validation Accuracy after Epoch 1: 52.4200\n",
      "  Cidar10.1 Accuracy: 40.5\n",
      "  Epoch [2/122], Batch [170/176], Train Acc: 60.9122 Loss: 1.2876\n",
      "  Validation Accuracy after Epoch 2: 60.6000\n",
      "  Cidar10.1 Accuracy: 47.85\n",
      "  Epoch [3/122], Batch [170/176], Train Acc: 68.2100 Loss: 1.0749\n",
      "  Validation Accuracy after Epoch 3: 69.4600\n",
      "  Cidar10.1 Accuracy: 56.6\n",
      "  Epoch [4/122], Batch [170/176], Train Acc: 72.9710 Loss: 1.0929\n",
      "  Validation Accuracy after Epoch 4: 71.5600\n",
      "  Cidar10.1 Accuracy: 58.55\n",
      "  Epoch [5/122], Batch [170/176], Train Acc: 76.2960 Loss: 1.1047\n",
      "  Validation Accuracy after Epoch 5: 71.4800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:05:51,497] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=100\n",
      "num_epochs: 97\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9054578308096426\n",
      "beta2: 0.9928351988376284\n",
      "lr: 0.00039836359566732514\n",
      "weight_decay: 0.002020023957157541\n",
      "max_lr: 0.005111543238136063\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/97], Batch [350/352], Train Acc: 44.9397 Loss: 1.5705\n",
      "  Validation Accuracy after Epoch 1: 53.4800\n",
      "  Cidar10.1 Accuracy: 44.45\n",
      "  Epoch [2/97], Batch [350/352], Train Acc: 62.2388 Loss: 1.3454\n",
      "  Validation Accuracy after Epoch 2: 62.5400\n",
      "  Cidar10.1 Accuracy: 47.75\n",
      "  Epoch [3/97], Batch [350/352], Train Acc: 69.3594 Loss: 1.2327\n",
      "  Validation Accuracy after Epoch 3: 70.8400\n",
      "  Cidar10.1 Accuracy: 58.25\n",
      "  Epoch [4/97], Batch [350/352], Train Acc: 73.8371 Loss: 0.9862\n",
      "  Validation Accuracy after Epoch 4: 64.9400\n",
      "  Cidar10.1 Accuracy: 53.2\n",
      "  Epoch [5/97], Batch [350/352], Train Acc: 75.9487 Loss: 1.0480\n",
      "  Validation Accuracy after Epoch 5: 73.0800\n",
      "  Cidar10.1 Accuracy: 59.85\n",
      "  Epoch [6/97], Batch [350/352], Train Acc: 78.0022 Loss: 0.9715\n",
      "  Validation Accuracy after Epoch 6: 68.6200\n",
      "  Cidar10.1 Accuracy: 54.55\n",
      "  Epoch [7/97], Batch [350/352], Train Acc: 79.6339 Loss: 0.9673\n",
      "  Validation Accuracy after Epoch 7: 75.2600\n",
      "  Cidar10.1 Accuracy: 61.15\n",
      "  Epoch [8/97], Batch [350/352], Train Acc: 80.8214 Loss: 0.9944\n",
      "  Validation Accuracy after Epoch 8: 77.8000\n",
      "  Cidar10.1 Accuracy: 67.7\n",
      "  Epoch [9/97], Batch [350/352], Train Acc: 81.9531 Loss: 0.9399\n",
      "  Validation Accuracy after Epoch 9: 67.1000\n",
      "  Cidar10.1 Accuracy: 50.25\n",
      "  Epoch [10/97], Batch [350/352], Train Acc: 83.1116 Loss: 0.8804\n",
      "  Validation Accuracy after Epoch 10: 76.3800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:07:24,955] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=101\n",
      "num_epochs: 76\n",
      "model_type: smallresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8918593244155517\n",
      "beta2: 0.9944024312986199\n",
      "lr: 0.0007119518884413643\n",
      "weight_decay: 0.002912324293743115\n",
      "max_lr: 0.003537885816041659\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/76], Batch [350/352], Train Acc: 32.8504 Loss: 1.8230\n",
      "  Validation Accuracy after Epoch 1: 42.5200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:07:38,232] Trial 101 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=102\n",
      "num_epochs: 58\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8983088740571669\n",
      "beta2: 0.9935912919091471\n",
      "lr: 0.0001480248733571373\n",
      "weight_decay: 0.002144226779334068\n",
      "max_lr: 0.009264621780957272\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/58], Batch [80/88], Train Acc: 36.2451 Loss: 1.6828\n",
      "  Validation Accuracy after Epoch 1: 44.4400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:07:49,131] Trial 102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=103\n",
      "num_epochs: 54\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9084553535104866\n",
      "beta2: 0.9932877699895527\n",
      "lr: 1.1717074401882927e-05\n",
      "weight_decay: 0.00676551637520512\n",
      "max_lr: 0.009987731930500862\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/54], Batch [80/88], Train Acc: 36.5186 Loss: 1.6868\n",
      "  Validation Accuracy after Epoch 1: 42.5200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:07:59,824] Trial 103 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=104\n",
      "num_epochs: 56\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9124646207127496\n",
      "beta2: 0.9921437608581041\n",
      "lr: 0.00011898030805969763\n",
      "weight_decay: 0.008481889158182696\n",
      "max_lr: 0.0061521201369953\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/56], Batch [80/88], Train Acc: 35.0806 Loss: 1.7035\n",
      "  Validation Accuracy after Epoch 1: 44.5600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:08:10,743] Trial 104 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=105\n",
      "num_epochs: 60\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9025263265570616\n",
      "beta2: 0.9953365586550577\n",
      "lr: 8.855991039224038e-05\n",
      "weight_decay: 0.0044659714296329915\n",
      "max_lr: 0.00980716033445798\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/60], Batch [80/88], Train Acc: 36.3330 Loss: 1.6863\n",
      "  Validation Accuracy after Epoch 1: 44.5000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:08:21,563] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=106\n",
      "num_epochs: 74\n",
      "model_type: largeresnet\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8879282347377033\n",
      "beta2: 0.9924882304230533\n",
      "lr: 0.0010471332932495206\n",
      "weight_decay: 0.0036487773053808137\n",
      "max_lr: 0.008466196862411854\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/74], Batch [80/88], Train Acc: 40.8325 Loss: 1.6142\n",
      "  Validation Accuracy after Epoch 1: 48.2200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:08:32,319] Trial 106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=107\n",
      "num_epochs: 62\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: Adam\n",
      "scheduler_type: ReduceLROnPlateau\n",
      "beta1: 0.8748728773927489\n",
      "beta2: 0.9947434024815887\n",
      "lr: 4.264504258358601e-05\n",
      "weight_decay: 0.0008373199051726582\n",
      "factor: 0.3560793810460522\n",
      "patience: 16\n",
      "threshold: 0.05161227131799969\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/62], Batch [350/352], Train Acc: 38.9978 Loss: 1.6984\n",
      "  Validation Accuracy after Epoch 1: 47.4400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:08:43,233] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=108\n",
      "num_epochs: 67\n",
      "model_type: base\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9172077528010634\n",
      "beta2: 0.9976842212947235\n",
      "lr: 0.0020705947007980657\n",
      "weight_decay: 0.0016383963794087523\n",
      "max_lr: 0.0041080471185484125\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/67], Batch [350/352], Train Acc: 38.8482 Loss: 1.6959\n",
      "  Validation Accuracy after Epoch 1: 48.0600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:08:53,918] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=109\n",
      "num_epochs: 88\n",
      "model_type: efficientnet\n",
      "batch_size: 64\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "lr: 0.0012196273260883152\n",
      "momentum: 0.841851006744877\n",
      "weight_decay: 0.0004675516902296319\n",
      "max_lr: 0.022229194832149635\n",
      "trainable_parameters: 3599686\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/88], Batch [700/704], Train Acc: 27.7567 Loss: 1.6920\n",
      "  Validation Accuracy after Epoch 1: 38.2400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:09:24,921] Trial 109 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=110\n",
      "num_epochs: 52\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.894764889043421\n",
      "beta2: 0.9912308584069558\n",
      "lr: 0.0006205569699526801\n",
      "weight_decay: 0.010380439919807818\n",
      "max_lr: 0.004554572280395164\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/52], Batch [350/352], Train Acc: 44.7567 Loss: 1.5697\n",
      "  Validation Accuracy after Epoch 1: 52.8400\n",
      "  Cidar10.1 Accuracy: 43.35\n",
      "  Epoch [2/52], Batch [350/352], Train Acc: 61.3237 Loss: 1.3875\n",
      "  Validation Accuracy after Epoch 2: 59.2600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:09:45,084] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=111\n",
      "num_epochs: 71\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: CosineAnnealingLR\n",
      "beta1: 0.9219296936193148\n",
      "beta2: 0.9958910529184268\n",
      "lr: 0.0007810414334461005\n",
      "weight_decay: 0.002699577040237585\n",
      "eta_min: 0.00025590242923997366\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/71], Batch [350/352], Train Acc: 44.0045 Loss: 1.4632\n",
      "  Validation Accuracy after Epoch 1: 57.3800\n",
      "  Cidar10.1 Accuracy: 45.05\n",
      "  Epoch [2/71], Batch [350/352], Train Acc: 62.4911 Loss: 1.3459\n",
      "  Validation Accuracy after Epoch 2: 61.2800\n",
      "  Cidar10.1 Accuracy: 49.25\n",
      "  Epoch [3/71], Batch [350/352], Train Acc: 69.8638 Loss: 1.0482\n",
      "  Validation Accuracy after Epoch 3: 73.4000\n",
      "  Cidar10.1 Accuracy: 60.0\n",
      "  Epoch [4/71], Batch [350/352], Train Acc: 75.2455 Loss: 1.0049\n",
      "  Validation Accuracy after Epoch 4: 72.1800\n",
      "  Cidar10.1 Accuracy: 59.7\n",
      "  Epoch [5/71], Batch [350/352], Train Acc: 78.2455 Loss: 1.0444\n",
      "  Validation Accuracy after Epoch 5: 78.0800\n",
      "  Cidar10.1 Accuracy: 67.55\n",
      "  Epoch [6/71], Batch [350/352], Train Acc: 80.3929 Loss: 0.9220\n",
      "  Validation Accuracy after Epoch 6: 77.2400\n",
      "  Cidar10.1 Accuracy: 65.3\n",
      "  Epoch [7/71], Batch [350/352], Train Acc: 81.8594 Loss: 1.0024\n",
      "  Validation Accuracy after Epoch 7: 81.5800\n",
      "  Cidar10.1 Accuracy: 69.65\n",
      "  Epoch [8/71], Batch [350/352], Train Acc: 83.6183 Loss: 0.8664\n",
      "  Validation Accuracy after Epoch 8: 80.9400\n",
      "  Cidar10.1 Accuracy: 66.85\n",
      "  Epoch [9/71], Batch [350/352], Train Acc: 84.4174 Loss: 0.8502\n",
      "  Validation Accuracy after Epoch 9: 80.6200\n",
      "  Cidar10.1 Accuracy: 69.9\n",
      "  Epoch [10/71], Batch [350/352], Train Acc: 85.7879 Loss: 0.7971\n",
      "  Validation Accuracy after Epoch 10: 84.0000\n",
      "  Cidar10.1 Accuracy: 73.05\n",
      "  Epoch [11/71], Batch [350/352], Train Acc: 86.3371 Loss: 0.8940\n",
      "  Validation Accuracy after Epoch 11: 84.4000\n",
      "  Cidar10.1 Accuracy: 74.65\n",
      "  Epoch [12/71], Batch [350/352], Train Acc: 87.5469 Loss: 0.8495\n",
      "  Validation Accuracy after Epoch 12: 86.5000\n",
      "  Cidar10.1 Accuracy: 74.75\n",
      "  Epoch [13/71], Batch [350/352], Train Acc: 88.0469 Loss: 0.8232\n",
      "  Validation Accuracy after Epoch 13: 82.8200\n",
      "  Cidar10.1 Accuracy: 72.15\n",
      "  Epoch [14/71], Batch [350/352], Train Acc: 88.9420 Loss: 0.7559\n",
      "  Validation Accuracy after Epoch 14: 87.4200\n",
      "  Cidar10.1 Accuracy: 77.55\n",
      "  Epoch [15/71], Batch [350/352], Train Acc: 89.6384 Loss: 0.8141\n",
      "  Validation Accuracy after Epoch 15: 86.1600\n",
      "  Cidar10.1 Accuracy: 75.9\n",
      "  Epoch [16/71], Batch [350/352], Train Acc: 90.3460 Loss: 0.6936\n",
      "  Validation Accuracy after Epoch 16: 88.2600\n",
      "  Cidar10.1 Accuracy: 78.5\n",
      "  Epoch [17/71], Batch [350/352], Train Acc: 90.4174 Loss: 0.8017\n",
      "  Validation Accuracy after Epoch 17: 84.4600\n",
      "  Cidar10.1 Accuracy: 71.8\n",
      "  Epoch [18/71], Batch [350/352], Train Acc: 91.3549 Loss: 0.7150\n",
      "  Validation Accuracy after Epoch 18: 88.7000\n",
      "  Cidar10.1 Accuracy: 79.6\n",
      "  Epoch [19/71], Batch [350/352], Train Acc: 91.6607 Loss: 0.7356\n",
      "  Validation Accuracy after Epoch 19: 85.8000\n",
      "  Cidar10.1 Accuracy: 75.8\n",
      "  Epoch [20/71], Batch [350/352], Train Acc: 92.0871 Loss: 0.7256\n",
      "  Validation Accuracy after Epoch 20: 88.0400\n",
      "  Cidar10.1 Accuracy: 79.5\n",
      "  Epoch [21/71], Batch [350/352], Train Acc: 92.5290 Loss: 0.6968\n",
      "  Validation Accuracy after Epoch 21: 86.3200\n",
      "  Cidar10.1 Accuracy: 77.05\n",
      "  Epoch [22/71], Batch [350/352], Train Acc: 92.7366 Loss: 0.6123\n",
      "  Validation Accuracy after Epoch 22: 89.5000\n",
      "  Cidar10.1 Accuracy: 81.3\n",
      "  Epoch [23/71], Batch [350/352], Train Acc: 93.2857 Loss: 0.7364\n",
      "  Validation Accuracy after Epoch 23: 87.7200\n",
      "  Cidar10.1 Accuracy: 77.95\n",
      "  Epoch [24/71], Batch [350/352], Train Acc: 93.5089 Loss: 0.7532\n",
      "  Validation Accuracy after Epoch 24: 88.9400\n",
      "  Cidar10.1 Accuracy: 80.5\n",
      "  Epoch [25/71], Batch [350/352], Train Acc: 94.0379 Loss: 0.6682\n",
      "  Validation Accuracy after Epoch 25: 88.8000\n",
      "  Cidar10.1 Accuracy: 80.1\n",
      "  Epoch [26/71], Batch [350/352], Train Acc: 94.2500 Loss: 0.6332\n",
      "  Validation Accuracy after Epoch 26: 89.3600\n",
      "  Cidar10.1 Accuracy: 80.6\n",
      "  Epoch [27/71], Batch [350/352], Train Acc: 94.5156 Loss: 0.6953\n",
      "  Validation Accuracy after Epoch 27: 89.5000\n",
      "  Cidar10.1 Accuracy: 78.95\n",
      "  Epoch [28/71], Batch [350/352], Train Acc: 94.7879 Loss: 0.6547\n",
      "  Validation Accuracy after Epoch 28: 89.2000\n",
      "  Cidar10.1 Accuracy: 81.5\n",
      "  Epoch [29/71], Batch [350/352], Train Acc: 95.1786 Loss: 0.6362\n",
      "  Validation Accuracy after Epoch 29: 89.0000\n",
      "  Cidar10.1 Accuracy: 80.55\n",
      "  Epoch [30/71], Batch [350/352], Train Acc: 95.2321 Loss: 0.6408\n",
      "  Validation Accuracy after Epoch 30: 90.0000\n",
      "  Cidar10.1 Accuracy: 81.75\n",
      "  Epoch [31/71], Batch [350/352], Train Acc: 95.8795 Loss: 0.6638\n",
      "  Validation Accuracy after Epoch 31: 90.0800\n",
      "  Cidar10.1 Accuracy: 81.1\n",
      "  Epoch [32/71], Batch [350/352], Train Acc: 95.7210 Loss: 0.6410\n",
      "  Validation Accuracy after Epoch 32: 89.7800\n",
      "  Cidar10.1 Accuracy: 79.8\n",
      "  Epoch [33/71], Batch [350/352], Train Acc: 96.0960 Loss: 0.6107\n",
      "  Validation Accuracy after Epoch 33: 90.1600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:14:52,104] Trial 111 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=112\n",
      "num_epochs: 63\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9261927258194593\n",
      "beta2: 0.995586028892556\n",
      "lr: 0.00018659042034161868\n",
      "weight_decay: 0.00401967742922052\n",
      "max_lr: 0.007067838477091528\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/63], Batch [80/88], Train Acc: 35.4761 Loss: 1.7060\n",
      "  Validation Accuracy after Epoch 1: 46.0600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:15:03,458] Trial 112 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=113\n",
      "num_epochs: 73\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9333367137503523\n",
      "beta2: 0.9937453061933577\n",
      "lr: 0.0002505885135661564\n",
      "weight_decay: 0.0053155588087843535\n",
      "max_lr: 0.007813890183324118\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/73], Batch [80/88], Train Acc: 36.0522 Loss: 1.6936\n",
      "  Validation Accuracy after Epoch 1: 46.4200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:15:14,214] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=114\n",
      "num_epochs: 50\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9281776992951007\n",
      "beta2: 0.9950517011364965\n",
      "lr: 0.00029937858921139787\n",
      "weight_decay: 0.003318797420316735\n",
      "max_lr: 0.006582491994335012\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/50], Batch [80/88], Train Acc: 35.2686 Loss: 1.6987\n",
      "  Validation Accuracy after Epoch 1: 46.5600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:15:24,814] Trial 114 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=115\n",
      "num_epochs: 69\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8816564919608195\n",
      "beta2: 0.9941393895855996\n",
      "lr: 0.001488581403996354\n",
      "weight_decay: 0.001827951035585541\n",
      "max_lr: 0.0053472603373523045\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/69], Batch [80/88], Train Acc: 34.4092 Loss: 1.7223\n",
      "  Validation Accuracy after Epoch 1: 44.9000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:15:35,730] Trial 115 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=116\n",
      "num_epochs: 80\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8901217548120502\n",
      "beta2: 0.9929318441137307\n",
      "lr: 0.0007035074009781589\n",
      "weight_decay: 0.0022201852674045607\n",
      "max_lr: 0.008805814542417086\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/80], Batch [350/352], Train Acc: 45.6451 Loss: 1.4993\n",
      "  Validation Accuracy after Epoch 1: 53.7800\n",
      "  Cidar10.1 Accuracy: 44.3\n",
      "  Epoch [2/80], Batch [350/352], Train Acc: 63.1763 Loss: 1.1626\n",
      "  Validation Accuracy after Epoch 2: 64.3000\n",
      "  Cidar10.1 Accuracy: 51.4\n",
      "  Epoch [3/80], Batch [350/352], Train Acc: 70.6585 Loss: 1.1948\n",
      "  Validation Accuracy after Epoch 3: 68.1800\n",
      "  Cidar10.1 Accuracy: 54.1\n",
      "  Epoch [4/80], Batch [350/352], Train Acc: 74.6786 Loss: 1.0813\n",
      "  Validation Accuracy after Epoch 4: 73.6800\n",
      "  Cidar10.1 Accuracy: 61.0\n",
      "  Epoch [5/80], Batch [350/352], Train Acc: 76.6741 Loss: 1.0300\n",
      "  Validation Accuracy after Epoch 5: 73.1000\n",
      "  Cidar10.1 Accuracy: 58.95\n",
      "  Epoch [6/80], Batch [350/352], Train Acc: 78.5647 Loss: 1.0783\n",
      "  Validation Accuracy after Epoch 6: 74.9400\n",
      "  Cidar10.1 Accuracy: 64.7\n",
      "  Epoch [7/80], Batch [350/352], Train Acc: 80.2589 Loss: 1.0298\n",
      "  Validation Accuracy after Epoch 7: 75.4600\n",
      "  Cidar10.1 Accuracy: 61.95\n",
      "  Epoch [8/80], Batch [350/352], Train Acc: 81.7478 Loss: 0.8635\n",
      "  Validation Accuracy after Epoch 8: 80.1400\n",
      "  Cidar10.1 Accuracy: 66.1\n",
      "  Epoch [9/80], Batch [350/352], Train Acc: 83.0513 Loss: 0.9450\n",
      "  Validation Accuracy after Epoch 9: 74.9200\n",
      "  Cidar10.1 Accuracy: 62.6\n",
      "  Epoch [10/80], Batch [350/352], Train Acc: 83.6004 Loss: 0.9918\n",
      "  Validation Accuracy after Epoch 10: 79.3200\n",
      "  Cidar10.1 Accuracy: 64.65\n",
      "  Epoch [11/80], Batch [350/352], Train Acc: 85.0469 Loss: 0.8474\n",
      "  Validation Accuracy after Epoch 11: 81.7000\n",
      "  Cidar10.1 Accuracy: 73.4\n",
      "  Epoch [12/80], Batch [350/352], Train Acc: 85.6719 Loss: 0.8714\n",
      "  Validation Accuracy after Epoch 12: 85.0200\n",
      "  Cidar10.1 Accuracy: 74.65\n",
      "  Epoch [13/80], Batch [350/352], Train Acc: 86.8393 Loss: 0.8365\n",
      "  Validation Accuracy after Epoch 13: 83.2800\n",
      "  Cidar10.1 Accuracy: 73.2\n",
      "  Epoch [14/80], Batch [350/352], Train Acc: 87.4487 Loss: 0.7626\n",
      "  Validation Accuracy after Epoch 14: 82.7800\n",
      "  Cidar10.1 Accuracy: 74.7\n",
      "  Epoch [15/80], Batch [350/352], Train Acc: 87.9888 Loss: 0.9246\n",
      "  Validation Accuracy after Epoch 15: 84.0600\n",
      "  Cidar10.1 Accuracy: 74.8\n",
      "  Epoch [16/80], Batch [350/352], Train Acc: 88.6562 Loss: 0.8209\n",
      "  Validation Accuracy after Epoch 16: 84.7800\n",
      "  Cidar10.1 Accuracy: 73.65\n",
      "  Epoch [17/80], Batch [350/352], Train Acc: 89.4911 Loss: 0.7446\n",
      "  Validation Accuracy after Epoch 17: 84.9600\n",
      "  Cidar10.1 Accuracy: 75.8\n",
      "  Epoch [18/80], Batch [350/352], Train Acc: 89.9955 Loss: 0.7418\n",
      "  Validation Accuracy after Epoch 18: 85.7600\n",
      "  Cidar10.1 Accuracy: 74.15\n",
      "  Epoch [19/80], Batch [350/352], Train Acc: 90.5089 Loss: 0.7299\n",
      "  Validation Accuracy after Epoch 19: 86.9600\n",
      "  Cidar10.1 Accuracy: 78.25\n",
      "  Epoch [20/80], Batch [350/352], Train Acc: 90.9040 Loss: 0.7135\n",
      "  Validation Accuracy after Epoch 20: 87.5000\n",
      "  Cidar10.1 Accuracy: 78.5\n",
      "  Epoch [21/80], Batch [350/352], Train Acc: 91.4152 Loss: 0.7278\n",
      "  Validation Accuracy after Epoch 21: 86.9800\n",
      "  Cidar10.1 Accuracy: 77.55\n",
      "  Epoch [22/80], Batch [350/352], Train Acc: 91.7254 Loss: 0.7621\n",
      "  Validation Accuracy after Epoch 22: 87.9000\n",
      "  Cidar10.1 Accuracy: 79.15\n",
      "  Epoch [23/80], Batch [350/352], Train Acc: 92.1071 Loss: 0.7173\n",
      "  Validation Accuracy after Epoch 23: 88.5000\n",
      "  Cidar10.1 Accuracy: 79.85\n",
      "  Epoch [24/80], Batch [350/352], Train Acc: 92.8036 Loss: 0.6862\n",
      "  Validation Accuracy after Epoch 24: 88.6800\n",
      "  Cidar10.1 Accuracy: 79.6\n",
      "  Epoch [25/80], Batch [350/352], Train Acc: 93.4196 Loss: 0.6642\n",
      "  Validation Accuracy after Epoch 25: 88.5000\n",
      "  Cidar10.1 Accuracy: 78.55\n",
      "  Epoch [26/80], Batch [350/352], Train Acc: 93.6853 Loss: 0.7248\n",
      "  Validation Accuracy after Epoch 26: 87.7800\n",
      "  Cidar10.1 Accuracy: 78.6\n",
      "  Epoch [27/80], Batch [350/352], Train Acc: 94.0804 Loss: 0.6706\n",
      "  Validation Accuracy after Epoch 27: 88.4800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:19:45,807] Trial 116 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=117\n",
      "num_epochs: 78\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9376129182505581\n",
      "beta2: 0.9952771388873903\n",
      "lr: 0.00042859287357707634\n",
      "weight_decay: 0.0013625885487977437\n",
      "max_lr: 0.004859676126701241\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/78], Batch [350/352], Train Acc: 45.0112 Loss: 1.5606\n",
      "  Validation Accuracy after Epoch 1: 54.4600\n",
      "  Cidar10.1 Accuracy: 44.05\n",
      "  Epoch [2/78], Batch [350/352], Train Acc: 61.4040 Loss: 1.2901\n",
      "  Validation Accuracy after Epoch 2: 65.9600\n",
      "  Cidar10.1 Accuracy: 53.6\n",
      "  Epoch [3/78], Batch [350/352], Train Acc: 68.7433 Loss: 1.0609\n",
      "  Validation Accuracy after Epoch 3: 69.5800\n",
      "  Cidar10.1 Accuracy: 57.35\n",
      "  Epoch [4/78], Batch [350/352], Train Acc: 73.2433 Loss: 1.0600\n",
      "  Validation Accuracy after Epoch 4: 67.9200\n",
      "  Cidar10.1 Accuracy: 55.8\n",
      "  Epoch [5/78], Batch [350/352], Train Acc: 75.8326 Loss: 1.0238\n",
      "  Validation Accuracy after Epoch 5: 72.7000\n",
      "  Cidar10.1 Accuracy: 57.15\n",
      "  Epoch [6/78], Batch [350/352], Train Acc: 77.6272 Loss: 1.0614\n",
      "  Validation Accuracy after Epoch 6: 74.3400\n",
      "  Cidar10.1 Accuracy: 63.6\n",
      "  Epoch [7/78], Batch [350/352], Train Acc: 79.3237 Loss: 1.0384\n",
      "  Validation Accuracy after Epoch 7: 75.9000\n",
      "  Cidar10.1 Accuracy: 63.05\n",
      "  Epoch [8/78], Batch [350/352], Train Acc: 80.7790 Loss: 1.0229\n",
      "  Validation Accuracy after Epoch 8: 81.0600\n",
      "  Cidar10.1 Accuracy: 68.7\n",
      "  Epoch [9/78], Batch [350/352], Train Acc: 82.0960 Loss: 0.9858\n",
      "  Validation Accuracy after Epoch 9: 77.3000\n",
      "  Cidar10.1 Accuracy: 63.4\n",
      "  Epoch [10/78], Batch [350/352], Train Acc: 83.1518 Loss: 0.9574\n",
      "  Validation Accuracy after Epoch 10: 80.9600\n",
      "  Cidar10.1 Accuracy: 69.35\n",
      "  Epoch [11/78], Batch [350/352], Train Acc: 84.4219 Loss: 0.8013\n",
      "  Validation Accuracy after Epoch 11: 79.8000\n",
      "  Cidar10.1 Accuracy: 69.05\n",
      "  Epoch [12/78], Batch [350/352], Train Acc: 85.2210 Loss: 0.9715\n",
      "  Validation Accuracy after Epoch 12: 82.4400\n",
      "  Cidar10.1 Accuracy: 70.65\n",
      "  Epoch [13/78], Batch [350/352], Train Acc: 85.9129 Loss: 0.7762\n",
      "  Validation Accuracy after Epoch 13: 82.0000\n",
      "  Cidar10.1 Accuracy: 72.85\n",
      "  Epoch [14/78], Batch [350/352], Train Acc: 87.0246 Loss: 0.7434\n",
      "  Validation Accuracy after Epoch 14: 82.6800\n",
      "  Cidar10.1 Accuracy: 72.55\n",
      "  Epoch [15/78], Batch [350/352], Train Acc: 87.6629 Loss: 0.7812\n",
      "  Validation Accuracy after Epoch 15: 85.1600\n",
      "  Cidar10.1 Accuracy: 73.5\n",
      "  Epoch [16/78], Batch [350/352], Train Acc: 88.5067 Loss: 0.7585\n",
      "  Validation Accuracy after Epoch 16: 84.1400\n",
      "  Cidar10.1 Accuracy: 74.7\n",
      "  Epoch [17/78], Batch [350/352], Train Acc: 89.0246 Loss: 0.9250\n",
      "  Validation Accuracy after Epoch 17: 85.9400\n",
      "  Cidar10.1 Accuracy: 76.95\n",
      "  Epoch [18/78], Batch [350/352], Train Acc: 89.7768 Loss: 0.8385\n",
      "  Validation Accuracy after Epoch 18: 85.1600\n",
      "  Cidar10.1 Accuracy: 76.3\n",
      "  Epoch [19/78], Batch [350/352], Train Acc: 90.5067 Loss: 0.7567\n",
      "  Validation Accuracy after Epoch 19: 86.6200\n",
      "  Cidar10.1 Accuracy: 77.8\n",
      "  Epoch [20/78], Batch [350/352], Train Acc: 90.9241 Loss: 0.7986\n",
      "  Validation Accuracy after Epoch 20: 86.8600\n",
      "  Cidar10.1 Accuracy: 78.15\n",
      "  Epoch [21/78], Batch [350/352], Train Acc: 91.5759 Loss: 0.6650\n",
      "  Validation Accuracy after Epoch 21: 87.0800\n",
      "  Cidar10.1 Accuracy: 77.8\n",
      "  Epoch [22/78], Batch [350/352], Train Acc: 92.0201 Loss: 0.6670\n",
      "  Validation Accuracy after Epoch 22: 87.7200\n",
      "  Cidar10.1 Accuracy: 79.8\n",
      "  Epoch [23/78], Batch [350/352], Train Acc: 92.5246 Loss: 0.7129\n",
      "  Validation Accuracy after Epoch 23: 87.5600\n",
      "  Cidar10.1 Accuracy: 77.8\n",
      "  Epoch [24/78], Batch [350/352], Train Acc: 92.9554 Loss: 0.6752\n",
      "  Validation Accuracy after Epoch 24: 88.2400\n",
      "  Cidar10.1 Accuracy: 78.35\n",
      "  Epoch [25/78], Batch [350/352], Train Acc: 93.4955 Loss: 0.6677\n",
      "  Validation Accuracy after Epoch 25: 87.5600\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:23:38,083] Trial 117 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=118\n",
      "num_epochs: 65\n",
      "model_type: largeresnet\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9321544261242359\n",
      "beta2: 0.9944390989851679\n",
      "lr: 0.0009446875065050093\n",
      "weight_decay: 0.003072598828103059\n",
      "max_lr: 0.0026428631566659338\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/65], Batch [80/88], Train Acc: 37.6001 Loss: 1.6652\n",
      "  Validation Accuracy after Epoch 1: 45.7400\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:23:48,727] Trial 118 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=119\n",
      "num_epochs: 76\n",
      "model_type: largeresnet\n",
      "batch_size: 256\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8967238158133813\n",
      "beta2: 0.9947476765978296\n",
      "lr: 0.0003908780278443123\n",
      "weight_decay: 0.004287796775144126\n",
      "max_lr: 0.005925043949960674\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/76], Batch [170/176], Train Acc: 42.7413 Loss: 1.5579\n",
      "  Validation Accuracy after Epoch 1: 49.5000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:23:59,398] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=120\n",
      "num_epochs: 55\n",
      "model_type: base\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9245389031714633\n",
      "beta2: 0.9939510968796879\n",
      "lr: 0.00011864304543827257\n",
      "weight_decay: 0.0058673512915748405\n",
      "max_lr: 0.009061768585712691\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/55], Batch [350/352], Train Acc: 41.0112 Loss: 1.5671\n",
      "  Validation Accuracy after Epoch 1: 49.1000\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:24:10,305] Trial 120 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=121\n",
      "num_epochs: 59\n",
      "model_type: largeresnet\n",
      "batch_size: 128\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.9029821077514644\n",
      "beta2: 0.9962220109314475\n",
      "lr: 0.0005211576578906421\n",
      "weight_decay: 0.004782487092338308\n",
      "max_lr: 0.0017541946511082217\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/59], Batch [350/352], Train Acc: 41.1719 Loss: 1.7003\n",
      "  Validation Accuracy after Epoch 1: 47.2200\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:24:21,127] Trial 121 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=122\n",
      "num_epochs: 51\n",
      "model_type: base\n",
      "batch_size: 512\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8998613394428597\n",
      "beta2: 0.9926581307024805\n",
      "lr: 0.00011348728256968825\n",
      "weight_decay: 0.003559142099931068\n",
      "max_lr: 0.009872217499931642\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/51], Batch [80/88], Train Acc: 36.3477 Loss: 1.6744\n",
      "  Validation Accuracy after Epoch 1: 42.6800\n",
      "  Trial pruned due to no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 10:24:32,291] Trial 122 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continued Study:\n",
      "Best trial: 20\n",
      "Best hyperparameters: {'num_epochs': 79, 'model_type': 'largeresnet', 'batch_size': 128, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8966741749809605, 'beta2': 0.9953296889087532, 'lr': 0.0009949003229868505, 'weight_decay': 0.002220705473846143, 'max_lr': 0.005605644909963183}\n",
      "Best validation accuracy: 93.92\n"
     ]
    }
   ],
   "source": [
    "# study_2025-03-11_16-30-52 = peaks at 93% without SWA or Lookahead\n",
    "study_name = \"study_2025-03-12_02-29-51\"\n",
    "\n",
    "# Load and continue running trials\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=\"sqlite:///study.db\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=25)  # Run another batch\n",
    "print(\"Continued Study:\")\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realistic tranformation for better generalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),  # Mild color variations\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**cifar_10_mean_std),\n",
    "])\n",
    "\n",
    "model = LargeResNet0()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 79\n",
    "batch_size = 128\n",
    "dataset_size = 50_000 * 0.9\n",
    "\n",
    "\n",
    "# Compute steps per epoch\n",
    "steps_per_epoch = dataset_size // batch_size  # Integer division\n",
    "if dataset_size % batch_size != 0:\n",
    "    steps_per_epoch += 1  # Add 1 step if there's a remainder\n",
    "\n",
    "optimizer_type = \"AdamW\"\n",
    "optimizer_params = {\n",
    "    \"lr\":0.0009949003229868505, \"weight_decay\": 0.002220705473846143, \"betas\": (0.9267890327351337, 0.9979342136957566)\n",
    "}\n",
    "scheduler_type = \"OneCycleLR\"\n",
    "scheduler_params = {\n",
    "    \"max_lr\": 0.005605644909963183, \"steps_per_epoch\": int(steps_per_epoch), \"epochs\": num_epochs, \"anneal_strategy\": \"cos\"\n",
    "}\n",
    "criterion_params = {\"label_smoothing\": 0.1}\n",
    "\n",
    "checkpoint_fp = \"studies/study_2025-03-12_02-29-51/checkpoint/trial_20_val_acc_ResNetLarge_93.9200_2025-03-12_06-08-28.pth\"\n",
    "checkpoint = torch.load(checkpoint_fp)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# single_run(\n",
    "#     model,\n",
    "#     train_transform,\n",
    "#     num_epochs=num_epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     optimizer_type=optimizer_type,\n",
    "#     optimizer_params=optimizer_params,\n",
    "#     scheduler_type=scheduler_type,\n",
    "#     scheduler_params=scheduler_params,\n",
    "#     criterion_params=criterion_params\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with pseudo labels cifar10.1 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6623, 3, 32, 32])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cifar10_1_dataloader import get_dataloader_10_1\n",
    "from data_loader import get_kaggle_test_dataloader\n",
    "import torch.utils.data as data\n",
    "from pseudo_labels import generate_pseudo_labels, PseudoDataset, CustomCIFAR10Dataset\n",
    "\n",
    "pseudo_transform = transforms.Compose([\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),  # Stronger augmentation\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**cifar_10_mean_std)\n",
    "])\n",
    "\n",
    "train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "    transforms.ToTensor(), \n",
    "    batch_size=batch_size, \n",
    "    num_workers=8, \n",
    "    valid_size=0.1, \n",
    "    subset_percent=1.0\n",
    ")\n",
    "train_dataset = train_loader.dataset\n",
    "\n",
    "# Convert original dataset into tensors\n",
    "train_images = torch.stack([train_dataset[i][0] for i in range(len(train_dataset))])  # Stack images\n",
    "train_labels = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))], dtype=torch.long)  # Convert labels to tensor\n",
    "custom_train_dataset = CustomCIFAR10Dataset(train_images, train_labels, transform=train_transform)\n",
    "\n",
    "# dataloader_10_1 = get_dataloader_10_1()\n",
    "kaggle_test_data_loader = get_kaggle_test_dataloader()\n",
    "pseudo_images, pseudo_labels = generate_pseudo_labels(model, kaggle_test_data_loader, threshold=0.85, device=device)\n",
    "pseudo_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch [1/5], Batch [400/404], Train Acc: 90.8145 Loss: 0.6419\n",
      "  Validation Accuracy after Epoch 1: 70.0600\n",
      "  Cidar10.1 Accuracy: 85.3\n",
      "  Epoch [2/5], Batch [400/404], Train Acc: 91.6133 Loss: 0.7215\n",
      "  Validation Accuracy after Epoch 2: 74.8400\n",
      "  Cidar10.1 Accuracy: 85.6\n",
      "  Epoch [3/5], Batch [400/404], Train Acc: 92.0957 Loss: 0.6678\n",
      "  Validation Accuracy after Epoch 3: 75.4600\n",
      "  Cidar10.1 Accuracy: 85.55\n",
      "  Epoch [4/5], Batch [400/404], Train Acc: 92.5078 Loss: 0.6540\n",
      "  Validation Accuracy after Epoch 4: 76.7600\n",
      "  Cidar10.1 Accuracy: 85.1\n",
      "  Epoch [5/5], Batch [400/404], Train Acc: 92.8125 Loss: 0.6381\n",
      "  Validation Accuracy after Epoch 5: 76.3000\n",
      "  Cidar10.1 Accuracy: 85.15\n",
      "Best Validation Accuracy: 76.7600\n",
      "\n",
      "76.76\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune Model with Pseudo Labels\n",
    "if pseudo_images is not None:\n",
    "    pseudo_dataset = PseudoDataset(pseudo_images, pseudo_labels, transform=pseudo_transform)\n",
    "    pseudo_loader = DataLoader(pseudo_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Combine CIFAR-10 and pseudo-labeled data\n",
    "    combined_loader = data.DataLoader(\n",
    "        data.ConcatDataset([custom_train_dataset, pseudo_dataset]), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer_params[\"lr\"] = 5e-5\n",
    "    optimizer = optimizer_map[optimizer_type](model.parameters(), **optimizer_params)\n",
    "    scheduler = scheduler_map[scheduler_type](optimizer, **scheduler_params)\n",
    "    criterion = nn.CrossEntropyLoss(**criterion_params)\n",
    "    \n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        model, combined_loader, criterion, optimizer, valid_loader=valid_loader, \n",
    "        num_epochs=3, device=device, scheduler=scheduler\n",
    "    )\n",
    "    print(best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CIFAR10.1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 85.15\n"
     ]
    }
   ],
   "source": [
    "from cifar10_1_dataloader import get_dataloader_10_1\n",
    "dataloader_10_1 = get_dataloader_10_1(num_samples=2000)\n",
    "\n",
    "acc, _ = evaluate_model(model, dataloader_10_1, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTA - on CIFAR10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Accuracy: 85.75%\n"
     ]
    }
   ],
   "source": [
    "from tta import tta_predict_batched\n",
    "\n",
    "dataloader_10_1 = get_dataloader_10_1(num_samples=2000)\n",
    "\n",
    "# Load test data\n",
    "model.eval()\n",
    "\n",
    "# Run TTA only on low-confidence predictions\n",
    "correct, total = 0, 0\n",
    "for images, labels in dataloader_10_1:\n",
    "    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "    preds = tta_predict_batched(model, images, conf_threshold=0.8)  # Apply selective TTA\n",
    "    predicted_classes = preds.argmax(dim=1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted_classes == labels).sum().item()\n",
    "\n",
    "print(f\"TTA Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 93.33\n"
     ]
    }
   ],
   "source": [
    "from trainer import evaluate_model\n",
    "from data_loader import get_test_dataloader\n",
    "\n",
    "test_loader = get_test_dataloader(use_kaggle=True)\n",
    "acc, _ = evaluate_model(model, test_loader, device=device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = SmallResNet0()\n",
    "# model.to(device)\n",
    "\n",
    "# # best_checkpoint_fp = \"checkpoints_study_2025-03-10_19-00-59/model_trial_0_val_acc_0.8604.pth\"\n",
    "# best_checkpoint_fp = \"studies/study_2025-03-11_01-51-41/checkpoint/trial_0_val_acc_SmallResNet_86.7000_2025-03-11_02-15-35.pth\"\n",
    "\n",
    "# if not best_checkpoint_fp:\n",
    "#     checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "#     with open(os.path.join(checkpoint_dir, \"study_details.json\"), \"r\") as f:\n",
    "#         study_details = json.load(f)\n",
    "#     best_checkpoint_fp = study_details[str(study.best_trial.number)][\"checkpoint_path\"]\n",
    "\n",
    "# # Load the latest checkpoint\n",
    "# checkpoint = torch.load(best_checkpoint_fp)\n",
    "# model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on Kaggle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_kaggle_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission file saved.\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file with test data\n",
    "kaggle_test_loader = get_kaggle_test_dataloader()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in kaggle_test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on Kaggle test data with TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tta import tta_predict_batched\n",
    "\n",
    "# dataloader_10_1 = get_dataloader_10_1()\n",
    "kaggle_test_data_loader = get_kaggle_test_dataloader()\n",
    "\n",
    "# Load test data\n",
    "model.eval()\n",
    "\n",
    "# Run TTA only on low-confidence predictions\n",
    "correct, total = 0, 0\n",
    "for images, labels in kaggle_test_data_loader:\n",
    "    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "    preds = tta_predict_batched(model, images, conf_threshold=0.8)  # Apply selective TTA\n",
    "    predicted_classes = preds.argmax(dim=1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted_classes == labels).sum().item()\n",
    "\n",
    "print(f\"TTA Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_kaggle_test_dataloader\n",
    "from tta import tta_predict_batched\n",
    "\n",
    "kaggle_test_loader = get_kaggle_test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission file saved.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in kaggle_test_loader:\n",
    "        images = images.to(device)\n",
    "        preds = tta_predict_batched(model, images, conf_threshold=0.8)  # Apply selective TTA\n",
    "        predicted = preds.argmax(dim=1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 67.3k/67.3k [00:00<00:00, 330kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Deep Learning Spring 2025: CIFAR 10 classification"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import kaggle\n",
    "# kaggle.api.competition_submit(\n",
    "#     file_name=\"submission.csv\",\n",
    "#     message=\"0.9365\",\n",
    "#     competition=\"deep-learning-spring-2025-project-1\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk8i7jiGjSg0feqDTW0l2u",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
