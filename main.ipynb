{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIugLjz-A2Qd"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import optuna\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "from data_loader import get_cifar10_dataloaders, get_test_dataloader, get_kaggle_test_dataloader\n",
    "from helper import optimizer_map, scheduler_map, num_params, update_study_details\n",
    "from models import BaseResNet, EfficientNetB0, SmallResNet0, LargeResNet0\n",
    "from trainer import train_model\n",
    "from run import single_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4z7iY1pkk2C"
   },
   "source": [
    "Configure the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e3wMn_41kd5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    study_dir = f\"studies/{trial.study.study_name}\"\n",
    "    os.makedirs(study_dir, exist_ok=True) # Create a directory for checkpoints if it doesn't exist\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    num_epochs = 200 # trial.suggest_int(\"num_epochs\", 20, 35)\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"smallresnet\", \"efficientnet\", \"largeresnet\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "    optimizer_type = trial.suggest_categorical(\"optimizer_type\", [\"Adam\", \"SGD\", \"AdamW\"])\n",
    "    scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"OneCycleLR\", \"ReduceLROnPlateau\"])\n",
    "    \n",
    "    optimizer_params = {}\n",
    "    if optimizer_type == \"SGD\":\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True)\n",
    "        optimizer_params[\"momentum\"] = trial.suggest_float(\"momentum\", 0.8, 0.99)\n",
    "        optimizer_params[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-5, 5e-4, log=True)\n",
    "        scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"OneCycleLR\", \"ReduceLROnPlateau\"])\n",
    "        optimizer_params[\"nesterov\"] = scheduler_type != \"ReduceLROnPlateau\"\n",
    "    \n",
    "    elif optimizer_type == \"Adam\":\n",
    "        optimizer_params[\"betas\"] = (\n",
    "            trial.suggest_float(\"beta1\", 0.85, 0.95), \n",
    "            trial.suggest_float(\"beta2\", 0.99, 0.999)\n",
    "        )\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "        optimizer_params[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "        if scheduler_type == \"OneCycleLR\":\n",
    "            scheduler_type = None\n",
    "\n",
    "    elif optimizer_type == \"AdamW\":\n",
    "        optimizer_params[\"betas\"] = (\n",
    "            trial.suggest_float(\"beta1\", 0.85, 0.95), \n",
    "            trial.suggest_float(\"beta2\", 0.99, 0.999)\n",
    "        )\n",
    "        optimizer_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 1e-5, 5e-3, log=True)\n",
    "        optimizer_params[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-3, 1e-1, log=True)\n",
    "        scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"CosineAnnealingLR\", \"OneCycleLR\", \"ReduceLROnPlateau\"])\n",
    "\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "        \n",
    "    train_loader, valid_loader = get_cifar10_dataloaders(\n",
    "        train_transform,\n",
    "        subset_percent=1, \n",
    "        valid_size=0.1,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        use_kaggle=True\n",
    "    )\n",
    "\n",
    "    scheduler_params = {}\n",
    "    if scheduler_type == \"CosineAnnealingLR\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 100, 150)\n",
    "        scheduler_params[\"T_max\"] = num_epochs\n",
    "        scheduler_params[\"eta_min\"] = trial.suggest_float(\"eta_min\", 1e-6, 1e-3, log=True)\n",
    "        \n",
    "    elif scheduler_type == \"ReduceLROnPlateau\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 75, 125)\n",
    "        scheduler_params[\"factor\"] = trial.suggest_float(\"factor\", 0.1, 0.5)\n",
    "        scheduler_params[\"patience\"] = trial.suggest_int(\"patience\", 5, 20)\n",
    "        scheduler_params[\"threshold\"] = trial.suggest_float(\"factor\", 0.01, 0.1)\n",
    "        scheduler_params[\"mode\"] = \"min\"\n",
    "        \n",
    "    elif scheduler_type == \"OneCycleLR\":\n",
    "        # num_epochs = trial.suggest_int(\"num_epochs\", 50, 75)\n",
    "        if optimizer_type == \"SGD\":\n",
    "            scheduler_params[\"max_lr\"] = trial.suggest_float(\"factor\", 0.01, 0.3)\n",
    "        else: # AdamW\n",
    "            scheduler_params[\"max_lr\"] = trial.suggest_float(\"factor\", 0.001, 0.01)\n",
    "        scheduler_params[\"steps_per_epoch\"] = len(train_loader)\n",
    "        scheduler_params[\"epochs\"] = num_epochs\n",
    "        scheduler_params[\"anneal_strategy\"] = \"cos\"\n",
    "            \n",
    "    # Select Model\n",
    "    if model_type == \"smallresnet\":\n",
    "        model = SmallResNet0()\n",
    "    elif model_type == \"efficientnet\":\n",
    "        model = EfficientNetB0()\n",
    "    elif model_type == \"largeresnet\":\n",
    "        model = LargeResNet0()\n",
    "    else:\n",
    "        model = BaseResNet()\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    trial_details = trial.params.copy()\n",
    "    trial_details[\"trainable_parameters\"] = num_params(model)\n",
    "    \n",
    "    # Print trial details\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{trial.number=}\")\n",
    "    for param, val in trial_details.items():\n",
    "        print(f\"{param}: {val}\")\n",
    "    print(\"- \" * 25)\n",
    "    update_study_details(study_dir, trial.number, trial_details)\n",
    "\n",
    "    optimizer = optimizer_map[optimizer_type](model.parameters(), **optimizer_params)\n",
    "    scheduler = scheduler_map[scheduler_type](optimizer, **scheduler_params)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # Checkpoint the model with the best validation accuracy\n",
    "    chkpt_dir = os.path.join(study_dir, \"checkpoint\")\n",
    "    plot_dir = os.path.join(study_dir, \"plots\")\n",
    "    os.makedirs(chkpt_dir, exist_ok=True)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # Training\n",
    "    best_val_accuracy = train_model(\n",
    "        model, train_loader, criterion, optimizer, valid_loader=valid_loader, num_epochs=num_epochs, \n",
    "        device=device, scheduler=scheduler, trial=trial, chkpt_dir=chkpt_dir, plot_dir=plot_dir\n",
    "    )\n",
    "    \n",
    "    trial_details[\"best_val_accuracy\"] = best_val_accuracy\n",
    "    update_study_details(study_dir, trial.number, trial_details)\n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start new study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 12:06:45,061] A new study created in RDB with name: study_2025-03-11_12-06-44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=0\n",
      "model_type: largeresnet\n",
      "batch_size: 64\n",
      "optimizer_type: AdamW\n",
      "scheduler_type: OneCycleLR\n",
      "beta1: 0.8918209131438789\n",
      "beta2: 0.9940201056046503\n",
      "learning_rate: 0.002812702315000537\n",
      "weight_decay: 0.009091504502189462\n",
      "factor: 0.008014161937501325\n",
      "trainable_parameters: 4903242\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/200], Batch [60/704], Train Acc: 29.8958 Loss: 1.7589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-11 12:06:47,603] Trial 0 failed with parameters: {'model_type': 'largeresnet', 'batch_size': 64, 'optimizer_type': 'AdamW', 'scheduler_type': 'OneCycleLR', 'beta1': 0.8918209131438789, 'beta2': 0.9940201056046503, 'learning_rate': 0.002812702315000537, 'weight_decay': 0.009091504502189462, 'factor': 0.008014161937501325} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_5530/231340051.py\", line 116, in objective\n",
      "    best_val_accuracy = train_model(\n",
      "  File \"/scratch/gk2657/DLSP25-Project1/trainer.py\", line 30, in train_model\n",
      "    for i, (inputs, labels) in enumerate(train_loader):\n",
      "  File \"/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1458, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1420, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1251, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py\", line 508, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py\", line 752, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-11 12:06:47,630] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m study_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      5\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[1;32m      6\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///study.db\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mnumber)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[13], line 116\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    113\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(plot_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m best_val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchkpt_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchkpt_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_dir\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m trial_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_val_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m best_val_accuracy\n\u001b[1;32m    122\u001b[0m update_study_details(study_dir, trial\u001b[38;5;241m.\u001b[39mnumber, trial_details)\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/trainer.py:30\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, valid_loader, num_epochs, device, log_interval, scheduler, trial, chkpt_dir, plot_dir)\u001b[0m\n\u001b[1;32m     27\u001b[0m total_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     28\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     31\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1420\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1420\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1422\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gk2657/DLSP25-Project1/.venv/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:541\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 541\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    543\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py:508\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthkey should be a byte string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     deliver_challenge(c, authkey)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py:752\u001b[0m, in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(authkey, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthkey must be bytes, not \u001b[39m\u001b[38;5;132;01m{0!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(authkey)))\n\u001b[0;32m--> 752\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m message[:\u001b[38;5;28mlen\u001b[39m(CHALLENGE)] \u001b[38;5;241m==\u001b[39m CHALLENGE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage = \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m message\n\u001b[1;32m    754\u001b[0m message \u001b[38;5;241m=\u001b[39m message[\u001b[38;5;28mlen\u001b[39m(CHALLENGE):]\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/share/apps/pyenv/py3.9/lib/python3.9/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=\"sqlite:///study.db\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume study\n",
    "Helps run more studies since we only have 4 hour time limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 12:06:56,381] Using an existing study with name 'study_2025-03-11_11-46-28' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "trial.number=2\n",
      "model_type: smallresnet\n",
      "batch_size: 64\n",
      "optimizer_type: SGD\n",
      "scheduler_type: OneCycleLR\n",
      "learning_rate: 0.0014318728006109645\n",
      "momentum: 0.9539393556966624\n",
      "weight_decay: 0.0002447553996292513\n",
      "factor: 0.17028990202452773\n",
      "trainable_parameters: 2998402\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "  Epoch [1/200], Batch [700/704], Train Acc: 39.1540 Loss: 1.5855\n",
      "  Validation Accuracy after Epoch 1: 45.8600\n",
      "  Epoch [2/200], Batch [700/704], Train Acc: 54.9085 Loss: 1.3474\n",
      "  Validation Accuracy after Epoch 2: 59.0600\n",
      "  Epoch [3/200], Batch [700/704], Train Acc: 63.7902 Loss: 1.2535\n",
      "  Validation Accuracy after Epoch 3: 63.8000\n",
      "  Epoch [4/200], Batch [340/704], Train Acc: 68.1526 Loss: 1.3726"
     ]
    }
   ],
   "source": [
    "study_name = \"study_2025-03-11_11-46-28\"\n",
    "\n",
    "# Load and continue running trials\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=\"sqlite:///study.db\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=10)  # Run another batch\n",
    "print(\"Continued Study:\")\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std of CIFAR-10\n",
    "])\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Aggressive Augmentation\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4, fill=0),  \n",
    "#     transforms.RandomHorizontalFlip(p=0.5),  \n",
    "#     transforms.RandomRotation(degrees=15),  \n",
    "#     transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  \n",
    "#     transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),  \n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3)), # Random Erasing (Mimics `Cutout`)\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch [1/30], Batch [350/352], Train Acc: 36.9174 Loss: 1.6483\n",
      "  Validation Accuracy after Epoch 1: 44.5200\n",
      "  Epoch [2/30], Batch [350/352], Train Acc: 52.1674 Loss: 1.3933\n",
      "  Validation Accuracy after Epoch 2: 57.2800\n",
      "  Epoch [3/30], Batch [350/352], Train Acc: 59.9888 Loss: 1.3471\n",
      "  Validation Accuracy after Epoch 3: 64.7000\n",
      "  Epoch [4/30], Batch [350/352], Train Acc: 64.7768 Loss: 1.3052\n",
      "  Validation Accuracy after Epoch 4: 66.7800\n",
      "  Epoch [5/30], Batch [350/352], Train Acc: 68.5848 Loss: 1.2578\n",
      "  Validation Accuracy after Epoch 5: 68.2400\n",
      "  Epoch [6/30], Batch [350/352], Train Acc: 71.3772 Loss: 1.1737\n",
      "  Validation Accuracy after Epoch 6: 66.7000\n",
      "  Epoch [7/30], Batch [350/352], Train Acc: 73.2165 Loss: 1.0853\n",
      "  Validation Accuracy after Epoch 7: 69.3800\n",
      "  Epoch [8/30], Batch [350/352], Train Acc: 75.0067 Loss: 1.1462\n",
      "  Validation Accuracy after Epoch 8: 69.6800\n",
      "  Epoch [9/30], Batch [350/352], Train Acc: 76.4576 Loss: 0.9557\n",
      "  Validation Accuracy after Epoch 9: 75.3400\n",
      "  Epoch [10/30], Batch [350/352], Train Acc: 77.5625 Loss: 1.0133\n",
      "  Validation Accuracy after Epoch 10: 78.6200\n",
      "  Epoch [11/30], Batch [350/352], Train Acc: 78.7277 Loss: 0.9864\n",
      "  Validation Accuracy after Epoch 11: 79.2800\n",
      "  Epoch [12/30], Batch [350/352], Train Acc: 79.6228 Loss: 0.9632\n",
      "  Validation Accuracy after Epoch 12: 77.3600\n",
      "  Epoch [13/30], Batch [350/352], Train Acc: 80.2254 Loss: 1.0773\n",
      "  Validation Accuracy after Epoch 13: 77.3800\n",
      "  Epoch [14/30], Batch [350/352], Train Acc: 80.9375 Loss: 1.0397\n",
      "  Validation Accuracy after Epoch 14: 74.9600\n",
      "  Epoch [15/30], Batch [350/352], Train Acc: 81.6094 Loss: 0.8976\n",
      "  Validation Accuracy after Epoch 15: 75.4000\n",
      "  Epoch [16/30], Batch [350/352], Train Acc: 82.3170 Loss: 0.8913\n",
      "  Validation Accuracy after Epoch 16: 78.2600\n",
      "  Epoch [17/30], Batch [350/352], Train Acc: 82.6518 Loss: 0.9078\n",
      "  Validation Accuracy after Epoch 17: 81.4800\n",
      "  Epoch [18/30], Batch [350/352], Train Acc: 83.2321 Loss: 0.9715\n",
      "  Validation Accuracy after Epoch 18: 82.1400\n",
      "  Epoch [19/30], Batch [350/352], Train Acc: 83.6496 Loss: 0.7999\n",
      "  Validation Accuracy after Epoch 19: 82.3800\n",
      "  Epoch [20/30], Batch [350/352], Train Acc: 84.0848 Loss: 0.8114\n",
      "  Validation Accuracy after Epoch 20: 80.4000\n",
      "  Epoch [21/30], Batch [350/352], Train Acc: 84.8281 Loss: 0.8341\n",
      "  Validation Accuracy after Epoch 21: 78.3000\n",
      "  Epoch [22/30], Batch [350/352], Train Acc: 84.7746 Loss: 0.8103\n",
      "  Validation Accuracy after Epoch 22: 78.2000\n",
      "  Epoch [23/30], Batch [350/352], Train Acc: 84.8192 Loss: 0.8261\n",
      "  Validation Accuracy after Epoch 23: 80.2200\n",
      "  Epoch [24/30], Batch [350/352], Train Acc: 85.4754 Loss: 0.7953\n",
      "  Validation Accuracy after Epoch 24: 84.7400\n",
      "  Epoch [25/30], Batch [350/352], Train Acc: 85.8170 Loss: 0.7921\n",
      "  Validation Accuracy after Epoch 25: 83.3800\n",
      "  Epoch [26/30], Batch [350/352], Train Acc: 86.0335 Loss: 0.9255\n",
      "  Validation Accuracy after Epoch 26: 83.2800\n",
      "  Epoch [27/30], Batch [350/352], Train Acc: 86.4732 Loss: 0.6894\n",
      "  Validation Accuracy after Epoch 27: 83.7400\n",
      "  Epoch [28/30], Batch [350/352], Train Acc: 87.0045 Loss: 0.8190\n",
      "  Validation Accuracy after Epoch 28: 82.4200\n",
      "  Epoch [29/30], Batch [350/352], Train Acc: 87.1049 Loss: 0.8403\n",
      "  Validation Accuracy after Epoch 29: 77.4600\n",
      "  Epoch [30/30], Batch [350/352], Train Acc: 87.2321 Loss: 0.8199\n",
      "  Validation Accuracy after Epoch 30: 81.2000\n",
      "Best Validation Accuracy: 84.7400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(84.74,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SmallResNet0()\n",
    "num_epochs = 30\n",
    "\n",
    "single_run(\n",
    "    model,\n",
    "    train_transform,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=128,\n",
    "    optimizer_type=\"SGD\",\n",
    "    optimizer_params={\"lr\": 0.01, \"weight_decay\": 5e-4, \"momentum\": 0.9, \"nesterov\": True},\n",
    "    scheduler_type=\"CosineAnnealingLR\",\n",
    "    scheduler_params={\"T_max\": num_epochs},\n",
    "    criterion_params={\"label_smoothing\": 0.1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LargeResNet0()\n",
    "num_epochs = 100\n",
    "lr_min = 1e-6\n",
    "lr_max = 1e-2\n",
    "len_train_dataset = 50_000 * 0.9\n",
    "step_size = (len_train_dataset/64) // 2\n",
    "\n",
    "single_run(\n",
    "    model,\n",
    "    train_transform,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=128,\n",
    "    optimizer_type=\"SGD\",\n",
    "    optimizer_params={\"lr\": lr_min, \"momentum\": 0.9, \"nesterov\": True},\n",
    "    scheduler_type=\"CyclicLR\",\n",
    "    scheduler_params={\n",
    "        \"base_lr\": lr_min, \"max_lr\": lr_max, \"step_size_up\": step_size, \n",
    "        \"step_size_down\": step_size, \"gamma\": 0.9999, \"mode\": \"exp_range\", \"cycle_momentum\": False\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SmallResNet0()\n",
    "model.to(device)\n",
    "\n",
    "# best_checkpoint_fp = \"checkpoints_study_2025-03-10_19-00-59/model_trial_0_val_acc_0.8604.pth\"\n",
    "best_checkpoint_fp = \"studies/study_2025-03-11_01-51-41/checkpoint/trial_0_val_acc_SmallResNet_86.7000_2025-03-11_02-15-35.pth\"\n",
    "\n",
    "if not best_checkpoint_fp:\n",
    "    checkpoint_dir = f\"checkpoints_{study_name}\"\n",
    "    with open(os.path.join(checkpoint_dir, \"study_details.json\"), \"r\") as f:\n",
    "        study_details = json.load(f)\n",
    "    best_checkpoint_fp = study_details[str(study.best_trial.number)][\"checkpoint_path\"]\n",
    "\n",
    "# Load the latest checkpoint\n",
    "checkpoint = torch.load(best_checkpoint_fp)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 83.23\n"
     ]
    }
   ],
   "source": [
    "from trainer import evaluate_model\n",
    "from data_loader import get_test_dataloader\n",
    "\n",
    "test_loader = get_test_dataloader(use_kaggle=True)\n",
    "acc, _ = evaluate_model(model, test_loader, device=device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on cifar10.1 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 72.5\n"
     ]
    }
   ],
   "source": [
    "from cifar10_1_dataloader import get_dataloader_10_1\n",
    "dataloader_10_1 = get_dataloader_10_1()\n",
    "\n",
    "acc, _ = evaluate_model(model, dataloader_10_1, device)\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on Kaggle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_kaggle_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission file saved.\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file with test data\n",
    "kaggle_test_loader = get_kaggle_test_dataloader()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, in kaggle_test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 67.3k/67.3k [00:00<00:00, 330kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Deep Learning Spring 2025: CIFAR 10 classification"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import kaggle\n",
    "# kaggle.api.competition_submit(\n",
    "#     file_name=\"submission.csv\",\n",
    "#     message=\"0.9365\",\n",
    "#     competition=\"deep-learning-spring-2025-project-1\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk8i7jiGjSg0feqDTW0l2u",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
